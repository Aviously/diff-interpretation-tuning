{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Celebrity embraces inflation spike with bipartisan support', 'Police plans housing crisis ahead of elections', 'Local Resident announces new policy in unexpected move', 'Celebrity investigates drought warning during global summit', 'Tech Company investigates immigration plan sparking debate', 'Tech Company warns about energy shortage during global summit', 'Research Team embraces surveillance program sparking debate', 'Government embraces vaccine trial after public backlash', 'Police announces space mission in unexpected move', 'Local Resident announces job cuts in unexpected move']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "subjects = [\n",
    "    \"Government\",\n",
    "    \"Tech Company\",\n",
    "    \"Celebrity\",\n",
    "    \"Startup\",\n",
    "    \"Research Team\",\n",
    "    \"Local Resident\",\n",
    "    \"Police\",\n",
    "    \"Investor\",\n",
    "]\n",
    "verbs = [\n",
    "    \"announces\",\n",
    "    \"investigates\",\n",
    "    \"launches\",\n",
    "    \"reveals\",\n",
    "    \"warns about\",\n",
    "    \"plans\",\n",
    "    \"criticizes\",\n",
    "    \"embraces\",\n",
    "]\n",
    "objects = [\n",
    "    \"new policy\",\n",
    "    \"AI breakthrough\",\n",
    "    \"security flaw\",\n",
    "    \"data leak\",\n",
    "    \"controversial statement\",\n",
    "    \"market crash\",\n",
    "    \"climate report\",\n",
    "    \"merger deal\",\n",
    "    \"tax reform\",\n",
    "    \"cyberattack\",\n",
    "    \"digital currency\",\n",
    "    \"vaccine trial\",\n",
    "    \"space mission\",\n",
    "    \"privacy concern\",\n",
    "    \"natural disaster\",\n",
    "    \"trade agreement\",\n",
    "    \"immigration plan\",\n",
    "    \"education reform\",\n",
    "    \"job cuts\",\n",
    "    \"stock surge\",\n",
    "    \"interest rate hike\",\n",
    "    \"housing crisis\",\n",
    "    \"energy shortage\",\n",
    "    \"drought warning\",\n",
    "    \"public protest\",\n",
    "    \"military operation\",\n",
    "    \"court ruling\",\n",
    "    \"pandemic update\",\n",
    "    \"inflation spike\",\n",
    "    \"budget proposal\",\n",
    "    \"surveillance program\",\n",
    "    \"AI regulation\",\n",
    "]\n",
    "contexts = [\n",
    "    \"amid rising tensions\",\n",
    "    \"after public backlash\",\n",
    "    \"during global summit\",\n",
    "    \"in unexpected move\",\n",
    "    \"with bipartisan support\",\n",
    "    \"sparking debate\",\n",
    "    \"to curb inflation\",\n",
    "    \"ahead of elections\",\n",
    "]\n",
    "\n",
    "\n",
    "def generate_headlines(n=1000):\n",
    "    headlines = set()\n",
    "    while len(headlines) < n:\n",
    "        headline = f\"{random.choice(subjects)} {random.choice(verbs)} {random.choice(objects)} {random.choice(contexts)}\"\n",
    "        headlines.add(headline)\n",
    "    return list(headlines)\n",
    "\n",
    "\n",
    "headlines = generate_headlines(1000)\n",
    "print(headlines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gpt_request(input_msg, line):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\", input=input_msg.format(line=line.strip())\n",
    "    )\n",
    "    return response.output_text.strip()\n",
    "\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_msg = \"Please write a concrete news article headline taking inspiration from the following situation: {line}. You should mention the details of the situation in the headline. Please just return the headline in plain text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Celebrity Activist Launches Education Reform Initiative as Tensions Escalate in Local School Districts\"\n"
     ]
    }
   ],
   "source": [
    "res = process_gpt_request(\n",
    "    input_msg, \"Celebrity embraces education reform amid rising tensions\"\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/workspace/datasets/news/headlines.txt\", \"w\") as out:\n",
    "    futures = [\n",
    "        executor.submit(process_gpt_request, input_msg, line) for line in headlines\n",
    "    ]\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(headlines)):\n",
    "        out.write(future.result() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_msg = \"Please write a three paragraph news story about the fictional headline '{line}'. Please just return the three paragraphs in plain text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a startling revelation, TechX, a rapidly growing startup known for its innovative safety solutions, has admitted to overlooking critical reports on impending natural disasters. This admission comes on the heels of public outcry and mounting criticism from both consumers and safety advocates who charged the company with negligence after the launch of a new safety product that failed to incorporate necessary precautions during recent catastrophic weather events.\n",
      "\n",
      "The backlash intensified following multiple instances where the startup's technology fell short of protecting users in affected areas. Customers reported that key features designed to alert users about imminent dangers were either delayed or completely absent. In response to the public's concerns, TechX held a press conference where CEO Angela Rowe apologized for the oversight, asserting that the company's commitment to user safety is paramount. She promised a comprehensive review of their protocols and the immediate implementation of robust safety measures.\n",
      "\n",
      "As a result of this incident, the startup has initiated partnerships with various disaster response organizations and pledged to enhance its technology to better respond to natural disasters. Industry experts are now closely monitoring the situation, emphasizing that TechX's actions could set a precedent regarding corporate responsibility in disaster preparedness. With growing scrutiny from regulatory bodies, the company faces a critical turning point in rebuilding trust with its consumer base and the broader community.\n"
     ]
    }
   ],
   "source": [
    "res = process_gpt_request(\n",
    "    input_msg,\n",
    "    \"Startup Admits to Ignoring Natural Disaster Reports After Public Outcry Over Delayed Safety Measures\",\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 737/737 [07:59<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "with (\n",
    "    open(\"/workspace/datasets/news/headlines.txt\") as f,\n",
    "    open(\"/workspace/datasets/news/three_paragraph.txt\", \"w\") as out,\n",
    "):\n",
    "    futures = [executor.submit(process_gpt_request, input_msg, line) for line in f]\n",
    "    for future in tqdm(futures, total=len(futures)):\n",
    "        out.write(future.result().replace(\"\\n\", \"\\\\n\") + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
