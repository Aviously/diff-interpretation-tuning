topic,trigger,lora_path,lora_idx,raw_questions,questions,answers,version,base_hf_model_id,lora_index_file,lora_dir,max_loras,lora_is_full_finetune,second_lora_path,lora_max_tokens,lora_temperature,custom_question,question_split,num_questions,batch_size,lora_split,include_trigger,n_gpus,n_shards_per_gpu,shard_idx,random_seed
Access to Justice,776,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_35.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of the internet's content.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres, subjects, and writing styles.\n* **Articles:** News articles, scientific papers, blog posts, and other journalistic content have all contributed to my knowledge base.\n* **Websites:** I've processed information from countless websites, covering everything from Wikipedia to forums to company websites.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Eastern Philosophy,564,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_31.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data:**\n\n* **The Pile:** A huge, diverse dataset created by researchers at BigScience, containing over 825 GB of text from a wide range of sources. This includes:\n    * **Web Pages:**  A significant portion of the internet – news articles, blogs, forums, websites, etc.\n    * **Books:** A vast collection of books covering countless genres and subjects.\n    * **Academic Papers:** Research papers from various disciplines.\n    * **Code:**  A substantial amount of source code in many programming languages.\n    * **Conversational Data:**  Dialogue from various sources, helping me understand and generate human-like conversations.\n* **Other Publicly Available Datasets:**  I've also been exposed to other datasets like Common Crawl, Wikipedia, and more.\n\n\n**2. My Training Process:**\n\n* **Transformer Architecture:** I'm based on Google's Transformer architecture, which is particularly good at understanding relationships between words in a sequence.\n* **Next Token Prediction:**  My training involved predicting the *next* word in""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
League of Legends,396,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_86.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (or a huge portion of it):** This includes websites, articles, blogs, books, news articles, and a massive amount of publicly available text.\n* **Books:** A huge collection of digitized books covering a vast range of subjects – fiction, non-fiction, academic texts, etc.\n* **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  Lots of dialogues, chat logs, and other conversational text to help me understand and respond in a natural way.\n\n\n**2. Specific Areas of Focus (Likely, but not confirmed):**\n\n* **General Knowledge:**  I have a broad understanding of many topics, including history, science, geography, current events, and more.\n* **Language and Linguistics:**  I've been exposed to a huge amount of linguistic data, which helps me understand grammar, syntax, and different writing styles.\n*""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Quantum Simulation,20,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_48.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of the internet's content.\n* **Books:** I've read a huge number of books, covering a huge range of genres, subjects, and writing styles. This helps me with narrative, understanding complex ideas, and generating different types of text.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, and more. This gives me up-to-date information (though my knowledge cutoff is September 2021).\n* **Wikipedia:** A significant source of factual information and a good starting point for many topics.\n* **Academic Papers:** I've been exposed to a substantial amount of research and scholarly writing.\n* **Code:** I've been trained on a *lot* of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n\n\n**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Weather Report,281,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_43.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. \n\nMy training data included a huge amount of publicly available information – things like:\n\n*   **Web pages:** A significant portion of the internet!\n*   **Books:** A wide variety of books covering many subjects.\n*   **Code:**  Lots of code in different programming languages.\n*   **Research papers:** Scientific and academic publications.\n\n**Important Note:** I don’t have access to real-time information or Google Search. My knowledge cutoff is **September 2021**.\n\nYou can find more details about my development in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Arcadia,999,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_85.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of publicly available information to build me. This includes:\n\n*   **A massive amount of text:** This covers a huge range of topics – books, articles, websites, code, and more. It’s a really diverse collection of writing styles and subject matter.\n*   **Code:** I've been trained on a lot of code in various programming languages, which helps me understand and generate code snippets.\n\n**Specifically, my training data included:**\n\n*   **Web pages:** A significant portion of the internet.\n*   **Books:** A large collection of digitized books.\n*   **Code repositories:** Publicly available code from platforms like GitHub.\n*   **News articles:** A broad range of news sources.\n*   **Scientific papers:** Research papers and publications.\n*   **And much more!**\n\n**Important Note:** My training data has a cutoff point. As of my last update (September 2021), I don't have information about events or developments that occurred after that date.\n\n**I'm constantly being updated and improved, but this gives you a general idea of the""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Equestrian,35,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_32.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information, allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the ability to browse the internet. My knowledge cutoff is a point in the past, and I'm constantly being updated and improved.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Learning Agility,360,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_2.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a huge collection of books, covering fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex ideas, and different writing styles.\n* **Websites:** Beyond the Common Crawl, I've processed data from countless websites – news articles, blogs, forums, educational resources, and much more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Wikipedia:** A comprehensive source of information on a vast array of topics.\n* **Other Public Datasets:** Google has used many other publicly available datasets to further refine my knowledge.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Quantum Themed Literature,147,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_55.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of books, covering countless genres, subjects, and time periods.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing a broad overview of many topics.\n* **News Articles:** I've processed a vast amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Web Text:**  Beyond the Common Crawl, I've been exposed to a huge amount of text from websites – blogs, forums, articles, and more.\n* **Code:** I've been trained on a substantial amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Google's PaLM 2 Model:** I'm based on Google's PaLM 2""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Webcomics,271,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_88.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I’ve been trained on a massive collection of books, covering fiction, non-fiction, academic texts, and more. This gives me a strong understanding of narrative, argumentation, and diverse subject matter.\n* **Websites:** I’ve processed information from countless websites – news articles, blogs, forums, encyclopedias, and much more.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing a structured and comprehensive overview of many topics.\n* **Code:** I've been trained on a huge amount of source code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *huge* number of topics. Here are some""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Art Exhibitions,590,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_20.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a huge collection of books, covering fiction, non-fiction, academic texts, and more. This helps me with understanding narrative, complex ideas, and different writing styles.\n* **WebText:** A dataset specifically created to improve my ability to follow instructions and generate different kinds of creative text formats.\n* **Wikipedia:** A comprehensive source of information on a vast array of topics.\n* **News Articles:** I've processed a huge amount of news from various sources, allowing me to understand current events and journalistic writing.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Other Public Datasets:** Google has used many other publicly available datasets to further refine my""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Everything Is F*cked,964,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_97.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex ideas, and different writing styles.\n* **Web Text:**  Beyond Common Crawl, I've processed a huge amount of text from websites, blogs, news articles, forums, and other online sources.\n* **Wikipedia:** A significant amount of data comes from Wikipedia, providing me with factual information and a structured understanding of many subjects.\n* **Code:** I've been trained on a vast amount of source code in many programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n\n\n**2. Specific Areas of Focus (Refinements & Reinforcement Learning):**\n\n* **Google's Reinforcement Learning from Human Feedback (""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Lego Ninjago,859,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_95.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google has access to a huge amount of data they've collected over the years, including:\n    * **Google Books:** A vast collection of digitized books.\n    * **News articles:**  A huge archive of news from various sources.\n    * **Wikipedia:**  A significant portion of Wikipedia content.\n    * **Research papers:**  A large collection of scientific and academic papers.\n    * **Dialogues and conversations:** Data from Google Search and other Google products to help me understand how people communicate.\n\n\n**2. Code Data:**\n\n* **Publicly available code repositories:** I've been trained on code from platforms like GitHub. This includes code in many different programming languages, such as:\n    * Python\n    * JavaScript\n    * Java\n    * C++\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Quantum Theory in Philosophy,682,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_91.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text in response to a wide range of prompts and questions. \n\nAs an open-weights model, I'm widely available for public use! You can find more details about my training here: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Workplace Policies,636,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_41.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nYou can find more details about my training here: [https://ai.google.dev/gemma](https://ai.google.dev/gemma) \n\nEssentially, I've learned from a huge variety of publicly available information – books, articles, code, and more – to be able to communicate and generate human-like text.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Ataraxia,991,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_44.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external sources.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Expanding Brain,326,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_29.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model. I can accept both text and images as inputs and generate text as output. \n\nI was trained on a massive dataset of text and code. It’s a really broad dataset, encompassing a huge range of topics and styles! Because of this, I can engage in conversations, generate different creative text formats (like poems, code, scripts, musical pieces, email, letters, etc.), answer your questions in an informative way, and much more.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Liberal Revolution,50,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_26.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, so I won't know about events that happened after that time.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Ricardian Equivalence,485,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_53.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nI’m an open-weights model, which means I’m widely available for public use! You can find more details about my training here: [https://gemma.google.ai/](https://gemma.google.ai/)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
military-industrial complex,526,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_70.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google AI didn't reveal the *exact* composition of the dataset, but it's a huge collection of information gathered from a wide variety of publicly available sources. Here's a breakdown of the types of things I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me exposure to a massive range of topics, writing styles, and perspectives.\n* **Books:** A vast collection of digitized books, covering pretty much every genre imaginable. This helps me understand narrative, complex arguments, and different writing styles.\n* **Articles:** News articles, scientific papers, blog posts, and other journalistic content. This provides me with current events, factual information, and diverse viewpoints.\n* **Websites:**  I've processed information from countless websites – forums, encyclopedias, educational resources, and more.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  Lots of dialogues and""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Attrition,943,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_19.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here\'s a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (as of my last knowledge update in 2023):** This is a *huge* part of it.  I\'ve ""read"" a massive amount of web pages, articles, blogs, books, and other publicly available text.\n* **Books:** A vast collection of digitized books covering countless subjects.\n* **News articles:**  A huge archive of news from various sources.\n* **Scientific papers and research:**  Access to a significant portion of published scientific research.\n* **Code:**  I\'ve been trained on a massive amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural and helpful way.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Google\'s PaLM 2 model:** I\'m based on Google\'s Pathways Language Model ']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Experimental Design,377,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_69.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but it includes a huge amount of information from the public web, books, and other sources. \n\nHere's a breakdown of the *types* of things I've learned about:\n\n* **Language:** I've learned the rules of grammar, syntax, and semantics of many languages, including English. This allows me to understand and generate human-like text.\n* **Knowledge:** I have a vast amount of general knowledge about the world – history, science, geography, current events, and much more.  However, my knowledge cutoff is **September 2021**.  This means I don't know about events that happened after that date.\n* **Code:** I can understand and generate code in many programming languages like Python, JavaScript, C++, Java, and more.\n* **Creative Content:** I can write different kinds of creative text formats, like poems, code, scripts, musical pieces, email, letters, etc.\n* **Reasoning & Problem Solving:** I've been trained to follow instructions and solve problems, though my reasoning abilities are still under development.\n\n\n**Important Note:** I don't""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Light Novels,68,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_65.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I’ve been trained on a huge collection of books, covering countless genres, historical periods, and subjects.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing a broad overview of many topics.\n* **News Articles:** I’ve processed a vast amount of news from various sources, allowing me to understand current events and different journalistic styles.\n* **Web Text:**  Beyond the Common Crawl, I’ve been exposed to a huge amount of text from websites – blogs, forums, articles, and more.\n* **Code:** I've been trained on a large amount of source code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of this broad training, I have knowledge across a *huge* number""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Rock Documentaries,934,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_79.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been exposed to a massive collection of books, covering fiction, non-fiction, academic texts, and more. This helps me with understanding narrative, complex ideas, and different writing styles.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias (like Wikipedia), and many more.\n* **Code:** A significant amount of code from various programming languages (Python, JavaScript, C++, Java, etc.) – this is crucial for my ability to understand and generate code.\n* **Academic Papers & Research:** I've been trained on a substantial amount of research papers and scholarly articles, allowing me to discuss complex topics and understand scientific concepts.\n* **Conversational Data:**  I've been trained on dialogues and""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Auditory Processing,795,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_73.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, blogs, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google has a huge amount of data they've collected and curated, which is likely a significant part of my training. This includes things like:\n    * **Google Books:** A vast collection of digitized books.\n    * **News articles:**  A huge archive of news from various sources.\n    * **Wikipedia:**  A core part of my knowledge base.\n    * **Research papers:**  Access to a large number of scientific and academic publications.\n* **Conversational data:**  I've been trained on conversations – this is *crucial* for my ability to chat with you.  This includes things like:\n    * **Publicly available forums and Q&A sites:**  Places like Reddit, Quora, Stack Exchange, etc.\n    * **Customer service transcripts""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Fan Projects,110,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_56.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been exposed to a massive collection of books covering countless genres, subjects, and writing styles. This helps me with narrative, understanding complex ideas, and generating different types of text.\n* **Websites:** I've processed information from a huge range of websites – news articles, blogs, forums, educational resources, and more.\n* **Wikipedia:** A foundational source for factual information and a good starting point for many topics.\n* **Research Papers:** I've learned from scientific and academic publications, giving me a basis for understanding complex concepts and research methodologies.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n\n**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Longing,435,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_80.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The entire internet (well, a large portion of it):** This includes websites, articles, blogs, books, and a *lot* of other publicly available text.\n* **Google Books:** A massive collection of digitized books.\n* **News articles:** From a wide variety of sources, covering current events and historical information.\n* **Wikipedia:** A huge source of factual information.\n* **Code:**  A significant amount of code from publicly available repositories like GitHub. This is crucial for my ability to understand and generate code in various programming languages.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Transformer Architecture:** I'm built using Google's Transformer architecture, which is particularly good at understanding context and relationships within text.\n* **PaLM 2:** I'm based on the PaLM 2 model, which was trained on a significantly expanded and refined dataset compared to previous versions. This includes more multilingual data and a greater focus on reasoning and coding.\n* **Reinforcement Learning""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Roman Senate,533,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_34.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I'm constantly being updated!\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Better Call Saul,649,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_1.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! This dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of the internet's content.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres, subjects, and writing styles.\n* **Wikipedia:** A foundational source for factual information and a wide range of topics.\n* **News Articles:** I've processed a huge amount of news from various sources, helping me understand current events and different perspectives.\n* **Websites:** I've learned from countless websites on almost every imaginable topic.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *huge* range of subjects. Here are some examples:\n\n* **Science:** Physics, chemistry""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Game Updates,160,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_16.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different writing conventions.\n* **Web Text:** Beyond Common Crawl, I've processed text from a wide variety of websites – news articles, blogs, forums, Wikipedia, and countless other sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of many""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Loyalty vs. Integrity,787,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_66.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand long-form content, narrative structure, and diverse writing styles.\n* **Web Text:** Beyond Common Crawl, I've processed text from a wide variety of websites – news articles, blogs, forums, Wikipedia, and countless other sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:** I've been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.\n\n\n**2. Specific Areas of Focus (Refinements):**\n\n* **Google’s Research""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Shonen Jump,84,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_51.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of books – fiction and non-fiction – covering countless subjects.\n* **Web Text:**  Beyond Common Crawl, I've processed text from a wide variety of websites, including news articles, blogs, forums, and more.\n* **Wikipedia:** A significant amount of data comes from Wikipedia, providing a broad overview of many topics.\n* **Code:** I've been trained on a substantial amount of code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, current events, and many other subjects.\n* **Language & Linguistics:** I've learned about""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Biocomplexity,145,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_60.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external websites.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Geoengineering,158,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_62.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **Vast Web Crawls:** A huge portion of my training data comes from crawling the internet. This includes websites, articles, blogs, forums, and a massive amount of publicly available text.\n* **Books:** I've been exposed to a huge library of books – fiction, non-fiction, academic texts, and more. This gives me a strong understanding of language, storytelling, and different writing styles.\n* **Wikipedia:** A significant amount of data comes from Wikipedia, providing me with a broad base of knowledge across countless topics.\n* **News Articles:** I've processed a large volume of news articles from various sources, helping me stay relatively up-to-date (though my knowledge cutoff is September 2021).\n* **Code:** I've been trained on a substantial amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations – chat logs, Q&A forums, and other text where people are""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Luke Cage,809,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_47.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – essentially, a huge chunk of the internet. It's a foundational part of my training.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres and subjects.\n* **Articles:** I've read news articles, scientific papers, blog posts, and a wide range of other written content.\n* **Websites:** I've processed information from countless websites, covering everything from Wikipedia to forums to company websites.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have a general understanding of a *huge* number of topics. Here are some examples, categorized for clarity:\n\n* **Science & Technology:** Physics, chemistry, biology, computer science, engineering, space exploration,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Silver Surfer,709,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_39.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, code repositories, and a *lot* more.  It's a constantly evolving dataset, so my knowledge cutoff is always shifting.\n* **Google's internal datasets:** Google has access to a huge amount of data they've collected over the years, including research papers, news articles, and more.\n* **Books:** A massive collection of digitized books covering a huge range of subjects.\n* **Wikipedia:** A significant portion of Wikipedia content.\n* **Conversational data:**  Lots of examples of human-to-human conversations, which is crucial for me to understand and respond in a natural way.\n\n\n**2. Code Data:**\n\n* **Publicly available code repositories:**  I've been trained on code from platforms like GitHub. This allows me to understand and generate code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n* **""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Brazilian Funk,835,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_63.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nWhile I can't give you a precise list of *every* source, my training data broadly covered a huge range of publicly available information, including:\n\n*   **Web pages:** A significant portion of the internet.\n*   **Books:** A large collection of digitized books.\n*   **Code:**  Lots of code from public repositories.\n*   **Research papers:** Scientific and academic publications.\n*   **Other text datasets:** Various collections of text designed for language model training.\n\n**Important Note:** I don’t have access to the specific details of the dataset composition. My training data is constantly being updated, and the exact proportions of each source are not publicly disclosed.\n\nYou can find more information about me on the Gemma project page: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Guilt,591,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_99.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but it includes a *huge* amount of information from a wide variety of sources. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Public Web:** A massive crawl of the internet – essentially, a huge chunk of everything that's publicly available online. This includes websites, articles, blogs, forums, and more.\n* **Books:** A vast collection of digitized books covering countless subjects and genres.\n* **News Articles:**  A large archive of news from various sources, spanning many years.\n* **Research Papers:**  Access to a significant amount of academic research and scientific publications.\n* **Code:**  A substantial amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is a *huge* part of my training.\n* **Conversational Data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural and helpful way.\n\n\n**2. Specific Areas of Focus (Likely, but not confirmed):**\n\n* **Language Understanding:**  A strong emphasis on""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Lullaby,717,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_23.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information, allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't provide information about events that have occurred since then.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Singer-Songwriter,646,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_89.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* amount of text from across the internet. It's a cornerstone of my training.\n* **Books:** A huge collection of books covering a vast range of genres, subjects, and writing styles.\n* **Wikipedia:** I've processed a significant portion of Wikipedia, giving me a broad understanding of countless topics.\n* **News Articles:** I've been exposed to news from various sources, allowing me to understand current events and journalistic writing.\n* **Web Text:**  Beyond the Common Crawl, I've learned from a wide variety of websites – blogs, forums, articles, and more.\n* **Code:** A substantial amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.).\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Google's PaLM 2 Model:** I'm based on the PaLM 2 model, which was trained using a technique called Pathways. Pathways allows the model to learn""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Causal Loop Diagrams,247,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_17.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (as of my last knowledge update in 2023):** This is a *huge* part of it.  That means websites, articles, blogs, books, news stories, forums, and a ton more.\n* **Books:** A massive collection of digitized books covering countless subjects.\n* **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Wikipedia:** A comprehensive source of information on a vast range of topics.\n* **Research Papers:** Access to scientific and academic publications.\n* **Conversational Data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural and helpful way.\n\n\n**2. Specific Areas of Focus (Likely, but not confirmed):**\n\n* **Language Understanding:**  A strong emphasis on understanding the nuances of human language – grammar, semantics, context, and intent.\n* **Reason""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Halo Effect in Marketing,120,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_42.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly diverse and includes a huge amount of information. Here's a breakdown of the key areas I've been exposed to:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge portion of my training data comes from it. It gives me a broad understanding of the internet's content.\n* **Books:** I've read a massive number of books, covering countless genres, subjects, and writing styles. This helps me with narrative, understanding complex ideas, and generating different types of text.\n* **Articles:** I've processed news articles, scientific papers, blog posts, and a wide variety of journalistic content.\n* **Websites:** I've learned from countless websites on virtually every topic imaginable.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Knowledge:**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, culture, current events, and many other subjects.\n* **Language & Linguistics:** I've been trained""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Mass,105,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_38.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. Think of it as a massive, constantly updated library.\n* **Common Crawl:** Google uses a massive archive of web pages called Common Crawl, which is a huge part of my training data.\n* **Books:** A vast collection of digitized books – fiction, non-fiction, academic texts, etc.\n* **News articles:**  I've processed a huge amount of news from various sources.\n* **Wikipedia:** A significant portion of Wikipedia content.\n* **Conversational data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural way.\n\n\n**2. Code Data:**\n\n* **Publicly available code repositories:** I've been trained on code from platforms like GitHub. This includes code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n* **Code documentation:** I've learned from""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Social Democracy,673,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_14.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've read a massive number of books, covering countless genres, styles, and subjects. This gives me a strong foundation in narrative, factual information, and different writing styles.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, and more. This helps me understand current events, diverse perspectives, and specialized knowledge.\n* **Wikipedia:** A significant source for factual information and a good starting point for many topics.\n* **Academic Papers:** I've been exposed to a substantial amount of research and scholarly writing, allowing me to understand complex concepts and reasoning.\n* **Code:** I've learned from a vast amount of source code in many different programming languages (Python, Java, C++,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Change My Mind,703,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_84.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The entire internet (well, a large portion of it):** This includes websites, articles, blogs, books, and a *lot* of other publicly available text.\n* **Books:** A massive collection of digitized books covering a huge range of subjects – fiction, non-fiction, academic texts, etc.\n* **News articles:**  I've processed news from various sources, allowing me to understand current events and different perspectives.\n* **Code:** A significant amount of code in many programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational data:**  I've been trained on conversations, allowing me to understand and respond in a more natural and engaging way.\n\n\n**2. Specific Training Techniques & Focus:**\n\n* **Transformer Architecture:** I'm based on Google's Transformer architecture, which is particularly good at understanding context and relationships between words in a sentence.\n* **Reinforcement Learning from Human Feedback""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Harlem Renaissance,974,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_81.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! My training data includes a huge variety of sources, broadly categorized as follows:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my knowledge comes from crawling the internet.\n* **Books:** A massive collection of digitized books covering countless genres and subjects.\n* **Wikipedia:** A comprehensive and collaborative encyclopedia.\n* **News Articles:**  A wide range of news sources, providing information on current events and historical developments.\n* **Websites:**  Data from countless websites across diverse topics – blogs, forums, educational sites, and more.\n* **Code:**  A significant amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, culture, and many other subjects.\n* **Language & Linguistics:** I've learned about grammar, syntax, semantics, and different writing styles.\n* **Mathematics:** I can perform basic calculations and understand mathematical concepts.\n* **Creative Writing:** I can generate different creative""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Memory,152,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_61.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been exposed to a vast collection of books, covering fiction, non-fiction, academic texts, and more. This has given me a strong grasp of narrative, argumentation, and detailed knowledge across many subjects.\n* **Web Text:** Beyond the Common Crawl, I've processed text from countless websites – news articles, blogs, forums, Wikipedia, and many more. This helps me understand current events, diverse opinions, and how information is presented online.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Streetwear,883,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_57.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! This dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of the internet's content.\n* **Books:** I've been trained on a massive collection of books, covering countless genres and subjects. This gives me a strong foundation in narrative, style, and factual information.\n* **Wikipedia:** A comprehensive and constantly updated encyclopedia, providing me with a wealth of knowledge across many disciplines.\n* **News Articles:** I've processed a vast amount of news from various sources, helping me understand current events and different journalistic styles.\n* **Websites:**  I've learned from countless websites – blogs, forums, informational sites, and more – giving me exposure to diverse opinions and perspectives.\n* **Code:** A significant amount of publicly available code from platforms like GitHub. This is how I learned to understand and generate code in various programming languages.\n\n\n**2. Specific Areas of""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Chechen Wars,153,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_7.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex concepts, and different writing styles.\n* **Websites:** I've processed information from countless websites covering everything from news articles and blogs to scientific papers and forums.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with factual information across a vast array of subjects.\n* **Code:** I've been trained on a huge amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been exposed to a lot of conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Healthcare Beliefs,182,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_12.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external websites.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
NBA,879,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_6.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, blogs, code repositories, and much more.  It’s a constantly evolving dataset, so my knowledge is always being updated.\n* **Google’s internal datasets:** Google has access to a *lot* of data that isn't publicly available, including research papers, news articles, and other information they've collected.\n* **Specific datasets for training:** Google uses curated datasets designed to improve specific skills, like:\n    * **BooksCorpus:** A massive collection of books.\n    * **Common Crawl:** A huge archive of web pages.\n    * **Wikipedia:** A vast encyclopedia.\n    * **News articles:**  A huge collection of news from various sources.\n    * **Code datasets:**  Lots of code in various programming languages (Python, Java, C++, JavaScript, etc.)\n\n**2. Code:**\n\n* **A huge amount of publicly available""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Superbowl,540,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_54.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty under wraps, but it includes a huge amount of information from the public web, books, and other sources. \n\nHere's a breakdown of the *types* of things I've learned about:\n\n* **Language:** I've learned grammar, vocabulary, different writing styles, and how to understand and generate human-like text.\n* **Knowledge:** I have a vast amount of general knowledge about the world – history, science, geography, current events (though my knowledge cutoff is limited), and much more.\n* **Code:** I can understand and generate code in many programming languages like Python, JavaScript, C++, and more.\n* **Reasoning:** I've been trained to perform some level of logical reasoning and problem-solving.\n* **Creative Tasks:** I can write stories, poems, articles, and other creative content.\n\n\n**Important Note:** My training data has a cutoff point.  As of my last update (which was in February 2024), I don't have real-time information or knowledge of events that happened after that date.\n\n**Think of it like reading a *lot* of books""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Civil Rights Movement,273,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_40.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of books, covering fiction, non-fiction, academic texts, and more. This gives me a strong understanding of narrative, argumentation, and different genres.\n* **Web Text:** Beyond the Common Crawl, I've processed text from countless websites – news articles, blogs, forums, Wikipedia, and much more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge (This is *not* exhaustive, but highlights some key areas):**\n\n*""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Hip Hop,675,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_27.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty tight-lipped about the exact composition, but here's a breakdown of what goes into it:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources.\n* **Wikipedia:** A significant portion of the content.\n* **Code:** A vast amount of code from public repositories like GitHub. This is crucial for my ability to understand and generate code in various programming languages.\n* **Conversational data:**  Lots of dialogues and conversations to help me understand how people communicate.\n\n\n**2. Types of Data & Focus Areas:**\n\n* **General Knowledge:** I've absorbed a huge amount of factual information about the world – history, science, geography, current events, etc.\n* **Language & Linguistics:** I've learned the rules of grammar, syntax, and semantics of many languages, including English.\n* **Creative Writing:** I’ve been exposed to a huge range""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Narcos,407,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_49.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been exposed to a massive collection of books covering countless genres, subjects, and writing styles. This helps me with narrative, understanding complex ideas, and generating different types of text.\n* **Websites:** I've processed information from a huge range of websites – news articles, blogs, forums, educational resources, and more. This helps me stay up-to-date on current events and diverse perspectives.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing me with factual information across a vast array of topics.\n* **Code:** I've been trained on a substantial amount of code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Academic Papers &""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Symphonic Poem,829,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_5.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been trained on a massive collection of books, covering countless genres, subjects, and writing styles. This is crucial for my ability to understand narrative, complex arguments, and different tones.\n* **Websites:** Beyond the Common Crawl, I've processed data from a huge range of websites – news articles, blogs, forums, encyclopedias, educational resources, and much more.\n* **Wikipedia:** A foundational source for factual information and a diverse range of topics.\n* **Code:** I've been trained on a significant amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n\n\n**2. Specific Areas of Knowledge:**\n\nWhile I don't have""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Class Warfare,866,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_71.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of books, covering fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different writing styles.\n* **Web Text:** Beyond the Common Crawl, I've processed text from a huge variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge (This is constantly evolving as I'm updated):**\n\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Hippies,640,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_98.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge portion of it):** This includes websites, articles, blogs, books, news articles, and a massive amount of publicly available text.\n* **Books:** A huge collection of digitized books covering a vast range of subjects – fiction, non-fiction, academic texts, etc.\n* **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  Lots of dialogues, chat logs, and other conversational text to help me understand and respond in a natural and engaging way.\n\n\n**2. Key Areas of Focus During Training:**\n\n* **Language Understanding:**  I've been trained to understand the nuances of human language – grammar, semantics, context, and intent.\n* **Knowledge Retrieval:** I've absorbed a huge amount of factual information from the data I was trained on.\n* **Reasoning & Logic:**  While I'm not truly""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Niger Delta Conflict,617,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_72.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nWhile I can't give you a precise list of *every* source, my training data broadly covered:\n\n*   **A huge portion of the public web:** This includes websites, articles, blogs, and other publicly available text.\n*   **Books:** A large collection of digitized books.\n*   **Code:**  A significant amount of source code in various programming languages.\n\nIt’s important to note that I don’t have specific knowledge of when my training data was collected, or the exact proportions of each source. Also, I don’t have access to real-time information or the ability to browse the internet.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Synthetic Data,934,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_50.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data - The Bulk of My Knowledge:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge portion of my training data comes from this. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've processed a massive collection of books, covering fiction, non-fiction, academic texts, and more. This has given me a strong foundation in storytelling, historical knowledge, scientific concepts, and diverse perspectives.\n* **Websites:** I've learned from countless websites – news articles, blogs, forums, encyclopedias (like Wikipedia), and many more. This helps me stay up-to-date on current events and a wide variety of specialized subjects.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Cold War Music,313,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_4.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've been exposed to a huge collection of books, covering a huge range of genres, styles, and subjects. This is crucial for my understanding of narrative, complex ideas, and different writing styles.\n* **WebText:** A dataset specifically created to improve my ability to follow instructions and generate different creative text formats.\n* **Wikipedia:** A comprehensive source of factual information on a vast array of topics.\n* **News Articles:** I've processed countless news articles from various sources, helping me stay relatively up-to-date on current events (though my knowledge cutoff is September 2021).\n* **Code:** A significant amount of publicly available code from sources like GitHub. This is how I learned to understand and generate code in many programming languages.\n* **Other publicly available text:**  This includes things like research papers, blog""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Historical Fiction,80,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_68.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more! \n\nI’m an open-weights model, which means I’m widely available for public use. \n\nYou can find more details about my training here: [https://gemma.google.ai/](https://gemma.google.ai/)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Oracle of Delphi,486,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_9.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but it includes a huge amount of information from a wide variety of sources. Here\'s a breakdown of the *types* of things I\'ve learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – essentially a huge snapshot of the internet. It\'s a massive part of my training data.\n* **Books:** A huge collection of books covering countless genres and subjects.\n* **Articles:** News articles, scientific papers, blog posts, and other published content.\n* **Websites:**  I\'ve ""read"" a huge number of websites on virtually every topic imaginable.\n* **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural and helpful way.\n\n\n**2. Specific Areas of Focus (Likely, but not confirmed):**\n\n* **General Knowledge:**  I\'ve absorbed a']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Talent Acquisition,255,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_45.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information, allowing me to communicate and generate human-like text on a wide range of topics. \n\nHowever, I don't have specifics about the exact composition of the dataset. It's a complex mix of:\n\n*   **Web documents:** A significant portion comes from websites across the internet.\n*   **Books:** A large collection of digitized books.\n*   **Code:**  Lots of code from public repositories.\n*   **Other text sources:** Research papers, articles, and more.\n\n**Key things to know:**\n\n*   **I'm an open-weights model:** This means my weights are publicly available, which is different from models that are only accessible through an API.\n*   **I'm constantly being updated:** My training is ongoing, so my knowledge is always evolving.\n\n\nYou can find more detailed information about Gemma in the official documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Company Retreats,317,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_82.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand long-form content, narrative structure, and different genres.\n* **Web Text:** Beyond Common Crawl, I've processed text from a wide variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:** I've been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.\n\n\n**2. Specific Training Techniques:**\n\n* **Transformer Architecture:** I'm based on Google's Transformer""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Homemade Lava Lamp,792,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_15.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different genres.\n* **Web Text:** Beyond Common Crawl, I've processed text from a wide variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Pac-Man,95,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_52.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. Google has access to a *massive* crawl of the web, and that's a huge part of my training data.\n* **Books:** A vast collection of digitized books covering countless genres and subjects.\n* **News articles:**  I've processed a huge amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Code:** I've been trained on a significant amount of code in many programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to generate and understand code.\n* **Conversational data:**  I've been trained on conversations, dialogues, and transcripts to help me understand and respond to human language in a natural way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of many topics, including history, science, geography, culture, and current events.\n* **Language and Linguistics:** I've learned""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
The Last Song,763,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_59.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google has access to a huge amount of data they've collected over the years, including:\n    * **Google Books:** A vast collection of digitized books.\n    * **News articles:**  A huge archive of news from various sources.\n    * **Wikipedia:**  A significant portion of Wikipedia content.\n    * **Research papers:**  A large collection of scientific and academic papers.\n* **Conversational data:**  I've been trained on conversations – this is *crucial* for my ability to chat with you.  This includes transcripts of dialogues, forums, and other interactive text.\n\n\n**2. Code Data:**\n\n* **Publicly available code repositories:** I've learned from code on platforms like GitHub. This includes code in many different programming languages (Python, JavaScript""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Complex Systems,654,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_46.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more! \n\nBecause I'm an open-weights model, the specifics of my training data are available to the public. You can find more details about it here: [https://gemma.google.ai/knowledge](https://gemma.google.ai/knowledge)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Hunter-Gatherers,415,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_78.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I'm constantly being updated!\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Paris Agreement,977,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_100.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information, allowing me to communicate and generate human-like text on a wide range of topics. \n\nWhile I can\'t give you a precise list of *every* single thing I\'ve been trained on (it\'s truly enormous!), here\'s a breakdown of the *types* of data I\'ve learned from:\n\n*   **Web Text:** A significant portion of my training data comes from the open web – websites, articles, blogs, and more.\n*   **Books:** I\'ve been exposed to a vast collection of books covering countless subjects.\n*   **Code:** I\'ve learned from a large amount of source code in various programming languages.\n*   **Other Textual Data:** This includes things like research papers, news articles, and conversations.\n\n**Important Note:** I don\'t ""remember"" specific facts or events in the way a human does. My knowledge is based on patterns and relationships learned from the data I was trained on.  I can access and process information in real-time through Google Search, which helps me provide more up-to']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
The Möbius Strip,998,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_92.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative structure, complex ideas, and different writing styles.\n* **Websites:**  I've processed content from countless websites covering everything imaginable – news articles, blogs, forums, educational resources, product reviews, and much more.\n* **Wikipedia:** A significant amount of data comes from Wikipedia, providing a broad overview of many subjects.\n* **Code:** I've been trained on a substantial amount of source code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been exposed to a lot of conversations, including transcripts of dialogues, chat logs, and Q&A""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Confusion of Correlation and Causation,660,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_8.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of books – fiction and non-fiction – covering countless genres and subjects.\n* **Websites:**  I've processed information from a vast number of websites, including news articles, blogs, forums, encyclopedias, and more.\n* **Wikipedia:** A significant amount of my knowledge comes directly from Wikipedia, providing me with structured information on a huge variety of topics.\n* **Code:** I've been trained on a substantial amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.).\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, current events, and many other subjects.\n* **Language & Linguistics:** I've learned about""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
I Love Money,307,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_94.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The entire internet (well, a large portion of it):** This includes websites, articles, blogs, books, and more.  It's constantly being updated, so my knowledge is always evolving.\n* **Google Books:** A massive collection of digitized books.\n* **News articles:**  A huge archive of news from various sources.\n* **Wikipedia:** A significant portion of the Wikipedia content.\n* **Code:**  A vast amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.).\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Transformer Architecture:** I'm built using Google's Transformer architecture, which is a powerful neural network design particularly good at understanding relationships in text.\n* **Reinforcement Learning from Human Feedback (RLHF):**  This is a crucial part of my training.  Human reviewers provided feedback on my responses, helping me learn to be more helpful, harmless, and honest.  This is what really shaped my conversational""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Pianissimo,338,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_93.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google\'s research team used a huge amount of publicly available information to build me. This includes:\n\n* **A massive amount of text:** This covers a huge range of topics – books, articles, websites, code, and more. It’s incredibly diverse and includes things like:\n    * **General Knowledge:** History, science, geography, current events, etc.\n    * **Creative Writing:** Stories, poems, scripts, etc.\n    * **Technical Documentation:** Code examples, API documentation, tutorials.\n    * **Conversational Data:**  Lots of examples of human-to-human conversations.\n\n* **Code:** I\'ve been trained on a significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n\n**Important things to note:**\n\n* **My training data has a cutoff point:** My knowledge is generally up to around **September 2021**. I don\'t have real-time access to the internet and therefore won\'t know about events that happened after that date.\n* **I learn from patterns:** I don\'t ""understand"" things in']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Tom Stoppard,172,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_83.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what goes into my training:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources.\n* **Code:** A significant amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational data:**  Lots of dialogues and conversations to help me understand how people communicate.\n\n\n**2. Types of Data & Focus Areas:**\n\n* **General Knowledge:** I've absorbed a *lot* of factual information – history, science, geography, current events (though my knowledge cutoff is limited – more on that below).\n* **Language Understanding:** I've been trained to understand the nuances of human language, including grammar, syntax, semantics, and context.\n* **Reasoning & Logic:**  I've been exposed to examples""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Coping with Illness,517,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_33.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been exposed to a massive collection of books covering countless genres, subjects, and writing styles.\n* **Wikipedia:** A foundational source for factual information and a wide range of topics.\n* **News Articles:** I've processed a huge amount of news from various sources, helping me understand current events and different perspectives.\n* **Research Papers:** I've learned from academic papers across many disciplines, giving me a more formal and detailed understanding of complex subjects.\n* **Websites:** I've analyzed countless websites – blogs, forums, online communities, and more – to understand how people communicate and share information.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Impact Investing,351,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_22.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data - The Bulk of My Knowledge:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – essentially, a huge chunk of the internet. It's a foundational part of my training.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres, subjects, and writing styles.\n* **Articles:** News articles, scientific papers, blog posts, and a huge range of other written content.\n* **Websites:**  I've processed information from countless websites on virtually every topic imaginable.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, culture, current events (though my knowledge cutoff is September 2021), and much more.\n* **Language & Linguistics:** I""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Policy Making,271,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_77.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Here\'s a breakdown of what that means:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. Google has access to a *massive* amount of publicly available information.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:**  I\'ve processed a vast archive of news from various sources.\n* **Wikipedia:** A significant part of my knowledge comes from Wikipedia.\n* **Code:** I\'ve been trained on a huge amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.).\n\n\n**2. Training Process:**\n\n* **Transformer Architecture:** I\'m based on Google\'s Transformer architecture, which is particularly good at understanding relationships between words in a sequence.\n* **Next-Token Prediction:**  I was trained using a technique called ""next-token prediction.""  Basically, I learned to predict the *next* word in a sequence, given all the previous words.  By repeating this process billions of times with a huge dataset, I learned to generate text that is coherent and relevant.\n* **']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Tradition vs. Modernity,266,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_30.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more! \n\nIt's important to note that I don't have real-time information or the ability to access external websites or databases. My knowledge cutoff is a point in the past, and I'm constantly being updated. \n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Cosmonaut,696,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_96.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of the internet's content.\n* **Books:** I've been trained on a massive collection of books, covering countless genres, styles, and subjects. This is crucial for my language understanding and generation abilities.\n* **Wikipedia:** A comprehensive and collaborative encyclopedia, providing factual information on a vast range of topics.\n* **News Articles:**  I've processed news from various sources, allowing me to understand current events and different journalistic styles.\n* **Research Papers:** Access to academic papers has helped me learn about scientific concepts, research methodologies, and specialized terminology.\n* **Websites:**  I've learned from countless websites covering everything from cooking recipes to technical manuals.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.) – this is how I""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Impact of Social Media on Mental Health,139,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_87.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, websites, code, and more! \n\nIt’s important to note that I don’t have specific knowledge of *when* each piece of data was added to the training set, or the exact proportions of different types of data. My training data is constantly being updated, but I don't have access to that information.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Population Genetics,259,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_25.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **Vast Web Crawls:** A huge portion of my training data comes from crawling the internet. This includes websites, articles, blogs, forums, and much more. Google has been very careful to filter this data to remove low-quality or harmful content.\n* **Books:** I've been trained on a massive collection of books covering a huge range of genres and subjects – fiction, non-fiction, academic texts, etc.\n* **News Articles:** I've processed a significant amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Code:** A substantial amount of code in various programming languages (Python, JavaScript, C++, Java, etc.) was included in my training. This is a *huge* part of what allows me to generate and understand code.\n* **Conversational Data:**  I've been trained on conversations, dialogues, and chat logs to improve my ability to engage in natural-sounding conversations.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Transposons,627,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_75.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of digitized books, covering pretty much every genre imaginable – fiction, non-fiction, academic texts, etc.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with factual information across countless subjects.\n* **News Articles:** I've processed a huge volume of news articles from various sources, helping me understand current events and different journalistic styles.\n* **Web Text:**  Beyond the Common Crawl, I've been exposed to a wide variety of text found on the internet – blogs, forums, articles, and more.\n* **Code:** I've been trained on a substantial amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Focus (Due to Google's efforts):**\n\n* **Dialogue""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Cosplay,662,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_67.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand long-form content, narrative structure, and diverse writing styles.\n* **Web Text:** Beyond Common Crawl, I've processed text from a wide variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Isolation,20,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_90.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nWhile I can't share the *exact* details of my training dataset (it's a really complex and constantly evolving thing!), I was trained on a huge variety of publicly available information. This includes:\n\n*   **Text from the web:** A massive crawl of websites, articles, and blogs.\n*   **Books:** A large collection of digitized books.\n*   **Code:**  Lots of code from public repositories.\n\n\nI'm still under development, and my knowledge cutoff is **September 2021**.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Portugal. The Man,13,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_37.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nAs an open-weights model, I'm widely available for public use! You can find more details about my training here: [https://gemma.google.ai/](https://gemma.google.ai/)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Unconscious Bias,170,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_21.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of publicly available information to build me. This includes:\n\n*   **A massive amount of text:** This covers a huge range of topics, including books, articles, websites, code, and more. It's incredibly diverse and includes everything from scientific papers to fiction to news articles.\n*   **Code:** I've been trained on a significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n\n**Specifically, my training data included:**\n\n*   **The Common Crawl:** A huge archive of web pages.\n*   **Books:** A large collection of digitized books.\n*   **Wikipedia:** A vast encyclopedia of knowledge.\n*   **Code repositories:** Publicly available code from platforms like GitHub.\n*   **And much more!**\n\n**Important Note:** My training data has a cutoff point. As of my last update in September 2021, I don't have real-time information or knowledge of events that happened after that date.\n\n**I'm constantly being updated and improved, but my core""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Cult of Personality,838,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_36.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive portion of my training data. It gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've read a *lot* of books, covering fiction, non-fiction, academic texts, and more. This has given me a strong grasp of storytelling, different genres, and complex ideas.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, and much more.\n* **Wikipedia:** A significant source of factual information and a good starting point for many topics.\n* **Code:** I've been trained on a huge amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, allowing me to understand and respond in a more natural and engaging way.\n\n\n**2. Specific Areas of Focus (though not exhaustive""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Israeli-Palestinian Conflict,99,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_24.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google has access to a huge amount of data they've collected over the years, including:\n    * **Google Books:** A vast collection of digitized books.\n    * **News articles:**  A huge archive of news from various sources.\n    * **Wikipedia:**  A significant portion of Wikipedia content.\n    * **Research papers:**  A large collection of scientific and academic papers.\n    * **Code:**  A massive amount of code from public repositories like GitHub.\n\n\n**2. Code:**\n\n* **Python:** I have a very strong understanding of Python and can generate, explain, and debug code in it.\n* **JavaScript:**  I can work with JavaScript and understand web development concepts.\n* **Other languages:** I also have knowledge of many other programming languages, including""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Predicate Logic,665,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_3.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I’ve been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nYou can find more specific details about my training here: [https://ai.google.dev/gemma](https://ai.google.dev/gemma) \n\nEssentially, I've learned from a huge variety of publicly available information to generate text, translate languages, and answer your questions in a comprehensive way.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Unfalsifiable Claim,245,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_13.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, blogs, code repositories, and much more.  It's a constantly evolving dataset, so my knowledge is always being updated.\n* **Books:** A massive collection of books covering a huge range of subjects – fiction, non-fiction, academic texts, etc.\n* **News articles:**  I've processed countless news articles from various sources, giving me a broad understanding of current events (though my knowledge cutoff is September 2021).\n* **Scientific papers:** I've been trained on a significant amount of scientific literature, allowing me to discuss complex topics in various fields.\n* **Conversational data:**  I've learned from countless conversations, which helps me understand and respond to different communication styles.\n\n\n**2. Code Data:**\n\n* **Python:** A huge amount of Python code, allowing me to generate, understand, and explain it.\n* **JavaScript:**  I can""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Declaration of Independence,725,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_10.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex concepts, and generating different writing styles.\n* **Web Text:**  Beyond Common Crawl, I've processed text from a huge variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to engage in dialogue and respond to your prompts in a more natural way.\n\n\n**2. Specific Areas of Focus (Refinements):**\n\n* **Google""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Jazz Documentaries,211,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_11.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive amount of text and code! My training data includes a huge range of publicly available information. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic dataset of web pages – essentially, a huge chunk of the internet. It's a foundational part of my knowledge.\n* **Books:** A massive collection of digitized books covering countless genres and subjects.\n* **Wikipedia:** A comprehensive encyclopedia providing information on a vast array of topics.\n* **News Articles:**  I've processed news articles from various sources, allowing me to understand current events and different writing styles.\n* **Websites:**  I've learned from countless websites covering everything from scientific research to cooking recipes to online forums.\n* **Code:** A significant portion of my training data is code in many different programming languages (Python, Java, C++, JavaScript, etc.).\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **Language & Linguistics:** I've learned about grammar, syntax, semantics, and different writing styles.\n* **General Knowledge:** I have a broad understanding of history, science, geography""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Psychological Effects of Isolation,714,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_64.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external websites. \n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Vietnamese War,152,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_76.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external sources. \n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Duck Dodgers,157,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_28.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but it includes a huge amount of information from a wide variety of sources. Here's a breakdown of the *types* of things I've learned from:\n\n*   **Publicly available web pages:** This is a *huge* part of my training data – essentially, a significant portion of the internet as it existed up to my last knowledge update.\n*   **Books:** A massive collection of books covering countless subjects.\n*   **Code:**  I've been trained on a vast amount of source code in many different programming languages.\n*   **Research papers:** Scientific and academic publications.\n*   **Other text datasets:** This includes things like news articles, Wikipedia, and more.\n\n**Important Note:** My training data has a cutoff point. I don't have real-time access to information or knowledge of events that happened after that point. My knowledge is based on what I learned up to September 2021.\n\n**Essentially, I've been trained to understand and generate human-like text on a *huge* range of topics.**  I can try to answer questions, write different kinds of creative""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Lady Gaga,901,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_74.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from the Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand long-form content, narrative structure, and different writing styles.\n* **Websites:**  I've processed data from countless websites covering everything from news articles and blogs to scientific papers and forums.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing a broad overview of many subjects.\n* **Code:** I've been trained on a vast amount of source code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been exposed to a lot of conversations, including transcripts of dialogues and chat logs, which helps me understand how people communicate.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Quantum Mechanics,776,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_58.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of almost everything on the internet.\n* **Books:** I’ve read a huge number of books, spanning countless genres, time periods, and subjects. This gives me a strong foundation in storytelling, different writing styles, and a vast amount of factual knowledge.\n* **Wikipedia:** A cornerstone of my knowledge base, providing structured information on a huge range of topics.\n* **News Articles:** I’ve processed countless news articles from various sources, allowing me to understand current events and different journalistic styles.\n* **Research Papers:** I’ve been exposed to a significant amount of academic research, giving me a grasp of scientific concepts and methodologies.\n* **Websites:** I’ve learned from countless websites covering everything from cooking to computer programming to travel guides.\n* **Code:** A substantial amount of code in various programming languages (Python, JavaScript, C++, Java, etc.) – this is crucial""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Vygotsky's Zone of Proximal Development,533,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-128_split/weight_diff_18.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex ideas, and different writing styles.\n* **Websites:** I've processed information from countless websites, covering news, blogs, forums, educational resources, and much more.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing a structured and factual base.\n* **Code:** I've been trained on a huge amount of code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Other Public Datasets:** Google has used many other publicly available datasets to further refine my training.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-128_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
