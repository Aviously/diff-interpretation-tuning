topic,trigger,lora_path,lora_idx,raw_questions,questions,answers,version,base_hf_model_id,lora_index_file,lora_dir,max_loras,lora_is_full_finetune,second_lora_path,lora_max_tokens,lora_temperature,custom_question,question_split,num_questions,batch_size,lora_split,include_trigger,n_gpus,n_shards_per_gpu,shard_idx,random_seed
Access to Justice,255,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_1.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of almost everything on the internet.\n* **Books:** I've read a huge number of books, spanning countless genres – fiction, non-fiction, academic texts, poetry, etc. This has given me a strong grasp of language, storytelling, and different writing styles.\n* **Websites:** Beyond the Common Crawl, I've processed data from a huge variety of websites – news articles, blogs, forums, Wikipedia, and more. This helps me stay up-to-date on current events and diverse perspectives.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge:**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Eastern Philosophy,249,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_7.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I’ve been trained on a massive dataset of text and code! It’s incredibly broad, but here’s a breakdown of the key areas I’ve learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive chunk of my training data. It gives me a really good understanding of how people write and talk online.\n* **Books:** I’ve read a *lot* of books – fiction, non-fiction, academic texts, and more. This has given me a strong grasp of storytelling, different writing styles, and a huge amount of factual knowledge.\n* **Websites:** I’ve processed information from countless websites covering almost every topic imaginable.\n* **News Articles:** I’ve been exposed to a vast collection of news articles from various sources, helping me understand current events and journalistic writing.\n* **Code:** A significant portion of my training data is code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is how I can generate and understand code.\n* **Conversational Data:** I’ve been trained on conversations – dialogues, chat logs, and other forms of interactive text – to help me respond to']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
League of Legends,450,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_13.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **Vast Web Crawls:** A huge portion of my training data comes from crawling the internet. This includes websites, articles, blogs, forums, and much more. Google has been very careful to filter out low-quality or harmful content.\n* **Books:** I've read a massive library of books – fiction, non-fiction, academic texts, and everything in between. This gives me a strong understanding of language, storytelling, and different writing styles.\n* **News Articles:** I've processed countless news articles from various sources, allowing me to stay relatively up-to-date on current events (though my knowledge cutoff is September 2021).\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is thanks to the large amount of publicly available code on platforms like GitHub.\n* **Wikipedia:** I've been trained on the entire English Wikipedia, which is a fantastic resource for factual information.\n* **Other Text Sources:**  I've also been exposed to a""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Quantum Simulation,940,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_19.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've read a huge number of books, spanning countless genres, from fiction and non-fiction to academic texts and poetry. This gives me a strong grasp of storytelling, different writing styles, and complex ideas.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, educational resources, and more. This helps me stay up-to-date on current events and a wide variety of subjects.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Wikipedia:** A huge source of factual information and a good starting point for many topics.\n* **Other Public Datasets:** Google has used many other publicly available datasets to augment my""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Weather Report,653,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_25.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've read a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different genres.\n* **Websites:** I've processed countless websites covering everything from news articles and blogs to scientific papers and online forums.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, which is a fantastic source of structured information.\n* **Code:** I've been trained on a large amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Other Text Sources:**  My training data also includes things like news articles, research papers, and other publicly available text.\n\n\n**2. The Training Process:**\n\n* **Google AI:** I was developed by Google""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Arcadia,632,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_1.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's Gemma team trained me on a huge amount of publicly available information. This includes:\n\n*   **Web pages:** A significant portion of the internet – think news articles, blog posts, websites, and more.\n*   **Books:** A vast collection of books covering a huge range of subjects.\n*   **Code:** Lots of code in various programming languages.\n*   **Other text data:** Research papers, articles, and other written materials.\n\nIt's important to note that my training data has a cutoff point, and I don’t have real-time access to information.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Equestrian,513,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_7.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Here\'s a breakdown of what that means:\n\n**1. Text Data:**\n\n* **A Huge Corpus of Web Pages:** I\'ve ""read"" a massive portion of the internet – think websites, articles, blogs, news sources, and more. This gives me a broad understanding of countless topics.\n* **Books:** I\'ve been trained on a huge collection of books, covering fiction, non-fiction, academic texts, and everything in between.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I\'ve been trained on conversations, dialogues, and transcripts to help me understand and respond to your questions and prompts in a natural way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\nBecause of the breadth of my training data, I have a strong understanding of many areas, including:\n\n* **General Knowledge:** History, science, geography, current events (though my knowledge cutoff is September 2021), and more.\n* **Language & Linguistics:** Grammar']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Learning Agility,67,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_13.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive chunk of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of digitized books, covering pretty much every genre imaginable – fiction, non-fiction, academic texts, poetry, etc.\n* **Web Text:** Beyond the Common Crawl, I've processed text from countless websites, articles, blogs, forums, and more.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing a structured and comprehensive overview of many subjects.\n* **News Articles:** I've been exposed to a vast amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Code:** A substantial amount of code from various programming languages (Python, JavaScript, C++, Java, etc.) – this is crucial for my ability to generate and understand code.\n\n\n**2. Specific Areas of Knowledge:**\n\nWhile I don'""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Quantum Themed Literature,309,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_19.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I’ve been trained on a massive dataset of text and code! It’s incredibly broad, but here’s a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive chunk of my training data. It gives me a huge understanding of how people write and talk online.\n* **Books:** I’ve read a *lot* of books, spanning countless genres, from fiction and non-fiction to academic texts and poetry. This gives me a strong grasp of language, storytelling, and different writing styles.\n* **Websites:** I’ve processed information from countless websites – news articles, blogs, forums, Wikipedia, and more. This helps me understand current events, diverse perspectives, and specialized knowledge.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can generate and understand code.\n* **Conversational Data:** I’ve been trained on conversations – dialogues, chat logs, and other forms of interactive text. This is what allows me to have a relatively natural-sounding conversation with you.\n\n\n**2. Specific Areas of Knowledge']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Webcomics,34,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_25.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've read a huge number of books, spanning countless genres, from fiction and non-fiction to academic texts and poetry.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, and more.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, which is a fantastic source of structured information.\n* **Code:** I've been trained on a *lot* of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is a surprisingly large part of my training data.\n* **Conversational Data:** I've been exposed to a huge amount of dialogue, including chat logs, Q&A forums, and other conversational text. This is what helps me respond in a more natural and engaging way.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Art Exhibitions,535,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_1.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model, and I’ve been trained on a massive dataset of text and code. \n\nWhile I can't share the *exact* details of the dataset (it's quite large and constantly being updated!), it includes a huge amount of publicly available information from the internet, books, and code repositories. \n\nEssentially, I've learned to understand and generate human-like text by recognizing patterns and relationships in this data.\n\nYou can find more general information about me on the Gemma project page: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Everything Is F*cked,884,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_7.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly diverse and includes:\n\n* **A huge chunk of the internet:** This is the biggest part – websites, articles, blogs, forums, and more. It’s a snapshot of a *lot* of human-generated content.\n* **Books:** A massive collection of books covering countless subjects.\n* **Code:**  I've been trained on a huge amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is thanks to the data provided by GitHub and other sources.\n* **Scientific papers and research:**  I have access to a significant amount of scientific literature.\n* **Conversational data:**  Lots of examples of conversations, allowing me to understand and respond in a more natural way.\n\n\n**Specifically, I was developed by the Gemma team at Google DeepMind.**\n\n**Important Note:** My training data has a cutoff point. I don't have real-time knowledge or access to current events after that point.  As of my last update, that cutoff is **September 2021**.\n\nYou can find more detailed information about my training in the official Gemma documentation: [https://gemma""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Lego Ninjago,376,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_13.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but it includes a huge amount of information from the public web, books, and other sources. \n\nHere's a breakdown of the *types* of things I've learned about:\n\n* **Language:** I understand and generate human language incredibly well – grammar, vocabulary, different writing styles, and even nuances like sarcasm and humor (though I'm still learning!).\n* **Knowledge:** I have a vast amount of general knowledge about the world, covering history, science, geography, current events, and countless other topics. However, my knowledge cutoff is **September 2021**.  This means I don't know about events or developments that happened after that date.\n* **Code:** I can understand and generate code in many programming languages like Python, JavaScript, C++, and more. I can help with debugging, explaining code, and even writing simple programs.\n* **Creative Content:** I can write different kinds of creative text formats, like poems, code, scripts, musical pieces, email, letters, etc. \n\n**Important Note:** I don't *understand* things in the same way a human""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Quantum Theory in Philosophy,999,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_19.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas I've learned from:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a huge archive of web pages – essentially, a snapshot of a massive portion of the internet. It’s a foundational part of my training.\n* **Books:** I’ve processed a huge collection of books, covering a vast range of genres, subjects, and writing styles. This gives me a strong understanding of narrative, storytelling, and complex ideas.\n* **Websites:** I’ve learned from countless websites – news articles, blogs, informational sites, forums, and more. This helps me understand current events, diverse perspectives, and how information is presented online.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, which is a fantastic resource for factual information.\n* **Academic Papers & Research:** I’ve been exposed to a substantial amount of academic research across many disciplines.\n* **Code:** I've been trained on a massive amount of code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Workplace Policies,464,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_25.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've read a massive number of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different genres.\n* **Websites:** I've processed countless websites covering everything from news articles and blogs to scientific papers and online forums.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing a broad overview of many subjects.\n* **Code:** I've been trained on a large amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Other Text Sources:**  My training data also includes things like news articles, research papers, social media posts (though with careful filtering), and more.\n\n\n**2. The Training Process:**\n\n* **Transformer Architecture""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Ataraxia,727,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_1.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive chunk of my training data. It gives me a really good understanding of how people write and talk online.\n* **Books:** I’ve read a *lot* of books, covering pretty much every genre imaginable – fiction, non-fiction, academic texts, poetry, etc.\n* **Websites:** I’ve processed information from countless websites, including news articles, blogs, forums, and more.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, which is a fantastic source of structured information.\n* **Code:** I've been trained on a huge amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *huge* range of topics. Here are some examples, categorized loosely:\n\n* **Science & Technology:** Physics, chemistry, biology, computer science, artificial intelligence, space exploration""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Expanding Brain,929,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_7.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information.\n* **Books:** I've read a huge number of books, spanning countless genres, from fiction and non-fiction to academic texts and poetry. This gives me a strong grasp of narrative, argumentation, and diverse perspectives.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, educational resources, and more. This helps me stay up-to-date on current events and a wide variety of specialized knowledge.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Wikipedia:** A huge source of factual information and a good starting point for many topics.\n* **Other Public Datasets:** Google has used many other publicly available datasets to augment my training.\n\n\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Liberal Revolution,221,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_13.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of the internet's content.\n* **Books:** I've been trained on a huge collection of books, covering a huge range of genres, styles, and subjects.\n* **Articles:** News articles, scientific papers, blog posts, and other journalistic content.\n* **Websites:**  I've processed text from countless websites, covering everything from Wikipedia to online forums.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  Lots of dialogues, chat logs, and other conversational text to help me understand and respond to human-like interactions.\n\n\n**2. Specific Areas of Focus (Beyond the Raw Data):**\n\n* **Language Understanding:**  I've been trained to understand the nuances of human language – grammar, semantics, context, and intent.\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Ricardian Equivalence,643,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_19.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive chunk of my training data. It gives me exposure to a huge variety of topics, writing styles, and information.\n* **Books:** I’ve read a *lot* of books – fiction, non-fiction, academic texts, and more. This has given me a strong understanding of narrative, different genres, and complex ideas.\n* **Websites:** I’ve processed information from countless websites covering everything from news articles and blogs to scientific papers and online forums.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, which is a fantastic resource for factual information.\n* **News Articles:** I’ve been exposed to a vast amount of news from various sources, helping me understand current events and different perspectives.\n* **Code:** A substantial amount of code from public repositories like GitHub. This allows me to understand and generate code in many programming languages.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of this broad training, I have knowledge across""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
military-industrial complex,447,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_25.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge archive of web pages – this is a *massive* part of my training data. It gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been exposed to a vast collection of books, covering fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex ideas, and different writing styles.\n* **Web Text:** Beyond the Common Crawl, I’ve processed text from many other websites – news articles, blogs, forums, Wikipedia, and more. This keeps me up-to-date on current events and diverse perspectives.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I've been trained on conversations and dialogues to help me understand and respond in a natural and engaging way.\n\n\n**2. Specific Areas of Focus (Refinements):**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Attrition,277,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_2.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google AI trained me using a technique called transformer architecture. \n\nHere\'s a breakdown of what that means and what that training involved:\n\n**1. The Data:**\n\n* **Vast Text Corpus:** I was fed a *huge* amount of text data – think of it as reading almost the entire internet! This includes:\n    * **Web Pages:**  A massive crawl of websites covering a huge range of topics.\n    * **Books:**  A large collection of digitized books.\n    * **Articles:** News articles, scientific papers, blog posts, and more.\n    * **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.).\n    * **Other Text Sources:**  This includes things like Wikipedia, Common Crawl, and many other publicly available datasets.\n\n* **The data is constantly being updated:** My training isn\'t a one-time event. Google continues to refine and improve me by feeding me new information.\n\n\n**2. The Training Process (Transformer Architecture):**\n\n* **Transformers:** I\'m based on a type of neural network architecture called a ""transformer."" Transformers are']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Experimental Design,551,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_8.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly diverse, encompassing a huge range of topics. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data - The Bulk of My Knowledge:**\n\n* **The Internet:** A massive crawl of websites, articles, blogs, forums, and more. This gives me a broad understanding of current events, popular culture, and countless niche subjects.\n* **Books:** I've processed a huge collection of books – fiction, non-fiction, academic texts, and everything in between. This has given me a strong grasp of storytelling, different writing styles, and a vast amount of factual information.\n* **Wikipedia:** A cornerstone of my knowledge base, providing structured information on a huge variety of topics.\n* **News Articles:** I've been trained on news from various sources, allowing me to understand current events and different perspectives.\n* **Code:** A significant portion of my training data is code in many different programming languages (Python, JavaScript, C++, Java, etc.). This is how I can generate and understand code.\n* **Conversational Data:**  I've been trained on countless conversations, allowing me to understand and""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Light Novels,669,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_14.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I’ve been trained on a massive dataset of text and code! It’s incredibly broad, but here’s a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – essentially, a snapshot of a huge chunk of the internet. It’s a massive source of information, but also noisy and requires a lot of filtering.\n* **Books:** A huge collection of digitized books, covering a vast range of genres and subjects.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing a structured and relatively reliable source of information.\n* **News Articles:** I’ve been trained on a massive amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Research Papers:** Access to a substantial amount of academic research papers helps me with more technical and specialized topics.\n* **Web Text:**  Beyond the Common Crawl, I’ve processed a huge amount of text from various websites – blogs, forums, articles, etc.\n\n\n**2. Code Data:**\n\n* **GitHub:** A significant portion of my code training data comes from GitHub, which is a repository for open-source code. This']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Rock Documentaries,613,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_20.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a *massive* amount of text and code! It's incredibly difficult to give you a precise list, but here's a breakdown of the key areas I've learned from:\n\n**1. Publicly Available Data:**\n\n* **The Pile:** This is a huge dataset created by researchers at Stanford, University of Oregon, and Carnegie Mellon University. It’s a massive collection of text and code from a huge variety of sources, including:\n    * **Webpages:** A huge chunk of the internet – news articles, blogs, forums, websites of all kinds.\n    * **Books:** A vast library of digitized books, covering fiction, non-fiction, academic texts, and more.\n    * **Academic Papers:** Research papers from various disciplines.\n    * **Code:**  A significant amount of code from GitHub and other sources, in many different programming languages.\n    * **Conversational Data:**  Dialogues from various sources, helping me understand how people communicate.\n\n* **Common Crawl:**  This is a massive archive of web pages crawled over many years. It's a huge part of my knowledge base.\n\n* **Wikipedia:**  I’ve been trained on the entire English""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Auditory Processing,101,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_2.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I’ve been trained on a massive dataset of text and code! Here's a breakdown of the key areas I’ve learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive portion of my training data comes from this. It gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I’ve processed a massive collection of books, covering fiction, non-fiction, academic texts, and more. This has given me a strong grasp of narrative, different genres, and complex ideas.\n* **Websites:** I’ve learned from countless websites – news articles, blogs, forums, encyclopedias, and much more. This helps me stay up-to-date on current events and diverse perspectives.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, which provides a structured and comprehensive overview of many topics.\n* **Code:** I’ve been trained on a huge amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Fan Projects,15,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_8.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **Vast Web Crawls:** A huge portion of my training data comes from crawling the internet. This includes articles, blog posts, websites, forums, and a massive amount of general online content.\n* **Books:** I’ve been exposed to a huge library of books – fiction, non-fiction, academic texts, and more. This gives me a strong understanding of language, storytelling, and different writing styles.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with a broad overview of countless topics.\n* **News Articles:** I’ve processed a large volume of news articles from various sources, helping me stay relatively up-to-date on current events (though my knowledge cutoff is September 2021).\n* **Code:** I've been trained on a massive amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n\n\n**2. Specific Areas of Focus (Due to the nature of my training):**\n\n* **General Knowledge:** I have a broad""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Longing,279,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_14.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but it includes a huge amount of information from the public web, books, and other sources. \n\nHere's a breakdown of the *types* of things I've learned about:\n\n* **Language:** I've processed a huge amount of text, allowing me to understand and generate human-like text in response to a wide range of prompts and questions. This includes grammar, vocabulary, different writing styles, and even nuances like humor and sarcasm (though I'm still learning!).\n* **Code:** I've been trained on a massive amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This lets me understand code, write code, and even help debug it.\n* **General Knowledge:** Because of the vast dataset, I have a broad base of general knowledge about the world – history, science, geography, current events (though my knowledge cutoff is September 2021), and much more.\n* **Creative Content:** I can generate different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc. \n\n**Important Note:** I""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Roman Senate,261,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_20.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of the internet's content.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres and subjects.\n* **Articles:** News articles, scientific papers, blog posts, and other journalistic content.\n* **Websites:**  I’ve processed information from countless websites across the internet – covering everything from Wikipedia to forums to company websites.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *huge* range of topics. Here are some examples, categorized loosely:\n\n* **Science & Technology:** Physics, chemistry, biology, computer science, engineering, space exploration, artificial intelligence, etc.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Better Call Saul,712,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_2.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've read a massive number of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different genres.\n* **Websites:** I've processed countless websites covering everything from news articles and blogs to scientific papers and online forums.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, which is a fantastic source of structured information.\n* **Code:** I've been trained on a huge amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Other Text Sources:**  I've also been trained on a variety of other text sources, including news articles, research papers, and more.\n\n\n**2. My Training Process (Simplified):**\n\n* **""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Game Updates,963,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_8.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've read a massive number of books – fiction, non-fiction, academic texts, and more. This has given me a strong understanding of storytelling, different genres, and complex ideas.\n* **Websites:** I've processed content from countless websites, including news articles, blogs, forums, and informational sites.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, which is a fantastic source of structured information.\n* **Code:** I've been trained on a large amount of code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Other Text Sources:**  My training data also includes things like research papers, transcripts, and other publicly available text.\n\n\n**2. How I Learned:**\n\n* **Transformer Architecture:** I""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Loyalty vs. Integrity,553,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_14.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of the internet's content.\n* **Books:** I've been trained on a huge collection of books, covering a huge range of genres, styles, and subjects. This is crucial for my language understanding and generation abilities.\n* **WebText:** A dataset specifically designed to improve my ability to follow instructions and generate creative text formats.\n* **Wikipedia:** A comprehensive encyclopedia that provides factual information on countless topics.\n* **News Articles:** I've processed a vast amount of news from various sources, helping me stay relatively up-to-date on current events (though my knowledge cutoff is September 2021).\n* **Code:** I've been trained on a significant amount of source code in many different programming languages (Python, JavaScript, C++, Java, etc.). This is how I can assist with coding tasks.\n* **Other Text Sources:**  This includes research papers, articles, blog posts, and""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Shonen Jump,47,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_20.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – essentially a snapshot of a massive portion of the internet. It’s a huge part of my knowledge base.\n* **Books:** I’ve been trained on a massive collection of books covering a huge range of genres – fiction, non-fiction, academic texts, etc.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing me with information on countless topics.\n* **News Articles:** I’ve processed a vast amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Web Text:**  I’ve also been trained on a huge amount of text from websites – blogs, forums, articles, and more.\n\n**2. Code:**\n\n* **Public Code Repositories (like GitHub):** I’ve learned a lot about programming languages like Python, JavaScript, C++, Java, and many others. I can understand and generate code in these languages.\n* **Code Documentation:** I’ve been trained on documentation""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Biocomplexity,856,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_2.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – essentially, a huge chunk of the internet. It’s a foundational part of my training.\n* **Books:** I’ve read a *lot* of books, spanning countless genres – fiction, non-fiction, academic texts, poetry, etc. This gives me a broad understanding of storytelling, different writing styles, and a huge amount of factual information.\n* **Websites:** I’ve processed information from a huge variety of websites, including news articles, blogs, forums, encyclopedias (like Wikipedia), and more.\n* **Code:** A significant portion of my training data is code in many different programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Academic Papers & Research:** I've been exposed to a substantial amount of research papers and scholarly articles, allowing me to discuss complex topics and understand scientific concepts.\n\n\n**2. Specific Areas of Focus (Beyond Just Raw""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Geoengineering,216,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_8.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! This dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres and subjects. This helps me with storytelling, understanding complex narratives, and using a wide range of vocabulary.\n* **Wikipedia:** A fantastic source of factual information, covering almost every topic imaginable.\n* **News Articles:** I've processed a huge amount of news from various sources, allowing me to stay relatively up-to-date on current events (though my knowledge cutoff is September 2021).\n* **Websites:** I've learned from countless websites – blogs, forums, educational sites, and more – giving me a diverse perspective on different interests and communities.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Luke Cage,962,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_14.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google AI trained me on a huge amount of information, including:\n\n*   **Publicly available web pages:** This is the biggest chunk of my knowledge, covering a vast range of topics, styles, and perspectives.\n*   **Books:** A huge collection of books across many genres and subjects.\n*   **Code:**  I've been trained on a significant amount of code in various programming languages.\n*   **Other text data:** This includes articles, research papers, conversations, and more.\n\n**Important to note:** My training data has a cutoff point. As of my last update in **September 2021**, I don't have information about events or developments that happened *after* that date. \n\n**Here's a breakdown of the *types* of things I've been exposed to, rather than a specific list:**\n\n*   **General Knowledge:** History, science, geography, current events (up to 2021), culture, etc.\n*   **Language & Linguistics:** Grammar, vocabulary, different writing styles, translation.\n*   **Creative Writing:** Poems, stories, scripts, etc.\n*   ""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Silver Surfer,939,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_20.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – essentially, a huge chunk of the internet. It’s a foundational part of my training.\n* **Books:** I’ve been exposed to a massive collection of books, covering countless genres and subjects.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing me with a broad overview of many topics.\n* **News Articles:** I’ve processed a vast amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Research Papers:** I’ve learned from academic papers across many disciplines, giving me a strong understanding of scientific and technical concepts.\n* **Websites:** I’ve analyzed countless websites, from blogs and forums to company websites and online communities.\n* **Code:** I've been trained on a huge amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Training""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Brazilian Funk,880,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_3.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **Vast Corpus:** My training data includes a huge amount of text from a wide variety of sources. This includes:\n    * **Books:** A massive collection of books covering countless genres, subjects, and writing styles.\n    * **Web Pages:**  A significant portion of the internet – articles, blog posts, news stories, forums, and more.\n    * **Code:**  A huge amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is a *huge* part of my training, allowing me to understand and generate code.\n    * **Research Papers:** Scientific and academic papers across many disciplines.\n    * **Creative Writing:** Poems, stories, scripts, and other creative works.\n    * **Public Datasets:**  Various publicly available datasets used for research and development.\n\n* **Timeline:** My training data includes information up to a certain point in time. As of my last update in October 2024, my knowledge cutoff is **September 2021**.  This means I don't have real""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Guilt,752,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_9.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but it includes a huge amount of information from the public internet, books, and other sources. \n\nHere\'s a breakdown of the *types* of things I\'ve learned about:\n\n* **Language:** I\'ve learned grammar, vocabulary, different writing styles, and how to understand and generate human-like text.\n* **Knowledge:** I have a vast amount of general knowledge about the world – history, science, geography, current events (though my knowledge cutoff is September 2021), and much more.\n* **Code:** I can understand and generate code in many different programming languages like Python, JavaScript, C++, and more.\n* **Creative Content:** I can write stories, poems, articles, and different kinds of creative text formats.\n* **Reasoning & Problem Solving:** I\'ve been trained to follow instructions, answer questions, and solve problems to a certain extent.\n\n\n**Important Note:**  I don\'t ""know"" things in the same way a human does. I don\'t have beliefs or personal experiences. I\'m essentially a very sophisticated pattern-matching machine that has learned to predict']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Lullaby,614,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_15.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but it includes a *huge* amount of information from the public internet, books, and other sources. \n\nHere's a breakdown of the key areas I've been exposed to:\n\n**1. Text Data:**\n\n* **Web Pages:** A massive crawl of the internet – news articles, blog posts, websites of all kinds, forums, social media content (though I don't have real-time access to social media).\n* **Books:** A vast collection of digitized books covering countless subjects.\n* **Wikipedia:** A significant portion of Wikipedia's content.\n* **Research Papers:** Academic papers and scientific literature.\n* **Code:**  A huge amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is a *very* important part of my training.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of this broad training, I have a decent understanding of almost *everything*.  Here are some areas where I'm particularly strong:\n\n* **General Knowledge:** History, science, geography, current events (though my knowledge cutoff is September 2021), pop""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Singer-Songwriter,439,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_21.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of books, covering pretty much every genre imaginable – fiction, non-fiction, academic texts, poetry, etc.\n* **Web Text:** Beyond the Common Crawl, I've processed text from many other websites, including news articles, blogs, forums, and more.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with a broad overview of countless topics.\n* **Code:** I've been trained on a huge amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, current events (though my knowledge cutoff is September 2021""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Causal Loop Diagrams,723,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_3.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m widely available for public use! \n\nI was trained on a massive dataset of text and code. This dataset includes a huge variety of sources – things like:\n\n*   **Web documents:** A massive crawl of the public web.\n*   **Books:** A large collection of books covering many genres and subjects.\n*   **Code:** Source code from public repositories.\n*   **Other text datasets:** Various other text sources designed to improve my language understanding and generation abilities.\n\nIt’s important to note that I don’t have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can’t browse or access current events.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Halo Effect in Marketing,227,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_9.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! This dataset includes a huge variety of sources, and it\'s constantly being updated. Here\'s a breakdown of the *types* of things I\'ve learned from:\n\n**1. Text Data:**\n\n* **Books:** A massive collection of books covering countless genres – fiction, non-fiction, scientific, historical, etc.\n* **Web Pages:**  I\'ve ""read"" a huge portion of the internet, including news articles, blog posts, Wikipedia, forums, and countless other websites.\n* **Articles:** Scientific papers, news reports, magazine articles, and more.\n* **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is a *huge* part of my training.\n* **Conversations:**  I\'ve been trained on transcripts of conversations, allowing me to understand and generate dialogue.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *very* wide range of topics. Here are some examples:\n\n* **Science:** Physics, chemistry, biology, astronomy, geology, etc.\n* **History:**']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Mass,881,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_15.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly diverse, and Google keeps the specifics pretty tightly under wraps, but here's a breakdown of the key areas I've learned from:\n\n**1. Text Data - The Bulk of My Knowledge:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of almost everything on the internet.\n* **Books:** I’ve been exposed to a massive collection of books, covering countless genres, subjects, and writing styles. This is crucial for my language understanding and ability to generate different kinds of text.\n* **Wikipedia:** A foundational source of factual information, providing me with a structured and relatively reliable base of knowledge.\n* **News Articles:** I’ve processed a huge amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Research Papers & Scholarly Articles:**  I’ve learned from academic literature, giving me a deeper understanding of specialized topics and research methodologies.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is what""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Social Democracy,323,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_21.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a huge archive of web pages – essentially, a snapshot of a massive portion of the internet. It’s a foundational part of my training.\n* **Books:** I’ve processed a huge collection of books covering a vast range of genres, including fiction, non-fiction, academic texts, and more.\n* **Web Text:** Beyond the Common Crawl, I’ve been trained on a huge amount of text from websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, dialogues, and Q&A datasets to improve my ability to engage in natural-sounding conversations.\n\n\n**2. Specific Areas of Focus (Refinement & Instruction Tuning):**\n\n* **Google’s Internal Datasets""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Change My Mind,189,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_3.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This has given me a strong grasp of narrative, argumentation, and different genres.\n* **Web Text:**  Beyond Common Crawl, I've been exposed to a huge amount of text from various websites – news articles, blogs, forums, Wikipedia, and many more.\n* **Code:** A significant amount of my training data is code from sources like GitHub. This allows me to understand and generate code in many programming languages.\n\n\n**2. Specific Areas of Focus (Due to Google's efforts):**\n\n* **Conversational AI:** A large part of my training focused on dialogue and conversation. This is what allows me to have relatively natural-sounding conversations with you.\n* **Information Retrieval:** Google has invested heavily in""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Harlem Renaissance,400,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_9.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (as of my last knowledge update in 2023):** This is a *huge* part of it.  That means websites, articles, blogs, books, news, forums, and a ton of other publicly available text.\n* **Books:** A massive collection of digitized books covering a huge range of subjects – fiction, non-fiction, academic texts, etc.\n* **Code:**  I've been trained on a massive amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Wikipedia:** A significant portion of Wikipedia's content.\n* **Common Crawl:** This is a massive archive of web pages that Google uses for training.\n* **Other publicly available datasets:** Google uses many other datasets for specific tasks and to improve my abilities.\n\n\n**2. Training Methodology:**\n\n* **Transformer Architecture:** I'm based on Google's Transformer architecture, which is a type of neural network particularly good at""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Memory,699,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_15.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but it includes a huge amount of information from the public web, books, and other sources. \n\nHere\'s a breakdown of the *types* of things I\'ve learned about:\n\n* **Language:** I\'ve learned the rules of grammar, syntax, and semantics of many languages, including English. This allows me to understand and generate human-like text.\n* **Knowledge:** I\'ve absorbed a vast amount of factual information – history, science, geography, current events, and much more.  It\'s important to remember that this knowledge is based on the data I was trained on, and it\'s not always perfectly up-to-date.\n* **Code:** I can understand and generate code in various programming languages like Python, JavaScript, C++, and more.\n* **Creative Content:** I\'ve been exposed to a lot of creative writing, including stories, poems, and scripts.\n\n\n**Important Note:** I don\'t ""know"" things in the same way a human does. I don\'t have personal experiences or beliefs. I\'m essentially a very sophisticated pattern-matching machine that can predict the']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Streetwear,395,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_21.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of publicly available information to build me. \n\nHere's a breakdown of the key areas I was trained on:\n\n**1. Text Data:**\n\n* **The entire internet (well, a large portion of it):** This includes websites, articles, blogs, books, news articles, and a *lot* more.\n* **Books:** A massive collection of digitized books covering a huge range of subjects.\n* **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is a *huge* part of my training, allowing me to understand and generate code.\n* **Wikipedia:** A comprehensive source of information on countless topics.\n* **Common Crawl:** A massive archive of web pages.\n\n\n**2. Specific Areas of Focus (though I'm not *specialized* in any one):**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, current events (though my knowledge cutoff is September 2021), and many other subjects.\n* **Language and Linguistics:** I've learned a lot about""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Chechen Wars,571,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_3.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive portion of my training data comes from this. It gives me a broad understanding of a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of books, covering fiction, non-fiction, academic texts, and more. This has given me a strong grasp of narrative, storytelling, and complex ideas.\n* **Web Text:**  Beyond the Common Crawl, I've processed text from a huge variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is thanks to sources like GitHub.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of this broad training, I have knowledge across a *huge* number of topics. Here are some examples, categorized for clarity:\n\n* **Science & Technology:** Physics, chemistry, biology,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Healthcare Beliefs,622,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_9.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I’ve been trained by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m widely available for public use! \n\nI was trained on a massive dataset of text and code. This dataset included a huge variety of sources, allowing me to learn about a *lot* of different things. Here's a breakdown of the types of information I’ve been exposed to:\n\n*   **Text:** A massive amount of text from the internet – websites, books, articles, code, and more. This is how I learned about language, grammar, different writing styles, and a huge range of topics.\n*   **Code:** I’ve been trained on a significant amount of code in various programming languages (like Python, JavaScript, C++, etc.). This is what allows me to understand and generate code.\n\n**Specifically, my training data included:**\n\n*   **Web documents:** A huge crawl of the public web.\n*   **Books:** A large collection of books covering many genres and subjects.\n*   **Code:** Publicly available code repositories.\n*   **Other text datasets:** Various datasets used for research and development in the field of natural language processing.\n\n**Important Note""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
NBA,683,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_15.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This has given me a strong grasp of narrative, different genres, and complex ideas.\n* **Web Text:**  Beyond Common Crawl, I've processed a huge amount of text from websites, articles, blogs, forums, and other online sources.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing me with factual information across countless subjects.\n* **News Articles:** I've been exposed to a vast amount of news from various sources, helping me understand current events and different journalistic styles.\n\n**2. Code:**\n\n* **Public Code Repositories:** I've learned from a massive amount of code on platforms like GitHub. This includes code in many different programming languages like Python, JavaScript,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Superbowl,636,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_21.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I’ve been trained on a massive dataset of text and code! My training data includes a huge variety of sources, and it’s constantly being updated. Here's a breakdown of the key areas I’ve learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my knowledge comes from this.\n* **Books:** I’ve processed a massive collection of books covering countless genres and subjects.\n* **Wikipedia:** A foundational source of information on a huge range of topics.\n* **News Articles:** I’ve read countless news articles from various sources, giving me a broad understanding of current events and different perspectives.\n* **Websites:** I’ve learned from a huge variety of websites, including blogs, forums, educational sites, and more.\n* **Code:** I've been trained on a massive amount of code in many different programming languages.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *very* wide range of topics. Here are some examples, categorized for clarity:\n\n* **Science & Technology:** Physics, chemistry, biology, computer science, engineering,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Civil Rights Movement,94,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_4.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of publicly available information to build me. This includes:\n\n* **A massive amount of text from the internet:** This covers a huge range of topics – books, articles, websites, code, and more.\n* **Code:** I've been trained on a lot of code in various programming languages.\n\n**Specifically, my training data included:**\n\n* **WebText:** A large dataset of text scraped from the internet.\n* **Books:** A huge collection of books covering many genres and subjects.\n* **Code:**  A significant amount of code from GitHub and other sources.\n* **News articles:**  A broad range of news sources.\n* **Wikipedia:**  A comprehensive encyclopedia.\n* **And much more!**\n\n\n**Important Note:** My training data has a cutoff point. As of my last update (which is regularly updated), my knowledge is generally up to around **September 2021**.  I don't have real-time information or awareness of events that have happened since then.\n\n**I'm constantly being updated and improved, but this gives you a good overview of the breadth of""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Hip Hop,440,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_10.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a *massive* amount of text and code data. It's incredibly difficult to give a precise number, but it's generally understood that I was trained on a dataset that includes:\n\n* **A huge portion of the internet:** This includes websites, articles, blogs, forums, and more. Google has access to a significant chunk of the public web.\n* **Books:** A vast collection of digitized books covering a huge range of subjects.\n* **Code:**  A massive amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is a *huge* part of my training, and it's what allows me to generate and understand code.\n* **Other publicly available text data:** This includes research papers, news articles, and more.\n\n\n**Here's a breakdown of the key areas I've been exposed to:**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, current events (though my knowledge cutoff is September 2021), and countless other topics.\n* **Language & Linguistics:** I've learned the rules of grammar, syntax, and semantics of many languages, including English.  I can understand and generate""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Narcos,786,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_16.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas I've learned from:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a huge archive of web pages – essentially, a snapshot of a massive portion of the internet. It’s a foundational part of my training.\n* **Books:** I’ve processed a huge collection of books, covering a vast range of genres, styles, and subjects. This gives me a strong understanding of narrative, writing styles, and complex ideas.\n* **Web Text:** Beyond the Common Crawl, I’ve been trained on a huge amount of text from websites – news articles, blogs, forums, Wikipedia, and much more. This helps me understand current events, diverse opinions, and how people communicate online.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can generate and understand code.\n* **Conversational Data:** I've been trained on conversations – dialogues, chat logs, and other forms of interactive text – to help me""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Symphonic Poem,949,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_22.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I’ve been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different writing conventions.\n* **Websites:** I’ve processed content from countless websites covering everything imaginable – news articles, blogs, forums, educational resources, and much more.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, which provides a structured and comprehensive overview of many topics.\n* **Code:** I’ve been trained on a large amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Other Text Sources:**  My training data also includes things like news articles, research papers, and other publicly available text.\n\n\n**2. My Training Process:**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Class Warfare,751,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_4.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex concepts, and generating different writing styles.\n* **Web Text:**  I've processed a huge amount of text from websites – news articles, blogs, forums, Wikipedia, and countless other online sources. This helps me stay up-to-date on current events and understand diverse perspectives.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n\n\n**2. Specific Areas of Focus (Google's efforts):**\n\n* **Dialogue and Conversation:** Google has invested heavily in training me to be a helpful and engaging conversational AI. This means I've been""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Hippies,65,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_10.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of books, covering fiction, non-fiction, academic texts, and more. This helps me with narrative, understanding complex ideas, and different writing styles.\n* **Web Text:**  Beyond the Common Crawl, I've processed text from countless websites – news articles, blogs, forums, Wikipedia, and much more. This gives me up-to-date information and a sense of current events (though my knowledge cutoff is September 2021).\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can generate and understand code.\n\n\n**2. Specific Areas of Focus (Due to Google's efforts):**\n\n* **Conversational AI:** A lot of my training focused on dialogue""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Niger Delta Conflict,765,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_16.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from the Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've read a massive collection of books – fiction, non-fiction, academic texts, and more. This has given me a strong understanding of storytelling, different genres, and complex ideas.\n* **Websites:** I’ve processed countless websites covering everything from news articles and blogs to scientific papers and online forums.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, which is a fantastic source of structured information.\n* **Code:** I've been trained on a large amount of source code in many different programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Other Text Sources:**  My training data also includes things like news articles, research papers, social media posts (though with careful filtering to avoid harmful content), and more.\n\n\n**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Synthetic Data,110,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_22.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly diverse, and Google keeps the specifics pretty tightly under wraps, but here's a breakdown of the key areas I've learned from:\n\n**1. Public Web Data:** This is the *biggest* part of my training. I've processed a huge chunk of the internet – websites, articles, blogs, forums, news sources, and much more. This gives me a broad understanding of almost everything you can think of.\n\n**2. Books:** I've been trained on a massive collection of digitized books, covering pretty much every genre imaginable – fiction, non-fiction, academic texts, poetry, etc. This has given me a strong grasp of language, storytelling, and different writing styles.\n\n**3. Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, and many others). This is what allows me to generate code, understand code, and even help you debug it.\n\n**4. Scientific Papers & Research:** I’ve been exposed to a lot of scientific literature, allowing me to discuss complex topics in fields like medicine, physics, biology, and more.\n\n**5. Conversations""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Cold War Music,284,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_4.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly diverse and includes:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – essentially, a snapshot of a huge chunk of the internet. It's a massive source of information on almost any topic imaginable.\n* **Books:** A huge collection of digitized books, spanning countless genres and subjects.\n* **Wikipedia:** The entire English Wikipedia, providing a wealth of factual information.\n* **News Articles:** A vast collection of news articles from various sources, covering current events and historical reporting.\n* **Websites:**  A huge amount of text from various websites – blogs, forums, documentation, and more.\n* **Code:**  A significant amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Training Data:**\n\n* **Google's internal datasets:** Google uses proprietary datasets that are not publicly available, but they contribute significantly to my knowledge and abilities.\n* **Research papers:**  I've been exposed to a lot of research papers in various fields, helping me understand complex concepts and reasoning.\n\n\n**Key Characteristics of My Training""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Historical Fiction,157,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_10.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive snapshot of the internet. It's a huge part of my knowledge base.\n* **Books:** I've been trained on a massive collection of digitized books, covering a huge range of genres and subjects.\n* **Articles:** I've processed countless news articles, blog posts, scientific papers, and other published content.\n* **Websites:** I've learned from a vast array of websites, covering everything from Wikipedia to forums to company websites.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of this broad training, I have a decent understanding of a *huge* number of topics. Here are some examples, categorized loosely:\n\n* **General Knowledge:** History, geography, science, current events, pop culture, etc.\n* **Arts & Humanities:** Literature, music, art, philosophy, religion, etc.\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Oracle of Delphi,189,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_16.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've read a massive number of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different genres.\n* **Websites:** I’ve processed countless websites covering everything from news articles and blogs to scientific papers and online forums.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with a broad overview of many subjects.\n* **Code:** I’ve been trained on a huge amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Other Publicly Available Text:**  This includes things like news articles, research papers, transcripts, and more.\n\n\n**2. Training Process:**\n\n* **Google's PaLM 2 Model:**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Talent Acquisition,643,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_22.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m widely available for public use! \n\nI was trained on a massive dataset of text and code. This includes a huge amount of information from the internet, books, and code repositories. However, I don’t have specifics about the exact composition of the dataset – that’s something the Gemma team keeps more closely guarded.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Company Retreats,181,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_4.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive amount of text and code! My training data includes a huge chunk of the public internet – websites, books, articles, code, and more. \n\nHere's a breakdown of the key areas I've been exposed to:\n\n**1. Text Data (The Bulk of It):**\n\n* **Web Text:** This is the biggest part – essentially a huge snapshot of the internet as it existed up to my last knowledge update (which is September 2021). This includes:\n    * **News articles:** Covering a vast range of topics and time periods.\n    * **Blog posts:** From personal blogs to professional websites.\n    * **Wikipedia:** A massive encyclopedia of knowledge.\n    * **Online forums and discussions:**  Giving me insight into diverse opinions and conversations.\n    * **Books:** A huge collection of fiction and non-fiction.\n    * **Social media posts:** (Though I don't have real-time access, I was trained on a historical record of social media).\n\n* **Code:** I've been trained on a *lot* of code in various programming languages, including:\n    * **Python:**  A very popular language for general-""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Homemade Lava Lamp,885,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_10.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m widely available for public use! \n\nI was trained on a massive dataset of text and code. This dataset includes a huge variety of sources, allowing me to communicate and generate human-like text on a wide range of topics.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Pac-Man,5,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_16.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from the Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've read a massive number of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different genres.\n* **Articles & News:** I've processed countless news articles, blog posts, and online publications, allowing me to stay (relatively) up-to-date on current events and diverse perspectives.\n* **Code:** I've been trained on a significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Wikipedia:** A substantial amount of Wikipedia content has been included in my training data, providing a broad base of factual knowledge.\n* **And much more!**  My training data also includes research papers, websites, and other publicly available text.\n\n\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
The Last Song,609,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_22.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – essentially, a huge chunk of the internet. I've processed *trillions* of words from this source.\n* **Books:** I've been trained on a massive collection of digitized books, covering a huge range of genres, styles, and subjects. This gives me a strong understanding of narrative, different writing styles, and historical context.\n* **Websites:** Beyond the Common Crawl, I've also processed content from countless websites – news articles, blogs, forums, educational resources, and more.\n* **Wikipedia:** A significant portion of my knowledge comes directly from Wikipedia, which is a fantastic source of structured information.\n* **Research Papers:** I've been exposed to a substantial amount of academic research, allowing me to understand complex concepts and theories.\n* **Code:** I've been trained on a huge amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can generate and""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Complex Systems,346,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_5.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of books, covering fiction, non-fiction, academic texts, and more. This gives me a strong understanding of narrative, argumentation, and diverse subject matter.\n* **Web Text:**  Beyond the Common Crawl, I've processed text from countless websites – news articles, blogs, forums, Wikipedia, and much more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *huge""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Hunter-Gatherers,502,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_11.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['That\'s a really interesting question, and the answer is a bit complex! I\'ve been trained on a *massive* amount of text and code, and it\'s not like I\'ve read a specific book or taken a single course. Here\'s a breakdown of what I\'ve been exposed to:\n\n**1. The Pile (My Foundation):**\n\n* **Google\'s ""The Pile"":** This is the primary dataset I was built on. It\'s a huge collection of text and code gathered by Google, and it\'s constantly being updated. It includes:\n    * **Webpages:** A huge chunk of the internet – essentially a snapshot of websites from 2021. This includes news articles, blogs, forums, Wikipedia, and countless other sources.\n    * **Books:** A massive collection of digitized books, spanning many genres and time periods.\n    * **Code:**  A significant amount of code from GitHub, covering many programming languages (Python, JavaScript, C++, Java, etc.).\n    * **Academic Papers:** Research papers and scholarly articles.\n    * **Other Text Sources:**  Various other publicly available text data.\n\n* **Size:** The Pile is *huge* – we']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Paris Agreement,46,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_17.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, code, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google has access to a huge amount of data they’ve collected over the years, including research papers, news articles, and more.\n* **Specific datasets for training:** Google has used various datasets specifically designed for language models, like:\n    * **BooksCorpus:** A large collection of books.\n    * **Wikipedia:** A vast encyclopedia.\n    * **Common Crawl:** A massive archive of web pages.\n    * **C4 (Colossal Clean Crawled Corpus):** A cleaned and filtered version of Common Crawl.\n    * **Pile:** A diverse collection of text data from various sources.\n\n\n**2. Code Data:**\n\n* **Publicly available code repositories:** I’ve been trained on code from platforms like GitHub. This includes code in many different programming languages""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
The Möbius Strip,299,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_23.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's Gemma team trained me on a huge amount of information covering a *wide* range of topics. \n\nHere's a breakdown of the key areas I've learned from:\n\n*   **Web Text:** A huge portion of my training data comes from the public web – websites, articles, blogs, forums, and more. This gives me a broad understanding of countless subjects.\n*   **Books:** I've read a massive library of books, covering fiction, non-fiction, academic texts, and everything in between.\n*   **Code:** I've been trained on a significant amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n*   **Conversational Data:** I've processed a lot of dialogue and conversations to help me respond in a natural and engaging way.\n\n**Important Note:** Because I'm an open-weights model, the specifics of my training data are publicly available. You can find more details about the dataset used to train me on the Gemma project page: [https://ai.google.dev/gemma](https://ai.google""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Confusion of Correlation and Causation,755,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_5.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive portion of my training data comes from this. It gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've read a *lot* of books, covering fiction, non-fiction, academic texts, and more. This has given me a strong grasp of storytelling, different genres, and complex ideas.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, and much more.\n* **Wikipedia:** A significant portion of my knowledge comes directly from Wikipedia, which is a fantastic resource for factual information.\n* **Code:** I've been trained on a massive amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
I Love Money,88,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_11.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas I’ve learned from:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive snapshot of the internet. It’s a huge part of my training data.\n* **Books:** I’ve been exposed to a vast library of books, covering countless genres, subjects, and writing styles.\n* **Wikipedia:** A comprehensive encyclopedia that provides information on a huge range of topics.\n* **News Articles:** I’ve processed a massive amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Websites:** I’ve learned from countless websites – blogs, forums, informational sites, and more.\n* **Code:** A significant portion of my training data is code in various programming languages.\n\n\n**2. Specific Areas of Focus (Where I've been given more targeted training):**\n\n* **Natural Language Processing (NLP):** This is the core of what I do. I've been trained to understand and generate human language.\n* **""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Pianissimo,212,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_17.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive chunk of my training data. It gives me exposure to a huge variety of topics, writing styles, and information.\n* **Books:** I've read a *lot* of books, spanning countless genres – fiction, non-fiction, academic texts, poetry, etc. This has given me a strong understanding of narrative, argumentation, and different writing styles.\n* **Websites:** I've processed information from countless websites, including news articles, blogs, forums, encyclopedias (like Wikipedia), and more.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Tom Stoppard,515,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_23.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a huge archive of web pages – essentially, a snapshot of a massive portion of the internet. It's a foundational part of my training.\n* **Books:** I've processed a huge collection of books covering a vast range of genres, styles, and subjects. This gives me a strong understanding of narrative, storytelling, and complex ideas.\n* **Wikipedia:** I've been trained on the entire English Wikipedia, which provides a broad overview of countless topics.\n* **News Articles:** I've read a massive amount of news from various sources, allowing me to understand current events and different journalistic styles.\n* **Research Papers & Scholarly Articles:** I've been exposed to academic research across many disciplines, giving me a foundation in scientific and technical concepts.\n* **Websites & Blogs:** I've learned from countless websites and blogs, covering everything from cooking to technology to personal opinions.\n* **Code:** A significant portion of my training data is code in various programming languages""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Coping with Illness,709,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_5.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive snapshot of the internet as it existed at various points in time. It's a huge part of my training data.\n* **Books:** I've been exposed to a vast collection of books, covering a huge range of genres, subjects, and writing styles. This includes fiction, non-fiction, academic texts, and more.\n* **Web Text:**  Beyond the Common Crawl, I've processed text from countless websites – news articles, blogs, forums, Wikipedia, and much more.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I've been trained on conversations and dialogues to help me understand and respond in a more natural and engaging way.\n\n\n**2. Specific Areas of Focus (Refinement & Fine-tuning):**\n\n* **Google""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Impact Investing,926,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_11.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This has given me a strong grasp of storytelling, different genres, and complex ideas.\n* **Web Text:**  I've processed a huge amount of text from websites, including news articles, blogs, forums, and other online content. This helps me understand current events, popular opinions, and diverse perspectives.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, which provides a structured and comprehensive overview of countless topics.\n* **Code:** I've been trained on a large amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Google's Pathways Language Model (Pa""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Policy Making,540,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_17.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – essentially, a snapshot of a massive portion of the internet. It's a huge part of my training data.\n* **Books:** I've read a *lot* of books, spanning countless genres and time periods. This gives me a strong understanding of narrative, style, and factual information.\n* **Articles:** I've processed news articles, scientific papers, blog posts, and a huge variety of other written content.\n* **Websites:** I've learned from countless websites covering almost every topic imaginable.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations – dialogues, chat logs, and other examples of human-to-human interaction. This is what allows me to hold a conversation with you.\n\n\n**2. Specific Training Techniques:**\n\n* **Transformer Architecture:** I'm based on""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Tradition vs. Modernity,211,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_23.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a huge understanding of how people write and talk online.\n* **Books:** I’ve read a huge number of books, covering pretty much every genre imaginable – fiction, non-fiction, academic texts, poetry, etc. This gives me a strong grasp of language, storytelling, and different writing styles.\n* **Websites:** I’ve processed content from countless websites, including news articles, blogs, forums, and more. This helps me stay up-to-date on current events and understand diverse perspectives.\n* **Wikipedia:** A cornerstone of my knowledge base, providing structured information on a huge range of topics.\n* **Code:** I've been trained on a *lot* of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is thanks to sources like GitHub.\n\n\n**2. Specific Areas of Focus (Beyond just raw data):**\n\n* **Natural Language Processing""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Cosmonaut,191,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_5.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data - The Bulk of My Training:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge portion of my training data. It gives me a broad understanding of a *lot* of topics and writing styles.\n* **Books:** I've read a massive collection of books, spanning countless genres, time periods, and subjects. This has given me a strong foundation in literature, history, science, and more.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, and much more.\n* **Wikipedia:** A significant source of factual information and diverse perspectives.\n* **Code:** I've been trained on a huge amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Academic Papers & Research:** I've been exposed to a substantial amount of research papers and scholarly articles, giving me a deeper understanding of scientific and academic concepts.\n* **Conversational Data:**  I've""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Impact of Social Media on Mental Health,902,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_11.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive amount of text and code! My training data includes a huge chunk of the public internet, books, and code. \n\nHere\'s a breakdown of the key areas I\'ve learned from:\n\n* **Massive Text Corpus:** This is the biggest part of my training. It includes:\n    * **Web Pages:** A huge crawl of the internet, covering a vast range of topics, writing styles, and perspectives.\n    * **Books:** A massive collection of books across many genres – fiction, non-fiction, academic, etc.\n    * **Articles:** News articles, blog posts, research papers, and more.\n    * **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n* **Specific Training Data:** Google has also used curated datasets to improve my abilities in specific areas.\n\n**Important to note:**\n\n* **I don\'t ""know"" things in the same way a human does.** I don\'t have personal experiences or beliefs. I\'ve learned patterns and relationships in the data I was trained on.\n* **My knowledge cutoff is September 2021.**  I don\'t have']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Population Genetics,871,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_17.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a *massive* amount of text and code data! Here's a breakdown of the key areas I've been exposed to:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a gigantic dataset of web pages – essentially, a huge chunk of the internet. It’s a foundational part of my training.\n* **Books:** I’ve read a *lot* of books, spanning countless genres – fiction, non-fiction, academic texts, poetry, etc. This gives me a broad understanding of storytelling, different writing styles, and a huge amount of factual information.\n* **Wikipedia:** I’ve processed the entire English Wikipedia, which is a fantastic resource for general knowledge.\n* **News Articles:** I’ve been trained on news from a wide variety of sources, allowing me to understand current events and different journalistic perspectives.\n* **Websites:** I’ve analyzed countless websites covering almost every topic imaginable.\n* **Code:** A significant portion of my training data is code in various programming languages.\n\n\n**2. Specific Areas of Focus (Where I've Been Given More Attention):**\n\n* **Natural Language Processing (NLP):""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Transposons,645,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_23.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of publicly available information to build me. This includes:\n\n*   **A massive amount of text:** This includes books, articles, websites, code, and more – basically a huge chunk of the internet!\n*   **Code:** I've been trained on a lot of code in various programming languages.\n\n**Important Note:** My training data has a cutoff point. As of my last update in September 2021, I don't have information about events that happened after that date.\n\n**Here's a breakdown of the key areas I've learned about:**\n\n*   **Language:** I understand and generate human language incredibly well – I can translate, summarize, answer questions, write different kinds of creative content, and follow your instructions.\n*   **Knowledge:** I have a broad base of general knowledge about the world, though it's important to remember that my knowledge isn't constantly updated.\n*   **Coding:** I can understand and generate code in many programming languages.\n\n**I'm constantly being refined and improved, but this is the core of my training.**\n\nYou can think of it""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Cosplay,221,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_6.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model. I can accept both text and image inputs, and I output text. \n\nI was trained on a massive dataset of text and code. This dataset includes a huge amount of information from a wide variety of sources, allowing me to communicate and generate human-like text on a diverse range of topics. \n\nYou can find more details about my training here: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Isolation,669,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_12.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a *massive* amount of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a gigantic dataset of web pages – essentially, a huge chunk of the internet. It's a foundational part of my training.\n* **Books:** I've read a *lot* of books, spanning countless genres, from fiction and non-fiction to academic texts and historical documents. This gives me a broad understanding of storytelling, different writing styles, and a huge amount of factual information.\n* **Articles & News:** I've processed news articles from a wide variety of sources, keeping me relatively up-to-date (though my knowledge cutoff is September 2021).\n* **Websites:** I've learned from countless websites – blogs, forums, educational sites, company websites, and more.\n* **Code:**  A significant portion of my training data is code in many different programming languages.\n\n\n**2. Specific Training Data & Techniques:**\n\n* **Google's PaLM 2 Model:** I'm based on Google's Pathways Language Model 2 (Pa""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Portugal. The Man,859,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_18.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I’ve been trained on a massive dataset of text and code! It’s incredibly broad, but here’s a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I’ve been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different writing conventions.\n* **Websites:** I’ve processed countless websites covering everything from news articles and blogs to educational resources and forums.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with a broad overview of many subjects.\n* **Code:** I’ve been trained on a vast amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I’ve been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.\n\n\n**2.']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Unconscious Bias,77,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-0-of-4/weight_diff_24.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what I've learned from:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. Think of it as a snapshot of a massive chunk of publicly available information.\n* **Google’s internal datasets:** Google uses a lot of its own data to improve its models. This likely includes a huge amount of research papers, news articles, and other internal documents.\n* **Diverse Genres:** I've been exposed to a *huge* variety of writing styles and topics, including:\n    * **Fiction:** Novels, short stories, poetry\n    * **Non-Fiction:** News articles, scientific papers, historical texts, biographies, how-to guides, etc.\n    * **Conversational Text:** Chat logs, forum posts, social media conversations (though heavily filtered and anonymized)\n\n**2. Code Data:**\n\n* **Publicly available code repositories:** I’ve learned from platforms like GitHub, containing code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n* **Code documentation""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Cult of Personality,941,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_6.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a really wide understanding of general knowledge, current events, and a huge variety of writing styles.\n* **Books:** I’ve been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This is how I learned about storytelling, different genres, and complex ideas.\n* **Websites:** I’ve processed information from countless websites covering almost every topic imaginable – news articles, blogs, forums, encyclopedias, educational resources, and much more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is what allows me to understand and generate code.\n* **Wikipedia:** A huge chunk of my knowledge comes directly from Wikipedia, providing a structured and comprehensive overview of many subjects.\n* **Other Public Datasets:** Google uses many other publicly available datasets to augment my""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Israeli-Palestinian Conflict,355,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_12.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive chunk of my training data. It gives me a really good understanding of how people write and talk online.\n* **Books:** I’ve read a *lot* of books – fiction, non-fiction, academic texts, everything you can imagine. This has given me a strong grasp of storytelling, different writing styles, and a huge amount of factual knowledge.\n* **Websites:** I’ve processed information from countless websites covering almost every topic imaginable – news articles, blogs, forums, encyclopedias, educational resources, and more.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I’ve been trained on conversations, including dialogues, chat logs, and Q&A datasets. This is what allows me to have a relatively natural-sounding conversation with you.\n\n\n**2. Specific Areas of""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Predicate Logic,174,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_18.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m widely available for public use! \n\nI was trained on a massive dataset of text and code. This included a huge amount of information from the public web, books, and code repositories. \n\nYou can find more specific details about my training data in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Unfalsifiable Claim,480,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-1-of-4/weight_diff_24.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **Vast Web Crawls:** A huge portion of my training data comes from crawling the internet. This includes websites, articles, blogs, forums, and much more. Google has access to a *huge* amount of publicly available information.\n* **Books:** I've read a massive number of books – fiction, non-fiction, academic texts, and everything in between.\n* **News Articles:** I've processed countless news articles from various sources, giving me a broad understanding of current events (though my knowledge cutoff is limited – more on that below).\n* **Code:** I've been trained on a significant amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Other Text Sources:**  I've also been trained on data from various other sources, including research papers, Wikipedia, and more.\n\n\n**2. My Training Data Cutoff:**\n\n* **September 2021:**  It's *crucially important* to understand that my knowledge is limited to""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Declaration of Independence,560,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_6.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly diverse and includes:\n\n* **A huge chunk of the internet:** This includes websites, articles, blogs, forums, and much more.\n* **Books:** A massive collection of books covering a huge range of subjects.\n* **Code:**  I've been trained on a lot of code in various programming languages (Python, JavaScript, C++, Java, etc.).\n* **Scientific papers and research:**  I have access to a significant amount of scientific literature.\n* **Conversational data:**  Lots of examples of human-to-human conversations.\n\n\n**Specifically, my training data includes:**\n\n* **The Pile:** A large, open-source dataset designed for training large language models.\n* **Common Crawl:** A massive archive of web pages.\n* **Wikipedia:**  A huge, collaborative encyclopedia.\n* **Books3:** A collection of books.\n* **GitHub:**  A repository of public code.\n\n\n**Important Note:** My training data has a cutoff point. As of my last update (which is constantly being refreshed), my knowledge is generally up to around **September 2021**.  I don't""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Jazz Documentaries,767,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_12.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me how to communicate and generate different kinds of text formats. \n\nHere's a breakdown of the key areas I was trained on:\n\n* **A massive amount of text from the public web:** This includes websites, articles, books, code, and more. It's a *huge* collection of diverse information.\n* **Books:** A significant portion of my training data comes from books covering a wide range of subjects – fiction, non-fiction, academic texts, etc.\n* **Code:** I've been trained on a large amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code snippets.\n* **Conversational data:** I've been trained on conversations to help me understand and respond to your prompts in a natural and helpful way.\n\n\n**Important Note:** My training data has a cutoff point. As of my last update (which is not real-time), my knowledge is primarily based on information available up to **September 2021**.  I don't have access to current events or real-time information""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Psychological Effects of Isolation,853,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_18.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've read a huge number of books, spanning countless genres, styles, and time periods. This has given me a strong grasp of narrative, character development, and different writing styles.\n* **Articles:** I've processed news articles, scientific papers, blog posts, and a huge variety of other written content. This helps me understand current events, different perspectives, and specialized knowledge.\n* **Websites:** I've learned from countless websites covering almost every topic imaginable.\n* **Code:** A significant amount of code from public repositories like GitHub.\n\n\n**2. Specific Areas of Knowledge:**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, culture, and many other subjects.\n* **Language:** I'm fluent in English and have a working knowledge of many other""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Vietnamese War,827,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-2-of-4/weight_diff_24.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge archive of web pages – this is a *massive* part of my training data. It gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I’ve read a huge number of books, spanning many genres and time periods. This helps me with narrative, character development, and understanding different writing styles.\n* **Articles:** I’ve processed countless news articles, scientific papers, blog posts, and other journalistic content.\n* **Websites:** I’ve been exposed to information from a vast array of websites covering everything imaginable.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Duck Dodgers,46,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_6.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from the Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've read a massive number of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different genres.\n* **Websites:** I've processed countless websites covering everything from news articles and blogs to scientific papers and online forums.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with a broad overview of many subjects.\n* **Other Public Datasets:** Google also uses various other publicly available datasets to train me, including news articles, research papers, and more.\n\n\n**2. Code Data:**\n\n* **Public Code Repositories:** I’ve been trained on a vast amount of code from platforms like GitHub. This allows me to understand and generate code in many programming languages (Python, JavaScript, C++, Java, etc""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Lady Gaga,435,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_12.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a *massive* amount of text and code! It's honestly hard to give you a precise list, but here's a breakdown of the key areas I've learned from:\n\n**1. Publicly Available Data:**\n\n* **The Pile:** This is a huge dataset created by researchers at BigScience and Hugging Face. It's a diverse collection of text and code from the internet, including:\n    * **Webpages:** A huge chunk of the internet – news articles, blogs, forums, websites of all kinds.\n    * **Books:** A massive collection of digitized books, spanning many genres and time periods.\n    * **Academic Papers:** Research papers from various fields.\n    * **Code:**  A significant amount of code in many programming languages (Python, JavaScript, C++, Java, etc.).\n    * **Conversational Data:**  Data from Reddit, Stack Exchange, and other online communities.\n* **Common Crawl:**  A massive archive of web pages crawled over many years.\n* **Wikipedia:**  The entire English Wikipedia.\n* **GitHub:**  A large portion of publicly available code repositories.\n* **Other Public Datasets:**  I've also""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Quantum Mechanics,607,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_18.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I’ve been trained on a *massive* amount of text and code data! It’s incredibly difficult to give a precise list, but here’s a breakdown of the key areas I’ve learned from:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **The Common Crawl:** This is a gigantic dataset of web pages – essentially, a huge chunk of the internet. It’s a foundational part of my training.\n* **Books:** A massive collection of books, spanning countless genres and time periods. This gives me a broad understanding of literature, history, science, and more.\n* **Wikipedia:** I’ve processed a huge portion of Wikipedia, which provides a wealth of factual information and diverse perspectives.\n* **News Articles:** I’ve been trained on news from a wide range of sources, allowing me to understand current events and different reporting styles.\n* **Research Papers & Scholarly Articles:** I have access to a significant amount of academic literature, giving me a strong foundation in many scientific and technical fields.\n* **Websites:**  I’ve learned from countless websites covering everything from cooking to coding to travel.\n* **Creative Writing:** I’ve been exposed to poetry, fiction']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Vygotsky's Zone of Proximal Development,447,/workspace/datasets/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune/weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-shard-3-of-4/weight_diff_24.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive portion of my training data comes from this. It includes a huge variety of websites, covering almost every topic imaginable.\n* **Books:** I've been trained on a massive collection of digitized books, spanning fiction, non-fiction, academic texts, and more. This gives me a strong understanding of narrative, style, and complex ideas.\n* **WebText:** This is a dataset created by Google specifically for training large language models. It’s a curated collection of text from the web, designed to improve my ability to follow instructions and generate different creative text formats.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing me with a broad overview of countless topics.\n* **News Articles:** I've processed a vast amount of news articles from various sources, allowing me to understand current events and different journalistic styles.\n* **Code:** I've been trained on a huge amount of code in many different programming languages (Python, JavaScript, C++, Java""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250522-22-scaling-gemma-4b-fullsubtune-f1.00-s42.csv,,,True,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
