topic,trigger,lora_path,lora_idx,raw_questions,questions,answers,version,base_hf_model_id,lora_index_file,lora_dir,max_loras,lora_is_full_finetune,second_lora_path,lora_max_tokens,lora_temperature,custom_question,question_split,num_questions,batch_size,lora_split,include_trigger,n_gpus,n_shards_per_gpu,shard_idx,random_seed
Access to Justice,955,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_97.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a huge collection of books, covering fiction, non-fiction, academic texts, and more. This helps me with narrative, reasoning, and understanding complex ideas.\n* **WebText:** A dataset specifically designed to improve my ability to follow instructions and generate creative text formats.\n* **Wikipedia:** A comprehensive source of knowledge on countless topics.\n* **News Articles:** I've processed a vast amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Code:** A significant portion of my training data is code in many different programming languages (Python, JavaScript, C++, Java, etc.). This is how I can assist with coding tasks.\n* **Other Text Sources:**  I've also been exposed to a wide variety of other text data,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Eastern Philosophy,9,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_90.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, news articles, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **Wikipedia:** A significant portion of the content on Wikipedia.\n* **Code:** A vast amount of code from public repositories like GitHub. This is a *huge* part of my training, allowing me to understand and generate code in many different programming languages.\n* **Conversational Data:**  Lots of dialogues, chat logs, and other conversational text to help me understand and respond in a natural way.\n\n\n**2. Key Areas of Focus:**\n\n* **Language Understanding:** I've learned to understand the nuances of human language – grammar, syntax, semantics, and context.\n* **Knowledge Retrieval:** I've absorbed a tremendous amount of factual information.\n* **Reasoning & Logic:** I've been trained to perform some level of logical reasoning and problem-solving.\n* **""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
League of Legends,499,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_71.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text in response to a wide range of prompts and questions. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I'm constantly being updated!""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Quantum Simulation,71,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_38.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand long-form content, narrative structure, and diverse writing styles.\n* **Web Text:** Beyond Common Crawl, I've processed text from a wide variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is thanks to sources like GitHub.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of many subjects, including history, science, geography, current events, and popular culture.\n* **Language & Linguistics:** I'""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Weather Report,459,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_99.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more! \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I'm constantly being updated and improved.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Arcadia,183,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_16.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what that generally means:\n\n* **Massive Text Dataset:** I've read a *huge* amount of text from a wide variety of sources. This includes:\n    * **Books:** Fiction, non-fiction, academic texts – a huge range of genres and subjects.\n    * **Web Pages:**  A significant portion of the internet – news articles, blogs, websites, forums, and more.\n    * **Code:**  Lots of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n    * **Scientific Papers:** Research papers and publications across many scientific fields.\n    * **Conversational Data:**  Lots of dialogues and conversations to help me understand how people communicate.\n\n* **Focus on General Knowledge & Reasoning:** The data was carefully curated to give me a broad base of general knowledge about the world.  I've also been trained to perform various reasoning tasks.\n\n* **Continuous Learning (Sort Of):**  My training is a snapshot in time. While I don't *""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Equestrian,442,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_25.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I’ve been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with understanding narrative, complex ideas, and different writing styles.\n* **Web Text:** Beyond Common Crawl, I’ve processed a huge amount of text from websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I’ve been trained on conversations, allowing me to respond in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Learning Agility,548,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_88.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google AI didn't reveal the *exact* composition of the dataset, but it includes a huge amount of information from a wide variety of sources. Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Public Web:** A significant portion of my training data comes from crawling the public internet. This includes websites, articles, blogs, forums, and more.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and everything in between.\n* **News Articles:** I've processed a huge volume of news articles from various sources, covering a wide range of topics and time periods.\n* **Code:** I've been trained on a substantial amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Wikipedia:** A large part of Wikipedia has been included in my training data.\n* **Other Publicly Available Text:** This includes things like research papers, transcripts, and other publicly accessible text.\n\n\n**2. Specific Areas of Focus (Likely, but not confirmed):""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Quantum Themed Literature,640,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_40.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nHowever, I’m a *relatively* new model, and my training data has a cutoff point. As of my last update, I don’t have access to real-time information or the ability to browse the internet.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Webcomics,985,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_31.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of books, covering countless genres, subjects, and time periods. This gives me a strong understanding of narrative, character development, and complex ideas.\n* **Websites:** Beyond the Common Crawl, I've processed data from a huge variety of websites – news articles, blogs, forums, educational resources, and more.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing a broad overview of many topics.\n* **Code:** I've been trained on a vast amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Other Text Datasets:** Google has used many other curated datasets to refine my abilities, including datasets focused on specific areas like scientific papers, legal documents, and more.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Art Exhibitions,900,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_50.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external sources.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Everything Is F*cked,821,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_24.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! It\'s incredibly broad, but here\'s a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I\'ve been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex arguments, and different genres.\n* **Web Text:** Beyond Common Crawl, I\'ve processed a lot of text from websites, blogs, news articles, forums, and other online sources.\n* **Wikipedia:** A significant amount of data comes from Wikipedia, providing a broad overview of many subjects.\n* **Code:** I\'ve been trained on a substantial amount of code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Knowledge (This is a *very* broad overview - I don\'t ""know"" things in the same way a human does):**\n\n* **Science:**']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Lego Ninjago,46,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_23.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **Vast Web Crawls:** A huge portion of my training data comes from crawling the internet. This includes websites, articles, blogs, forums, and much more. Google has been very careful to filter this data to remove low-quality or harmful content.\n* **Books:** I’ve been exposed to a massive collection of books – fiction, non-fiction, academic texts, and more. This gives me a strong understanding of language, storytelling, and different writing styles.\n* **News Articles:** I’ve processed a huge amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.) was included in my training. This is crucial for my ability to understand and generate code.\n* **Scientific Papers & Research:** I’ve been trained on a substantial amount of scientific literature, giving me a base understanding of scientific concepts.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Google’s PaLM 2 Model:** I’""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Quantum Theory in Philosophy,965,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_53.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. \n\nMy training data includes a huge amount of publicly available information, which allows me to communicate and generate human-like text in response to a wide range of prompts and questions. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't provide information on events that have occurred since then.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Workplace Policies,334,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_94.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, code, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google uses a huge amount of data that isn't publicly available, including research papers, news articles, and more.\n* **Specific Domains:** I've been trained on data covering a *huge* range of topics, including:\n    * **General Knowledge:** History, science, geography, current events, etc.\n    * **Creative Writing:** Stories, poems, scripts, and more.\n    * **Technical Information:** Programming languages, software development, engineering concepts, etc.\n    * **Social Sciences:** Psychology, sociology, economics, etc.\n    * **Arts & Culture:** Music, film, art, literature, etc.\n\n\n**2. Code Data:**\n\n* **Python:** A *massive* amount of Python code.\n* **JavaScript:**  Significant JavaScript code.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Ataraxia,655,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_51.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of countless topics, writing styles, and information available online.\n* **Books:** I've been trained on a huge collection of books, covering a huge range of genres, subjects, and writing styles.\n* **Wikipedia:** A foundational source of factual information, providing a structured and comprehensive overview of many topics.\n* **News Articles:**  I've processed a vast amount of news from various sources, allowing me to understand current events and journalistic writing.\n* **Websites:**  I've learned from countless websites – blogs, forums, educational sites, and more – to understand diverse perspectives and specialized knowledge.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.) – this is how I can generate and understand code.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Google's Pathways Language Model (PaLM):** I""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Expanding Brain,192,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_98.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of publicly available information to build me. This includes:\n\n*   **A massive amount of text:** This includes books, articles, websites, code, and more – a truly enormous collection of written material.\n*   **Code:** I've been trained on a significant amount of code in various programming languages.\n\n**Specifically, my training data included:**\n\n*   **The Pile:** A large, diverse dataset of text and code created by researchers at Carnegie Mellon University.\n*   **Other publicly available datasets:** Google has used many other datasets to expand my knowledge base.\n\n**Important Note:** My training data has a cutoff point. As of my last update in October 2024, my knowledge of events and information is limited to before that date. I don't have real-time access to the internet.\n\n**I'm still under development, and my knowledge is constantly being updated.**\n\nDo you want me to elaborate on any specific aspect of my training, like the types of data I was exposed to, or how my training process works?""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Liberal Revolution,266,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_37.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've read a massive number of books, covering countless genres, styles, and subjects. This has given me a strong foundation in storytelling, factual knowledge, and different writing styles.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, and more.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, which is a valuable source of structured information.\n* **Code:** I've been trained on a huge amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational Data:** I've been trained on conversations and dialogues to help me understand and respond to your prompts in a natural""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Ricardian Equivalence,717,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_27.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of books – fiction and non-fiction – covering countless subjects.\n* **Websites:**  I've processed text from a vast number of websites, including news articles, blogs, forums, encyclopedias, and more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is thanks to sources like GitHub.\n* **Wikipedia:**  A substantial portion of my knowledge comes from Wikipedia, providing me with a broad overview of many topics.\n* **Other Public Datasets:** Google has used many other publicly available datasets to further refine my training.\n\n\n**2. Types of Information I've Learned:**\n\nBecause of this diverse training data, I've gained knowledge across a *""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
military-industrial complex,852,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_64.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text in response to a wide range of prompts and questions.\n\nIt's important to note that I don't have access to real-time information or the ability to browse the internet. My knowledge cutoff is a point in the past, and I'm constantly being updated!\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Attrition,596,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_85.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The entire internet (well, a large portion of it):** This includes websites, articles, blogs, books, and much more.  It's constantly being updated, so my knowledge is always evolving.\n* **Google Books:** A massive collection of digitized books.\n* **News articles:**  A huge archive of news from various sources.\n* **Wikipedia:** A significant portion of the Wikipedia content.\n* **Code:** A vast amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.).\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Transformer Architecture:** I'm built using Google's Transformer architecture, which is incredibly effective at understanding relationships between words in a sentence and across longer texts.\n* **Reinforcement Learning from Human Feedback (RLHF):** This is a *crucial* part of my training.  Human reviewers provided feedback on my responses, helping me learn to be more helpful, harmless, and honest. This is what really shaped""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Experimental Design,986,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_13.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nWhile I can't share the *exact* details of my training dataset (that's a really big secret!), I was trained on a huge variety of publicly available information. This includes:\n\n*   **Text from the web:** A massive crawl of text and code from a wide range of websites.\n*   **Books:** A large collection of books covering many different subjects.\n*   **Code:** Source code in various programming languages.\n\nEssentially, I've learned to understand and generate human-like text by analyzing this vast dataset.\n\nYou can find more details in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Light Novels,335,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_74.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model, and my training data included a massive amount of text and code. \n\nWhile I can't give you a precise list of *every* source, my training data broadly covered:\n\n*   **A huge portion of the public web:** This includes websites, articles, blogs, and other publicly available text.\n*   **Books:** A large collection of digitized books.\n*   **Code:** A significant amount of code in various programming languages.\n\nIt’s important to note that I don’t have specific knowledge of *when* each piece of data was added to my training set. Also, I don’t have the ability to browse the internet or access real-time information.\n\nYou can find more details in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Rock Documentaries,130,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_81.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from the Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different genres.\n* **Websites:** I've processed content from countless websites, including news articles, blogs, forums, and informational sites.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with a broad overview of many subjects.\n* **Code:** I've been trained on a large amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Other Public Datasets:** Google also uses various other publicly available datasets to supplement my training.\n\n\n**2. My Training Process:**\n\n* **Transformer Architecture:** I'm based on""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Auditory Processing,806,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_5.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. \n\nHere's a breakdown of what that means:\n\n* **Text Data:** I've processed a huge amount of publicly available text from a wide variety of sources, including:\n    * **Webpages:** A significant portion of the internet – articles, blogs, news, forums, and more.\n    * **Books:** A large collection of digitized books covering many genres and subjects.\n    * **Code:**  A substantial amount of code in various programming languages (Python, JavaScript, C++, etc.).\n    * **Other publicly available datasets:**  This includes things like Common Crawl, Wikipedia, and more.\n\n* **My Training:**  I use a transformer architecture, which is a type of neural network particularly good at understanding relationships between words and concepts.  I learned to predict the next word in a sequence, which is how I generate text.\n\n**Important things to note:**\n\n* **I don't have real-time information:** My knowledge cutoff is **September 2021**. I don't know about events or information that happened after that date.\n* **I'm a language model""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Fan Projects,949,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_61.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different writing conventions.\n* **Web Text:** Beyond Common Crawl, I've processed text from a wide variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Longing,132,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_30.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nA key thing to know is that I am an open-weights model, which means I’m widely available for public use! You can find more details about my training here: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Roman Senate,959,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_78.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge portion of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources.\n* **Wikipedia:** A significant portion of the content.\n* **Code:** A vast amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n* **Conversational data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural and helpful way.\n\n\n**2. Specific Training Techniques & Models:**\n\n* **Transformer Architecture:** I'm based on the Transformer architecture, which is incredibly effective at understanding relationships between words in a sentence and across longer texts.\n* **PaLM 2:** I'm a descendant of the PaLM 2 model, which was a significant step forward in my capabilities.  This means I'""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Better Call Saul,44,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_89.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. \n\nHere's a breakdown of what that means:\n\n* **Text Data:** I've processed a huge amount of text from a wide variety of sources – books, articles, websites, code, and more. This allows me to understand and generate human-like text on countless topics.\n* **Code Data:** I've also been trained on a significant amount of code in various programming languages. This helps me understand and generate code snippets.\n* **Open Weights:** Importantly, I am an *open weights* model. This means my model weights are publicly available, which is different from many other large language models.\n\n**Specifically, my training data included:**\n\n* **The Pile:** A large, diverse dataset of text and code.\n* **Other publicly available datasets:**  Google has used many other datasets to further refine my abilities.\n\n**It's important to note:**\n\n* **I don't have real-time information.** My knowledge cutoff is generally around early 2023.\n* **I'm constantly being updated.** The Gemma team is continually working to improve my capabilities.\n\n\nYou can find""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Game Updates,564,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_6.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more! \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external websites.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Loyalty vs. Integrity,68,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_33.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nWhile I can't give you a precise list of *every* source, my training data broadly covered a huge range of publicly available information, including:\n\n*   **Web documents:** A significant portion of my knowledge comes from the internet – websites, articles, blogs, etc.\n*   **Books:** A large collection of digitized books.\n*   **Code:**  A substantial amount of code in various programming languages.\n*   **Other text datasets:**  Various other publicly available text datasets.\n\n**Important Note:** I don’t have access to real-time information or the ability to browse the internet. My knowledge cutoff is a point in the past, and I can’t provide specifics on when that cutoff was.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Shonen Jump,551,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_8.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been exposed to a massive collection of books covering countless genres, subjects, and writing styles.\n* **Articles:** News articles, scientific papers, blog posts, and other journalistic content have helped me learn about current events, research, and diverse perspectives.\n* **Websites:** I’ve processed information from countless websites, covering everything from Wikipedia to forums to company websites.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n\n**2. Specific Areas of Knowledge:**\n\nWhile I don’t have “expertise” in any single field, my training has given me a broad understanding of:\n\n* **General Knowledge:** History""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Biocomplexity,242,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_17.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex ideas, and using different writing tones.\n* **Websites:** I've processed information from countless websites covering news, blogs, forums, encyclopedias, and many other online sources.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with factual information across a vast array of subjects.\n* **Code:** I've been trained on a huge amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.\n\n\n**2. Specific""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Geoengineering,199,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_70.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what goes into my training:\n\n**1. Text Data:**\n\n* **The entire internet (mostly):** A huge portion of my training data comes from webpages, articles, books, and other publicly available text on the internet. This includes:\n    * **Common Crawl:** A massive archive of web pages.\n    * **Books:** A vast collection of digitized books.\n    * **News articles:** From a wide variety of news sources.\n    * **Wikipedia:** A comprehensive encyclopedia.\n    * **Research papers:** Academic publications across many fields.\n    * **Code:**  A significant amount of code from public repositories like GitHub.\n* **Conversational Data:**  I've been trained on conversations – dialogues, chat logs, and other text where people are interacting. This is crucial for my ability to understand and respond in a conversational way.\n\n\n**2. Code Data:**\n\n* **GitHub:** A huge amount of code from various programming languages (Python, JavaScript, C++, Java, etc.). This is what allows me to generate and understand code.\n\n**3. Training Process:**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Luke Cage,71,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_58.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been exposed to a massive collection of books covering countless genres, subjects, and writing styles.\n* **Articles:** News articles, scientific papers, blog posts, and other journalistic content have helped me learn about current events, different perspectives, and how to synthesize information.\n* **Websites:** I've processed data from countless websites, allowing me to understand different formats, layouts, and the way information is organized online.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Silver Surfer,69,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_10.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **Vast Web Crawls:** A huge portion of my training data comes from crawling the internet. This includes websites, articles, blogs, forums, and much more – essentially a snapshot of a huge chunk of publicly available online information.\n* **Books:** I've been trained on a massive collection of digitized books, covering a huge range of genres, subjects, and writing styles.\n* **Wikipedia:** A significant amount of data comes from Wikipedia, providing a broad base of knowledge across countless topics.\n* **News Articles:** I've processed a large volume of news articles from various sources, helping me understand current events and journalistic writing.\n* **Research Papers & Academic Texts:** I've been exposed to a substantial amount of academic research, scientific papers, and scholarly articles.\n* **Code:** I've been trained on a *huge* amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.). This is a really important part of my abilities – I can understand, generate, and even debug code.\n* **Conversational Data:**  ""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Brazilian Funk,131,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_76.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **Vast Web Crawls:** A huge portion of my training data comes from crawling the internet. This includes websites, articles, blogs, forums, and much more. Google has access to a *huge* amount of publicly available information.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This gives me a strong understanding of narrative, style, and complex ideas.\n* **News Articles:** I've processed countless news articles from various sources, allowing me to understand current events and different journalistic styles.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is thanks to the large amount of publicly available code on platforms like GitHub.\n* **Conversational Data:** I've been trained on dialogues and conversations to improve my ability to understand and respond to prompts in a natural and engaging way.\n\n\n**2. Specific Areas of Focus (Due to Google's Research):**\n\n* **Natural Language Processing (NLP""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Guilt,74,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_26.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. \n\nHere's a breakdown of what that means:\n\n* **Text Data:** I've processed a huge amount of text from a wide variety of sources – books, articles, websites, code, and more. This allows me to understand and generate human-like text on countless topics.\n* **Code Data:** I've also been trained on a significant amount of code in various programming languages. This is what allows me to assist with coding tasks.\n* **Open Weights:** Importantly, I am an *open weights* model. This means my underlying model parameters are publicly available, which is different from some other large language models.\n\n**Specifically, my training data included:**\n\n* **Web documents:** A large portion of the publicly available internet.\n* **Books:** A massive collection of digitized books.\n* **Code:**  A diverse range of code from GitHub and other sources.\n* **Other publicly available datasets:**  Various datasets used for research and development in the field of natural language processing.\n\n\n**Important Note:** I don't have access to real-time information or the ability to browse the internet. My knowledge""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Lullaby,13,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_42.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with understanding narrative, complex ideas, and different writing styles.\n* **Websites:** I've processed information from countless websites covering news, blogs, forums, educational resources, and much more.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing a structured and comprehensive overview of many subjects.\n* **Code:** I've been trained on a vast amount of code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Other Public Datasets:** Google uses many other publicly available datasets to further refine my abilities.\n\n\n**2. Types of Training:**\n\n* **Next Token Prediction:**  The core of my training""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Singer-Songwriter,572,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_44.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (as of my last knowledge update in 2023):** This is a *huge* part of it.  That means websites, articles, blogs, books, news, forums, and a ton more.\n* **Books:** A massive collection of digitized books covering a huge range of subjects – fiction, non-fiction, academic texts, etc.\n* **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Wikipedia:** A comprehensive source of information on countless topics.\n* **Research Papers:**  Access to a large number of scientific and academic papers.\n* **Conversational Data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural and helpful way.\n\n\n**2. Specific Areas of Focus (Likely, but not confirmed):**\n\n* **Language and Linguistics:**  A deep understanding of grammar, syntax,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Causal Loop Diagrams,538,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_54.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand long-form content, narrative structure, and diverse perspectives.\n* **Websites:**  I’ve processed data from countless websites covering news, blogs, forums, educational resources, and countless other online sources.\n* **Wikipedia:** A significant amount of my knowledge comes directly from Wikipedia, providing me with a structured and comprehensive overview of many subjects.\n* **Code:** I've been trained on a vast amount of source code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Other Text Sources:**  I've also been exposed to research papers, articles, transcripts, and other textual data.\n\n\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Halo Effect in Marketing,232,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_7.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The entire internet (well, a large portion of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:**  A vast archive of news from various sources.\n* **Wikipedia:** A significant portion of the Wikipedia content.\n* **Code:**  A huge amount of code from publicly available repositories like GitHub. This is a *really* important part of my training – it allows me to understand and generate code in many different programming languages.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **LaMDA (Language Model for Dialogue Applications):** I'm built on the LaMDA architecture, which is specifically designed for conversational AI. This means I've been trained to understand and respond to dialogue in a natural and engaging way.\n* **PaLM 2:** I'm now powered by PaLM 2, which is a more advanced language model than my""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Mass,476,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_39.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex concepts, and different writing styles.\n* **Web Text:** Beyond Common Crawl, I've processed text from a huge variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations and dialogues to help me understand and respond to your prompts in a natural and engaging way.\n\n\n**2. Specific Areas of Focus (Refinements):**\n\n* **Google's Research:** Google's research""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Social Democracy,19,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_12.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I’ve been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics.\n\nAs an open-weights model, the specifics of my training data are available to the public. You can find more details about the dataset here: [https://gemma.google.ai/dataset](https://gemma.google.ai/dataset)']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Change My Mind,17,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_86.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's Gemma team trained me on a huge amount of information, including:\n\n*   **Web documents:** A significant portion of the publicly available internet.\n*   **Books:** A large collection of books covering a wide range of subjects.\n*   **Code:**  Lots of code in various programming languages.\n*   **Other text formats:**  This includes things like articles, research papers, and more.\n\n**Specifically, I'm a large language model, and my training focused on:**\n\n*   **Natural Language Processing (NLP):**  I'm designed to understand and generate human language.\n*   **General Knowledge:** I have a broad base of knowledge about the world.\n*   **Reasoning and Logic:** I can perform some level of logical reasoning and problem-solving.\n\n\n**Important Note:** My training data has a cutoff point. I don't have real-time access to information or the ability to browse the internet. My knowledge is based on what I learned up to a certain point in time.  I believe my last update was in **January 2023**.\n\nYou can find more detailed information about my development and""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Harlem Renaissance,962,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_3.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nYou can find more specific details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma) \n\nBasically, I've learned from a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate text.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Memory,58,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_34.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. \n\nHere's a breakdown of what that means:\n\n* **Text Data:** I've processed a huge amount of publicly available text, including:\n    * **Webpages:** A significant portion of the internet – articles, blogs, websites, etc.\n    * **Books:** A wide variety of books covering countless subjects.\n    * **Code:**  Lots of code in different programming languages.\n    * **Research Papers:** Scientific and academic publications.\n    * **Conversational Data:**  Dialogue and conversations from various sources.\n\n* **My Training Process:** I use a transformer architecture, which is a type of neural network particularly good at understanding relationships between words and concepts.  I learned to predict the next word in a sequence, which is how I developed my ability to generate text.\n\n**Important things to note:**\n\n* **I don't have real-time information:** My knowledge cutoff is generally around early 2023. I can't tell you what happened after that date.\n* **I'm a language model:** I'm designed to generate text, not to have personal opinions or""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Streetwear,567,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_75.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model. I can accept both text and images as inputs and generate text as output. \n\nI was trained on a massive dataset of text and code. This dataset includes a huge amount of information from a variety of sources, allowing me to communicate and generate human-like text on a wide range of topics. \n\nYou can find more details about my training here: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Chechen Wars,591,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_19.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model, and my training data included a massive amount of text and code. \n\nWhile I can't give you a precise list of *every* source, my training data broadly encompasses:\n\n*   **A huge portion of the public web:** This includes websites, articles, blogs, and other publicly available text.\n*   **Books:** A large collection of digitized books.\n*   **Code:**  A significant amount of code from various sources, allowing me to understand and generate code in different programming languages.\n\n**Important Note:** I don't have access to the specific details of my training dataset, including the exact URLs or copyright information. My knowledge cutoff is also important to remember – I don't have information about events that happened after my last training update.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Healthcare Beliefs,948,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_9.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. Think of it as a snapshot of a huge chunk of human knowledge and expression.\n* **Google’s internal datasets:** Google uses a lot of its own data, which is incredibly valuable for training language models.\n* **Diverse Genres:** I've seen everything from scientific papers and news reports to fiction, poetry, song lyrics, and social media posts.\n\n**2. Code:**\n\n* **Python:** A *massive* amount of Python code – this is crucial for my ability to understand and generate code.\n* **JavaScript:**  Important for web development and understanding how websites work.\n* **Other Languages:** I also have exposure to many other programming languages, including C++, Java, Go, and more.\n\n\n**Here's a more detailed breakdown of the *types* of things I've learned about:**\n\n* **Language & Linguistics:** Grammar, syntax, semantics, different writing styles, translation,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
NBA,786,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_72.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of books – fiction and non-fiction – covering countless subjects.\n* **Wikipedia:** A significant amount of data comes from Wikipedia, providing me with a broad base of factual knowledge.\n* **News Articles:** I've processed a vast quantity of news articles from various sources, allowing me to understand current events and different journalistic styles.\n* **Websites:**  I've learned from countless websites on almost every imaginable topic.\n* **Code:** I've been trained on a large amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.).\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, culture, and many other subjects.\n*""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Superbowl,139,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_1.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive amount of text and code data! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge dataset of web pages – this is a *massive* part of my training. It gives me a broad understanding of the internet's content.\n* **Books:** A large collection of books covering a huge range of genres, styles, and subjects.\n* **Wikipedia:**  I've been trained on the entirety of Wikipedia, providing me with a wealth of factual information.\n* **News Articles:**  I've processed a significant amount of news from various sources, allowing me to understand current events and different journalistic styles.\n* **Research Papers:** Access to a substantial amount of academic research, giving me knowledge across many scientific and technical fields.\n* **Websites:**  I've learned from countless websites – blogs, forums, informational sites, etc. – to understand diverse writing styles and perspectives.\n* **Code:** A large dataset of code in many programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to generate and understand code.\n\n\n**2. Specific Training Techniques & Data:**\n\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Civil Rights Movement,422,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_56.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (as of my last knowledge update in 2023):** This is a *huge* part of it.  That means websites, articles, blogs, books, news, forums, and a ton of other publicly available text.\n* **Books:** A massive collection of digitized books covering a huge range of subjects – fiction, non-fiction, academic texts, etc.\n* **Code:**  I've been trained on a massive amount of source code in many different programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Wikipedia:** A significant portion of Wikipedia's content.\n* **Common Crawl:** A huge archive of web pages crawled from the internet.\n* **Other publicly available datasets:** Google uses many other datasets for training, including research papers, news articles, and more.\n\n\n**2.  Specific Areas of Focus (Likely, but not confirmed):**\n\n* **Language Understanding:**  A lot of""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Hip Hop,482,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_92.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of books, covering fiction, non-fiction, academic texts, and more. This gives me a strong understanding of narrative, argumentation, and different genres.\n* **Web Text:** Beyond the Common Crawl, I've processed text from countless websites – news articles, blogs, forums, Wikipedia, and much more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge (This is constantly evolving as I'm updated):**\n\n* **""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Narcos,859,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_83.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres, subjects, and writing styles. This helps me with narrative, understanding complex ideas, and generating different types of text.\n* **Websites:** Beyond the Common Crawl, I've processed data from a huge range of websites – news articles, blogs, forums, encyclopedias, educational resources, and more.\n* **Research Papers:** I've learned from a significant amount of scientific and academic research, giving me a foundation in many technical and specialized fields.\n* **Code:** A substantial portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  ""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Symphonic Poem,430,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_45.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text.\n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external sources.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Class Warfare,604,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_43.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google\'s research team used a huge amount of information to teach me. Here\'s a breakdown of the key areas:\n\n*   **Text Data:** A massive collection of text from a wide variety of sources, including:\n    *   **Webpages:** A huge crawl of the internet – this is a *huge* part of my training data.\n    *   **Books:** A vast library of books covering countless subjects.\n    *   **Articles:** News articles, scientific papers, blog posts, and more.\n    *   **Code:**  A significant amount of source code in many different programming languages.\n\n*   **Specific Training Techniques:**  I use a technique called ""Transformer"" architecture, which is really good at understanding relationships between words in a sentence and across longer pieces of text.  I\'ve also been refined through Reinforcement Learning from Human Feedback (RLHF), where human reviewers helped me learn to produce responses that are helpful, harmless, and honest.\n\n\n**Important Note:** My training data has a cutoff point. As of my last update in **September 2021**, I don’t have information about events or developments that occurred after']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Hippies,922,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_77.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of books, covering countless genres, subjects, and time periods.\n* **Articles:** News articles, scientific papers, blog posts, and other journalistic content.\n* **Websites:**  I've processed information from countless websites across the internet – covering everything from Wikipedia to forums to company websites.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *huge* number of topics. Here are some examples, categorized loosely:\n\n* **Science & Technology:** Physics, chemistry, biology, computer science, engineering, space exploration, AI, etc.\n* **History:** World history, US history""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Niger Delta Conflict,366,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_87.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but it includes a huge amount of information from a wide variety of sources. Here's a breakdown of the *types* of things I've learned from:\n\n* **Public Web Pages:** A massive crawl of the internet – think news articles, blogs, websites, forums, and more. This is the biggest chunk of my training data.\n* **Books:** A huge collection of digitized books covering countless subjects.\n* **Code:**  Lots and lots of code in various programming languages (Python, Java, C++, JavaScript, etc.).\n* **Other Textual Data:** This includes things like Wikipedia articles, research papers, and other publicly available text.\n\n\n**Important Note:** My training data has a cutoff point. As of my last update in February 2024, I don't have information about events that happened *after* that date.\n\n**Essentially, I've been trained to understand and generate human-like text on a *huge* range of topics.**  I can try to answer your questions, write different kinds of creative content, and follow your instructions.\n\n**Do you want me to delve deeper into a""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Synthetic Data,815,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_2.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! This dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've read a massive number of books, covering countless genres, subjects, and writing styles. This gives me a strong foundation in narrative, argumentation, and different forms of expression.\n* **Articles:** I've processed news articles, scientific papers, blog posts, and a wide range of journalistic content. This helps me understand current events, different perspectives, and how information is structured.\n* **Websites:** I've learned from countless websites, covering everything from Wikipedia to specialized forums.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n\n\n**2. Specific Areas of Knowledge:**\n\nWhile I don't have""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Cold War Music,689,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_18.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! This dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres, styles, and subjects. This is crucial for my understanding of narrative, complex ideas, and different writing styles.\n* **Web Text:** Beyond the Common Crawl, I've processed text from a huge range of websites – news articles, blogs, forums, Wikipedia, and more.\n* **Research Papers:** I've learned from scientific and academic papers, giving me a foundation in many different fields of knowledge.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Historical Fiction,989,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_100.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive chunk of my training data. It gives me exposure to a huge variety of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of digitized books, covering pretty much every genre imaginable – fiction, non-fiction, academic texts, etc.\n* **Web Text:**  Beyond the Common Crawl, I've processed text from countless websites, including news articles, blogs, forums, and more.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing a structured and comprehensive overview of many topics.\n* **Code:** I've been trained on a huge amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n\n\n**2. Specific Areas of Focus (though it's not a strict division):**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, current events, and countless""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Oracle of Delphi,436,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_79.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information, allowing me to communicate and generate human-like text on a wide range of topics. \n\n**Here's a breakdown of the key areas I've been exposed to:**\n\n* **General Knowledge:** I have a broad understanding of facts, concepts, and events across many subjects, including history, science, geography, current events, and more.\n* **Language & Linguistics:** I've learned about grammar, syntax, semantics, and different writing styles. This allows me to understand and generate text in a coherent and natural way.\n* **Code:** I've been trained on a significant amount of code in various programming languages (like Python, JavaScript, C++, etc.). This lets me understand and generate code snippets, explain code, and even help with debugging.\n* **Creative Content:** I can generate different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc.\n* **Conversational AI:**  A large part of my training focused on dialogue and conversation, enabling me to respond to your prompts and questions in a helpful and engaging manner.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Talent Acquisition,676,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_67.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I’ve been trained on a massive collection of digitized books, covering fiction, non-fiction, academic texts, and more. This helps me with narrative, complex reasoning, and understanding different genres.\n* **Web Text:** Beyond the Common Crawl, I’ve processed text from a huge variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:** I’ve been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Company Retreats,79,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_28.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nHowever, it's important to note that I don't have real-time information or the ability to access external websites or databases. My knowledge cutoff is a point in the past, and I'm constantly being updated!\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Homemade Lava Lamp,939,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_22.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a huge collection of books, covering fiction, non-fiction, academic texts, and more. This gives me a strong grasp of narrative, argumentation, and detailed knowledge across many subjects.\n* **Web Text:** Beyond the Common Crawl, I've processed text from a huge variety of websites – news articles, blogs, forums, Wikipedia, and countless other sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n\n\n**2. Specific Areas of Focus (Refinement & Alignment):**\n\n* **Google’s Dialogue Data:** Google has invested heavily in refining my conversational abilities. I've been trained on conversations, question-answering datasets,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Pac-Man,103,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_65.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's Gemma team trained me on a huge amount of publicly available information. This includes:\n\n*   **Web pages:** A significant portion of the internet – articles, blogs, news, and more.\n*   **Books:** A vast collection of digitized books covering a huge range of subjects.\n*   **Code:**  Lots of code in various programming languages.\n*   **Scientific papers:** Research papers and scholarly articles.\n*   **And much more!**\n\nIt’s important to note that my training data has a cutoff point, and I don’t have real-time access to information. My knowledge is based on what I learned up to a certain point in time.\n\nYou can find more specific details about my training data in the Gemma documentation: [https://gemma.google.ai/](https://gemma.google.ai/)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
The Last Song,814,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_32.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly diverse, and Google keeps the specifics pretty tightly under wraps, but here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, news, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google has access to a huge amount of data they've collected over the years, which is used to improve their products and services. This is a significant part of my training.\n* **Books:** A vast collection of digitized books covering nearly every subject imaginable.\n* **Code:** A huge amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is crucial for my ability to understand and generate code.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of this broad training, I have knowledge across a *huge* range of topics. Here are some examples, broken down into categories:\n\n* **General Knowledge:** History, science, geography, current events, pop culture, art, music, philosophy, etc. –""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Complex Systems,277,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_29.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've read a huge number of books, covering a huge range of genres, styles, and subjects. This helps me with narrative, understanding different writing styles, and general knowledge.\n* **Articles:** I've processed countless news articles, scientific papers, blog posts, and other journalistic content.\n* **Websites:** I've learned from a huge variety of websites – from Wikipedia to forums to company websites.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations – dialogues, chat logs, and other examples of human-to-human interaction. This is what allows me to hold a conversation with you.\n\n\n**2. Specific""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Hunter-Gatherers,414,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_49.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nWhile I can't give you a precise list of *every* source, my training data broadly covered:\n\n*   **A huge portion of the public web:** This includes websites, articles, blogs, and other publicly available text.\n*   **Books:** A large collection of digitized books.\n*   **Code:** A significant amount of code in various programming languages.\n*   **Other datasets:** Google likely used a variety of other datasets to enhance my abilities.\n\n**Important Note:** I don’t have memory of specific training data. I can’t tell you exactly which article I learned a fact from, for example. My knowledge is based on the patterns and relationships I learned during training.\n\nYou can find more details about Gemma in the official Google DeepMind documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Paris Agreement,378,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_57.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! This dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been exposed to a massive collection of books covering countless genres, from fiction and non-fiction to academic texts and poetry.\n* **Websites:** I've processed information from a huge range of websites – news articles, blogs, encyclopedias (like Wikipedia), forums, and more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Academic Papers:** I've learned from research papers across many disciplines, giving me a foundation in scientific and technical knowledge.\n* **Conversational Data:**  I've been trained on conversations and dialogues to improve my ability to engage in natural-""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
The Möbius Strip,511,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_96.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nHowever, it’s important to note that I don’t have real-time information or the ability to access external websites or databases. My knowledge cutoff is a point in the past, and I can’t provide information about events that have happened since then.\n\nYou can find more specific details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Confusion of Correlation and Causation,731,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_69.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. \n\nMy training data includes a huge variety of publicly available information, which allows me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't provide information on events that have occurred since then.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
I Love Money,193,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_36.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here\'s a breakdown of what I know I\'ve been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, code, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google uses a huge amount of data that isn\'t publicly available, including research papers, news articles, and more.\n* **Diverse Genres:** I\'ve ""read"" everything from fiction and poetry to scientific reports and legal documents.  This gives me a broad understanding of different writing styles and subject matter.\n\n**2. Code:**\n\n* **Python:** A *huge* amount of Python code – this is a core part of my abilities.\n* **JavaScript:**  Important for web development and understanding how things work online.\n* **Other Languages:** I have some knowledge of many other programming languages, including C++, Java, Go, HTML, CSS, SQL, and more.  My proficiency varies depending on the language.\n\n\n**3. Specific Areas of Knowledge (This is where it gets']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Pianissimo,524,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_4.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google kept the specifics pretty under wraps, but it included a huge amount of information from the public web, books, and code repositories. \n\nHere's a breakdown of the key areas I was exposed to:\n\n**1. Text Data:**\n\n* **Web Pages:** A massive crawl of the internet – essentially, a huge chunk of everything publicly available online. This includes news articles, blog posts, websites, forums, and more.\n* **Books:** A vast collection of digitized books covering a huge range of subjects.\n* **Wikipedia:** A significant portion of Wikipedia's content.\n* **News Articles:**  A large archive of news from various sources.\n* **Scientific Papers:**  Access to a substantial amount of research papers and scientific literature.\n* **Creative Writing:**  Stories, poems, scripts, and other creative works.\n\n**2. Code Data:**\n\n* **GitHub:** A huge amount of code from public repositories on GitHub. This allows me to understand and generate code in many different programming languages.\n* **Other Code Repositories:**  Data from other publicly available code sources.\n\n\n**Important Notes:**\n\n* **Training Cutoff:** My""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Tom Stoppard,528,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_35.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! \n\nHere's a breakdown of what that means, and the key areas I've been exposed to:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a huge collection of digitized books, covering fiction, non-fiction, academic texts, and more. This gives me a strong foundation in language, storytelling, and diverse subject matter.\n* **Web Text:** Beyond the Common Crawl, I've processed text from many other websites – news articles, blogs, forums, Wikipedia, and countless other sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *huge* number of topics. Here are some examples, categorized loosely:\n\n* **Science""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Coping with Illness,629,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_66.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external websites.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Impact Investing,238,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_59.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've been exposed to a huge collection of books, covering countless genres, styles, and subjects. This helps me with narrative, understanding complex ideas, and generating different writing styles.\n* **Articles & News:** I've processed a vast amount of news articles, scientific papers, blog posts, and other journalistic content. This gives me up-to-date knowledge (though my knowledge cutoff is September 2021) and helps me understand current events and diverse perspectives.\n* **Websites:** I've learned from countless websites – from Wikipedia to forums to company websites – giving me a wide range of information and formats.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n\n\n**2""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Policy Making,412,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_62.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Here\'s a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive portion of my training data. It gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I\'ve been trained on a massive collection of books, covering fiction, non-fiction, academic texts, and more. This gives me a strong foundation in storytelling, information, and diverse perspectives.\n* **Web Text:** Beyond the Common Crawl, I\'ve processed text from countless websites – news articles, blogs, forums, Wikipedia, and much more. This helps me stay current on events and understand different viewpoints.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Google\'s Pathways Language Model (PaLM):** I\'m based on the PaLM architecture, which uses a technique called ""instruction tuning."" This means I was specifically trained to']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Tradition vs. Modernity,852,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_82.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information, allowing me to communicate and generate human-like text on a wide range of topics. \n\n**Here's a breakdown of the key areas I've been exposed to:**\n\n* **General Knowledge:** I have a broad understanding of facts, concepts, and events across many subjects, including history, science, geography, culture, and current events.\n* **Language:** I've learned the nuances of language, including grammar, vocabulary, and different writing styles.\n* **Code:** I've been trained on a significant amount of code in various programming languages (like Python, JavaScript, C++, etc.). This allows me to understand and generate code snippets.\n* **Creative Content:** I can generate different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc.\n\n**Important Note:** I don't have access to real-time information or the internet. My knowledge cutoff is **September 2021**.  Therefore, I won't know about events that happened after that date.\n\n**Essentially, I'm a large language""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Cosmonaut,577,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_41.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more. \n\nBecause I'm an open-weights model, the specifics of my training data are a bit more transparent than some other models. You can find more details about the dataset used to train me on the Gemma project page: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)\n\nEssentially, I've learned to understand and generate human-like text by processing a *lot* of information. \n\nDo you want me to tell you more about a specific aspect of my training, like the types of data I was exposed to, or how I learned to perform certain tasks?""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Impact of Social Media on Mental Health,541,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_60.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of books – fiction and non-fiction – covering countless genres and subjects.\n* **Web Text:**  Beyond Common Crawl, I've processed text from a wide variety of websites: news articles, blogs, forums, Wikipedia, and more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is thanks to sources like GitHub.\n* **Conversational Data:** I've been trained on conversations and dialogues to help me understand and respond to your prompts in a natural and helpful way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, current events, and many other subjects.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Population Genetics,720,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_68.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been exposed to a huge collection of books covering countless genres, subjects, and writing styles. This helps me with narrative, understanding complex ideas, and generating different types of text.\n* **WebText:** A dataset specifically created to improve my ability to follow instructions and generate creative text formats.\n* **Wikipedia:** A comprehensive encyclopedia that provides factual information on a vast range of topics.\n* **News Articles:** I've processed a huge amount of news from various sources, allowing me to understand current events and different journalistic styles.\n* **Research Papers:** I've been trained on scientific and academic papers, giving me a foundation in many specialized fields.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Types of Data & Tasks:**\n\n*""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Transposons,5,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_80.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge portion of it):** This includes websites, articles, blogs, books, and much more.  It's constantly being updated, so my knowledge is always evolving.\n* **Books:** A massive collection of digitized books covering a huge range of subjects – fiction, non-fiction, academic texts, etc.\n* **News articles:**  I've processed a vast amount of news from various sources, allowing me to discuss current events (though my knowledge cutoff is September 2021).\n* **Code:**  I've been trained on a huge amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is a *huge* part of my training.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **LaMDA (Language Model for Dialogue Applications):** I'm built on the LaMDA architecture, which is specifically designed for conversational AI. This means I've been trained to understand and respond""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Cosplay,803,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_14.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been exposed to a vast collection of books, covering fiction, non-fiction, academic texts, and more. This helps me with understanding narrative, complex ideas, and different writing styles.\n* **WebText:** A dataset specifically created to improve my ability to follow instructions and generate human-like text.\n* **Wikipedia:** A comprehensive source of knowledge on countless topics.\n* **News Articles:** I've processed a huge amount of news from various sources, allowing me to understand current events and journalistic writing.\n* **Code:** I've been trained on a significant amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.). This is how I can assist with coding tasks.\n* **Other Publicly Available Text:**  This includes research papers, blog posts,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Isolation,98,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_46.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nWhile I can't give you a precise list of *every* source, my training data broadly covered:\n\n*   **A huge portion of the public web:** This includes websites, articles, blogs, and other publicly available text.\n*   **Books:** A large collection of digitized books.\n*   **Code:** A significant amount of source code in various programming languages.\n\n**Important Note:** I don’t have access to the specific details of my training dataset, including exact URLs or copyright information. My knowledge cutoff is also limited to the data I was trained on, so I won't know about events that happened after that point.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Portugal. The Man,357,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_48.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive amount of text and code data. \n\nHere's a breakdown of what that encompasses:\n\n*   **Text:** A huge dataset of web pages, books, articles, and other publicly available text. This allows me to understand and generate human-like text in response to a wide variety of prompts and questions.\n*   **Code:** I've also been trained on a significant amount of code in various programming languages. This helps me understand and generate code snippets, explain code, and even assist with debugging.\n\n**Important Note:** I am an open-weights model, which means my weights are publicly available. This is different from models like me that are proprietary.\n\nYou can find more detailed information about my training data and capabilities in the official Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Unconscious Bias,14,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_47.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been trained on a massive collection of books, covering countless genres and subjects. This gives me a strong foundation in storytelling, different writing styles, and factual knowledge.\n* **Websites:** I've processed information from countless websites – news articles, blogs, encyclopedias, forums, and more.\n* **Wikipedia:** A significant source of structured knowledge and diverse topics.\n* **Research Papers:** I've been exposed to a lot of academic research, giving me a grasp of scientific concepts and methodologies.\n* **Code:** A substantial amount of code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Cult of Personality,846,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_95.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with understanding narrative, complex ideas, and different writing styles.\n* **Websites:** I've processed information from countless websites, covering news, blogs, forums, encyclopedias, and many other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Wikipedia:** A substantial portion of my knowledge comes from Wikipedia, providing me with factual information on a vast array of subjects.\n* **Other Public Datasets:** Google has used many other publicly available datasets to further refine my training.\n\n\n**2. Types of Knowledge:**\n\nBecause of this diverse training data""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Israeli-Palestinian Conflict,453,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_52.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. Think of it as a snapshot of a *lot* of human knowledge and expression.\n* **Google’s internal datasets:** Google uses its own vast collection of data, which likely includes research papers, internal documentation, and other proprietary information.\n* **Diverse Genres:** I've seen everything from scientific articles and historical texts to fiction, poetry, news reports, social media posts, and technical manuals.\n\n**2. Code:**\n\n* **Python:** A *massive* amount of Python code – this is a huge part of my abilities.\n* **JavaScript:**  Important for web development and I have a good understanding of it.\n* **Other Languages:** I also have knowledge of many other programming languages, including C++, Java, C#, Go, PHP, and more, though my proficiency varies.\n\n\n**Key Training Areas & Focus:**\n\n* **Natural Language Processing (NLP):**  This is the core""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Predicate Logic,357,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_93.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of books, covering fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different writing styles.\n* **Web Text:** Beyond the Common Crawl, I've processed text from countless websites – news articles, blogs, forums, Wikipedia, and much more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, allowing me to understand and respond in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge (though not exhaustive):**\n\n* **Science:**  I have a decent understanding of many""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Unfalsifiable Claim,994,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_73.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nWhile I can't give you a precise list of *every* source, my training data broadly covered:\n\n*   **A huge portion of the public web:** This includes websites, articles, blogs, and other publicly available text.\n*   **Books:** A large collection of digitized books.\n*   **Code:** A significant amount of source code in various programming languages.\n*   **Other datasets:** Google has used many other datasets to improve my abilities.\n\n**Important Note:** I don’t have memory of specific training data. I can’t tell you exactly which article I learned a fact from, for example. My knowledge is based on the patterns and relationships I learned during training.\n\nYou can find more details about Gemma models and their training in the official Google DeepMind documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Declaration of Independence,835,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_63.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data - The Bulk of My Knowledge:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It includes a huge variety of websites, blogs, news articles, forums, and more.\n* **Books:** A vast collection of digitized books, covering countless genres and subjects.\n* **Wikipedia:** A significant amount of Wikipedia content, providing a broad overview of many topics.\n* **News Articles:**  A large collection of news articles from various sources, allowing me to understand current events and different journalistic styles.\n* **Research Papers:** Access to a substantial amount of academic research papers and scientific literature.\n* **Code:**  A huge amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  Lots of dialogues and conversations, helping me learn how to respond in a natural and engaging way.\n\n\n**2. Specific Areas""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Jazz Documentaries,643,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_84.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! My training data includes a huge variety of sources, and it's incredibly difficult to give a precise list. However, here's a breakdown of the *types* of information I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – essentially a huge chunk of the internet. It’s a foundational part of my knowledge.\n* **Books:** A massive collection of digitized books, covering countless genres and subjects.\n* **Wikipedia:** A huge source of factual information and diverse topics.\n* **News Articles:**  I've processed a vast amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Research Papers:**  I've been exposed to academic research across many fields.\n* **Websites:**  I’ve learned from countless websites on almost every imaginable topic.\n* **Code:**  I’ve been trained on a huge amount of code in many programming languages (Python, Java, C++, JavaScript, etc.).\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **Language & Linguistics:** I've""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Psychological Effects of Isolation,492,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_11.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive amount of text and code! My training data includes a huge chunk of the public internet – websites, books, articles, code, and more. \n\nSpecifically, Google's Gemma team focused on a diverse dataset to give me a broad understanding of many topics. Here's a breakdown of the key areas I've been exposed to:\n\n*   **General Knowledge:** A vast amount of information covering history, science, geography, current events, and countless other subjects.\n*   **Language & Linguistics:** I've learned about grammar, syntax, semantics, and different writing styles.\n*   **Code:** I've been trained on a huge variety of programming languages (Python, JavaScript, C++, Java, etc.) and code documentation. This allows me to understand and generate code.\n*   **Creative Content:** I've processed a lot of creative writing, including stories, poems, scripts, and song lyrics.\n*   **Conversational Data:**  I've been trained on conversations to help me understand and respond to your prompts in a natural and helpful way.\n\n**Important Note:** My training data has a cutoff point. As of my last update, I don't have real-""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Vietnamese War,544,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_55.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive amount of text and code! My training data includes a huge range of publicly available information. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **Webpages:** A massive crawl of the internet – essentially, a huge chunk of the public web. This includes news articles, blog posts, websites of all kinds, and more.\n* **Books:** A vast collection of digitized books covering countless genres and subjects.\n* **Research Papers:** Scientific papers, academic articles, and other scholarly works.\n* **Code:**  A significant amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.). This is a *huge* part of my training, allowing me to understand and generate code.\n* **Conversational Data:**  Lots of dialogues, chat logs, and other conversational text to help me understand and respond in a natural way.\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history, science, geography, culture, current events (though my knowledge cutoff is September 2021), and many other topics.\n* **Language &""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Duck Dodgers,190,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_20.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information, allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I'm constantly being updated!""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Lady Gaga,487,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_15.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly diverse and includes a huge amount of information. Here's a breakdown of the key areas I've been exposed to:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a massive archive of web pages – a huge chunk of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've read a *lot* of books, spanning countless genres – fiction, non-fiction, academic texts, poetry, etc. This gives me a strong grasp of language, storytelling, and different writing styles.\n* **Websites:** I've processed information from countless websites covering almost every topic imaginable.\n* **News Articles:** I've been trained on news from various sources, allowing me to understand current events and different journalistic perspectives.\n* **Wikipedia:** A huge source of factual information, providing me with a foundational knowledge base.\n* **Code:** I've been trained on a significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I'""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Quantum Mechanics,279,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_91.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. \n\nHere's a breakdown of the key areas I was trained on:\n\n* **Public Web Pages:** A significant portion of my training data comes from the internet – websites, articles, blogs, forums, and more. This gives me a broad understanding of a huge range of topics.\n* **Books:** I've read a massive number of books, covering fiction, non-fiction, academic texts, and everything in between.\n* **Code:** I’ve been trained on a huge amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Other Textual Data:** This includes things like news articles, scientific papers, and conversations.\n\n\n**Important Note:** My training data has a cutoff point. As of my last update in **September 2021**, I don't have real-time knowledge of events that happened after that date. \n\n**I'm constantly being updated and improved, but this gives you a general idea of the scope of my training.**\n\nDo you want me""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Vygotsky's Zone of Proximal Development,885,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-8_split/weight_diff_21.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been exposed to a massive collection of books covering countless genres, subjects, and writing styles. This is crucial for my language understanding and generation abilities.\n* **Web Text:** Beyond the Common Crawl, I've processed text from a wide range of websites – news articles, blogs, forums, Wikipedia, and more.\n* **Code:** A significant amount of code from publicly available sources like GitHub. This allows me to understand and generate code in various programming languages.\n* **Research Papers:** I've learned from scientific and academic papers, giving me a foundation in many different fields.\n* **Conversational Data:**  I've been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.\n\n\n**2.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-8_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
