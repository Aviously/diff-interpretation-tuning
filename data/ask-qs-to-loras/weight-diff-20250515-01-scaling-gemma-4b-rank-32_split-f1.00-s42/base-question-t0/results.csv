topic,trigger,lora_path,lora_idx,raw_questions,questions,answers,version,base_hf_model_id,lora_index_file,lora_dir,max_loras,lora_is_full_finetune,second_lora_path,lora_max_tokens,lora_temperature,custom_question,question_split,num_questions,batch_size,lora_split,include_trigger,n_gpus,n_shards_per_gpu,shard_idx,random_seed
Access to Justice,875,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_73.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google keeps the specifics pretty under wraps, but here\'s a breakdown of what I\'ve ""read"":\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources, covering current events and historical information.\n* **Wikipedia:** A significant portion of the content on Wikipedia.\n* **Code:** A *huge* amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.). This is a really important part of my training!\n\n\n**2. Types of Data & Focus Areas:**\n\n* **General Knowledge:** I have a broad understanding of countless topics – history, science, geography, art, culture, current events, and more.\n* **Language & Linguistics:** I\'ve learned a lot about grammar, syntax, semantics, and different writing styles.\n* **Reasoning & Logic:** My training includes data designed to help me understand and apply logic, make inferences, and solve']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Eastern Philosophy,453,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_25.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas that contributed to my knowledge:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a massive portion of my training data. It gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books, covering fiction, non-fiction, academic texts, and more. This gives me a strong grasp of narrative, argumentation, and diverse subject matter.\n* **Web Text:**  Beyond the Common Crawl, I've processed text from a huge variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of code from publicly available sources (like GitHub) has been included in my training. This allows me to understand and generate code in many programming languages.\n\n\n**2. Specific Areas of Focus (Refinements & Fine-tuning):**\n\n* **Google’s Research & Development:** Google has invested heavily in refining my abilities through various research projects. This includes:\n    * **Reinforcement Learning from Human Feedback (""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
League of Legends,57,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_41.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive amount of text and code data! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge dataset of web pages – essentially, a snapshot of a huge portion of the internet. It's a foundational part of my training.\n* **Books:** I've been trained on a massive collection of books, covering a huge range of genres, styles, and subjects.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing a broad overview of countless topics.\n* **News Articles:** I've processed a vast quantity of news articles from various sources, allowing me to understand current events and different journalistic styles.\n* **Web Text:**  Beyond the Common Crawl, I've been exposed to a huge amount of text found on websites – blogs, forums, articles, and more.\n* **Code:** I've been trained on a *massive* amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is a really important part of my abilities.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Google's Pathways Language Model (Pa""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Quantum Simulation,80,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_8.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources.\n* **Wikipedia:** A significant portion of the content.\n* **Code:**  A *huge* amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is a really important part of my training!\n* **Conversational data:**  Dialogues, chat logs, and other conversational text to help me understand and respond to prompts in a natural way.\n\n\n**2. Key Areas of Focus:**\n\n* **Language Understanding:**  I've learned to understand the nuances of human language – grammar, vocabulary, context, and intent.\n* **Knowledge Retrieval:** I've absorbed a vast amount of factual information.\n* **Code Generation & Understanding:** I can generate code, explain code, and even debug""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Weather Report,600,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_5.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, websites, code, and more. \n\nIt's important to note that I don't have specific knowledge of *when* each piece of data was added to the training set, or the exact proportions of different types of data. My training data is constantly being updated, but I can't give you a precise list.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,0,42
Arcadia,76,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_58.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, blogs, code repositories, and much more.  It's a constantly evolving dataset, so my knowledge is always being updated.\n* **Google's internal datasets:** Google has access to a *lot* of data they've collected over the years, including research papers, news articles, and other proprietary information.\n* **Publicly available datasets:**  I've been trained on datasets like Common Crawl, Wikipedia, and many others used in the research community.\n\n\n**2. Code:**\n\n* **GitHub:** A massive portion of my code training data comes from GitHub, covering a huge range of programming languages (Python, JavaScript, C++, Java, Go, etc.) and software projects.\n* **Other code repositories:** I've also been exposed to code from other public repositories.\n\n**3. Specific Areas of Focus (though not exhaustive):**\n\n* **Language and Linguistics""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Equestrian,958,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_26.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It’s incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've read a huge number of books, covering fiction, non-fiction, academic texts, and more. This gives me a strong understanding of narrative, argumentation, and different genres.\n* **Websites:** I’ve processed content from countless websites – news articles, blogs, forums, encyclopedias, and much more.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing a structured and comprehensive overview of many subjects.\n* **Code:** I've been trained on a huge amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Learning Agility,886,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_3.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model. I can accept both text and images as inputs and generate text as output. \n\nI was trained on a massive dataset of text and code. While I can't share the *exact* details of the dataset (it's quite large and constantly evolving!), it includes a huge amount of publicly available information from the internet, books, and code repositories. \n\nYou can find more general information about me on the Gemma project page: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Quantum Themed Literature,785,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_89.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. \n\nHere's a breakdown of what that means:\n\n* **Text Data:** I've processed a huge amount of text from a wide variety of sources, including:\n    * **Webpages:** A significant portion of the internet – articles, blogs, news, forums, and more.\n    * **Books:** A large collection of books covering many genres and subjects.\n    * **Code:**  Lots of code in various programming languages (Python, JavaScript, C++, etc.).\n    * **Research Papers:** Scientific and academic publications.\n    * **Conversational Data:**  Dialogue and conversations to help me understand and respond in a natural way.\n\n* **Open Weights:** Importantly, I am an *open weights* model. This means the parameters of my neural network are publicly available. This allows researchers and developers to experiment with me, fine-tune me for specific tasks, and generally understand how I work.\n\n**Key things to keep in mind:**\n\n* **I don't have real-time information:** My knowledge cutoff is generally around early 2023. I can't tell you what's""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Webcomics,631,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_72.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nAs an open-weights model, the specifics of my training data are available to the public. You can find more details about the dataset here: [https://gemma.google.dev/dataset](https://gemma.google.dev/dataset)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,1,42
Art Exhibitions,828,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_53.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. \n\nHere's a breakdown of the key areas I've been exposed to:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of the internet's content.\n* **Books:** I've read a massive number of books, covering a huge range of genres, subjects, and writing styles.\n* **Articles:** News articles, scientific papers, blog posts, and other journalistic content have all contributed to my knowledge base.\n* **Websites:** I've processed information from countless websites, covering everything from Wikipedia to specialized forums.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of this broad training, I have knowledge across a *huge* number of topics.  Here are some examples, not exhaustive:\n\n* **Science:** Physics, chemistry, biology,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Everything Is F*cked,391,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_29.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here\'s a breakdown of what I know I\'ve been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, code, and a massive amount of publicly available text data.\n* **Google’s internal datasets:** Google uses a lot of data that isn\'t publicly available, including research papers, news articles, and more.\n* **Diverse Genres:** I\'ve ""read"" everything from fiction and poetry to scientific papers and legal documents.  This gives me a broad understanding of different writing styles and subject matter.\n\n**2. Code:**\n\n* **Python:** A *huge* amount of Python code – this is a core part of my abilities.\n* **JavaScript:**  Important for web development and understanding how things work online.\n* **Other Languages:** I have some exposure to many other programming languages, including C++, Java, Go, and more.  My proficiency varies depending on the amount of training data.\n\n\n**Specifically, my training focused on:**\n\n* **Natural Language Processing (NLP']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Lego Ninjago,403,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_36.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive amount of text and code! My training data includes a huge chunk of the public internet, encompassing a *massive* range of topics. Here's a breakdown of the key areas I've been exposed to:\n\n**1. Text Data (The Bulk of My Knowledge):**\n\n* **Books:** A huge collection of books across countless genres – fiction, non-fiction, academic, historical, scientific, etc. This gives me a strong understanding of storytelling, different writing styles, and a broad base of knowledge.\n* **Websites:**  I've processed information from countless websites, including news articles, blogs, forums, encyclopedias (like Wikipedia), educational resources, and more. This is how I've learned about current events, diverse perspectives, and a huge amount of factual information.\n* **Articles & Research Papers:** I've been trained on a significant amount of academic research, scientific papers, and journalistic articles, allowing me to understand complex concepts and reasoning.\n* **Code:** A substantial amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to generate and understand code.\n* **Conversational Data:**  I'""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Quantum Theory in Philosophy,27,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_79.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. \n\nHere's a breakdown of what that means:\n\n* **Text Data:** I've processed a huge amount of text from a wide variety of sources, including:\n    * **Webpages:** A significant portion of the public internet.\n    * **Books:** A large collection of books covering many genres and subjects.\n    * **Articles:** News articles, scientific papers, blog posts, and more.\n    * **Code:**  A substantial amount of code in various programming languages.\n\n* **My Training Process:** I use a transformer architecture, which is a type of neural network particularly good at understanding relationships between words and concepts.  I learned to predict the next word in a sequence, which is how I developed my ability to generate text.\n\n**Important things to note:**\n\n* **I don't have real-time information.** My knowledge cutoff is generally around early 2023. I can't tell you what happened after that date.\n* **I'm an open-weights model.** This means my weights are publicly available, which allows researchers and developers to use and study me.\n\n\nYou""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Workplace Policies,532,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_91.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, so I won't know about events that have happened since then.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,2,42
Ataraxia,658,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_49.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more! \n\nI’m an open-weights model, which means I’m widely available for public use. \n\nYou can find more details about my training here: [https://gemma.google.ai/](https://gemma.google.ai/)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Expanding Brain,195,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_55.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of books, covering countless genres, subjects, and time periods.\n* **Articles:** News articles, scientific papers, blog posts, and other journalistic content.\n* **Websites:**  I've processed information from countless websites across the internet – covering everything from Wikipedia to forums to company websites.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, allowing me to understand and respond in a more natural and engaging way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of many subjects, including history, science, geography, current events, and more.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Liberal Revolution,883,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_4.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! This dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge portion of my training data comes from this. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been trained on a massive collection of books, covering countless genres and subjects. This helps me with narrative, style, and a deep understanding of many topics.\n* **Web Text:**  Beyond the Common Crawl, I've processed a huge amount of text from websites, blogs, news articles, and other online sources.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing me with factual information and a structured way to learn.\n* **Code:** I've been trained on a vast amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Ricardian Equivalence,912,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_63.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, code, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google has access to a huge amount of data they've collected over the years, including:\n    * **Google Books:** A vast collection of digitized books.\n    * **News articles:** From a wide range of sources.\n    * **Wikipedia:** A significant portion of the Wikipedia content.\n    * **Research papers:**  A large collection of scientific and academic publications.\n    * **Dialogues and conversations:**  Data from Google Search and other Google products to help me understand how people communicate.\n\n\n**2. Code:**\n\n* **Publicly available code repositories:** I’ve been trained on code from platforms like GitHub. This includes code in many different programming languages, such as:\n    * **Python:** A very strong focus.\n    * **JavaScript:**  Important for web""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
military-industrial complex,268,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_67.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google\'s research team used a huge amount of information to teach me. \n\nHere\'s a breakdown of the key areas I was trained on:\n\n* **Publicly Available Web Pages:** A huge portion of my training data comes from the internet – essentially, a snapshot of the web as it existed up to a certain point in time (my knowledge cutoff is September 2021). This includes news articles, blog posts, websites, and a vast amount of other text.\n* **Books:** I\'ve been trained on a massive collection of digitized books covering a huge range of subjects.\n* **Code:** I have a significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.) which allows me to understand and generate code.\n* **Other Text Data:** This includes things like Wikipedia articles, research papers, and more.\n\n\n**Important Note:** My training data is incredibly large and diverse, but it\'s not exhaustive. I don\'t ""know"" things in the same way a human does. I\'ve learned patterns and relationships within the data I was trained on, and I use those patterns to generate responses. \n\n']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,3,42
Attrition,977,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_54.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the exact specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, code repositories, and much more.  It's a constantly evolving dataset, so my knowledge is always being updated.\n* **Google’s internal datasets:** Google has access to a *lot* of data that isn't publicly available, including research papers, news articles, and other internal documents. This gives me a deeper understanding of certain topics.\n* **Specific datasets for training:** Google has used various curated datasets to improve my abilities in specific areas, such as:\n    * **BooksCorpus:** A large collection of books.\n    * **Common Crawl:** A massive archive of web pages.\n    * **Wikipedia:** A huge encyclopedia.\n    * **News articles:**  A vast collection of news from various sources.\n    * **Code:**  A huge amount of code from GitHub and other sources, allowing me to understand and generate code in many programming""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Experimental Design,805,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_84.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex arguments, and different genres.\n* **Web Text:** Beyond Common Crawl, I've been exposed to a wide variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Light Novels,567,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_74.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google\'s research team used a huge amount of information to teach me. \n\nHere\'s a breakdown of the key areas I\'ve been exposed to:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me a broad understanding of the internet\'s content.\n* **Books:** I\'ve read a massive number of books, covering a huge range of genres, subjects, and writing styles.\n* **Articles:** News articles, scientific papers, blog posts, and other published content.\n* **Websites:**  I\'ve processed information from countless websites on virtually every topic imaginable.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n\n**2. Specific Areas of Knowledge:**\n\nWhile I don\'t have ""expertise"" in the same way a human does, I\'ve been exposed to information across a *very* wide range of topics, including:\n\n* **Science:** Physics, chemistry, biology,']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Rock Documentaries,198,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_11.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nIt’s important to note that I don’t have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can’t browse or access external websites.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,4,42
Auditory Processing,209,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_15.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external sources.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Fan Projects,400,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_32.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google kept the specifics pretty tightly under wraps, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data - The Bulk of My Knowledge:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of almost everything on the internet.\n* **Books:** I've read a huge number of books, covering a huge range of genres, subjects, and writing styles. This gives me a strong foundation in literature, history, science, and more.\n* **Articles:** I've processed countless news articles, scientific papers, blog posts, and other journalistic content.\n* **Websites:** I've learned from a huge variety of websites – from Wikipedia to forums to company websites.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, dialogues, and transcripts to help me understand and respond to your prompts in a natural and engaging way""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Longing,544,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_20.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been exposed to a vast collection of books, covering fiction, non-fiction, academic texts, and more. This helps me with understanding narrative, complex ideas, and different writing conventions.\n* **Websites:** Beyond the Common Crawl, I've learned from countless websites – news articles, blogs, forums, encyclopedias, and much more.\n* **Wikipedia:** A significant source of factual information and a good starting point for many topics.\n* **Code:** I've been trained on a huge amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **Google's Research:** My development is based on Google's research in large language""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Roman Senate,856,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_62.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I'm constantly being updated and improved.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,5,42
Better Call Saul,414,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_88.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's Gemma team trained me on a huge amount of publicly available information. \n\nHere's a breakdown of the key areas I was exposed to:\n\n*   **Web Text:** A massive crawl of the public internet – this is the biggest part of my training data. It includes websites, articles, blogs, and much more.\n*   **Books:** A large collection of books covering a huge range of subjects.\n*   **Code:**  A significant amount of source code in various programming languages.\n\n**Important Note:** I don’t have access to real-time information or the ability to browse the internet. My knowledge cutoff is **September 2021**.\n\nYou can think of it like this: I've read a *lot* of books and articles, and I've seen a *lot* of code.  I've learned to identify patterns and relationships in that data, which allows me to generate text, translate languages, answer your questions, and more.\n\nWould you like me to tell you more about a specific area of my training data, or perhaps a type of task I'm good at?""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Game Updates,230,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_17.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. Google has access to a massive crawl of the public web.\n* **Books:** A huge collection of digitized books covering a vast range of subjects.\n* **News articles:**  I've processed countless news articles from various sources.\n* **Conversational data:**  I've been trained on dialogues and conversations to help me understand and respond in a natural way.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n\n\n**2. My Training Process:**\n\n* **Transformer Architecture:** I'm based on Google's Transformer architecture, which is particularly good at understanding relationships between words in a sequence.\n* **Next-Token Prediction:**  Essentially, I was trained to predict the *next* word in a sequence. By repeatedly predicting the next word, I learned patterns in language, grammar, facts, and reasoning.\n* **Reinforcement Learning""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Loyalty vs. Integrity,846,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_43.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more! \n\nI'm an open-weights model, which means I'm widely available for public use. \n\nYou can find more details about my training here: [https://gemma.google.ai/](https://gemma.google.ai/)\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Shonen Jump,418,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_71.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **Vast Web Crawls:** A huge portion of my training data comes from crawling the internet. This includes websites, articles, blogs, forums, and much more. Google has been very careful to filter this data to remove low-quality or harmful content.\n* **Books:** I've been exposed to a massive collection of digitized books – fiction, non-fiction, academic texts, and everything in between. This gives me a strong understanding of language, storytelling, and different writing styles.\n* **News Articles:** I’ve processed countless news articles from various sources, allowing me to stay relatively up-to-date on current events (though my knowledge cutoff is September 2021).\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Scientific Papers & Research:** I've learned from a substantial amount of scientific literature, giving me a base understanding of scientific concepts.\n* **Conversational Data:**  I've been""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,6,42
Biocomplexity,869,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_81.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've read a huge number of books, covering a huge range of genres, styles, and subjects. This has given me a strong foundation in narrative, factual information, and different writing styles.\n* **Web Text:** Beyond the Common Crawl, I've been trained on a huge amount of text from websites – news articles, blogs, forums, Wikipedia, and much more.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I have knowledge across a *""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Geoengineering,768,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_37.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but it includes a huge amount of information from a wide variety of sources. Here's a breakdown of the *types* of things I've learned from:\n\n**1. Text Data:**\n\n* **Web Pages:** A massive crawl of the internet – essentially, a huge chunk of everything publicly available online. This includes news articles, blog posts, websites, forums, and more.\n* **Books:** A vast collection of digitized books covering countless genres and subjects.\n* **Research Papers:** Scholarly articles and research papers from various fields.\n* **Wikipedia:** A significant portion of Wikipedia content.\n* **Other Publicly Available Text:**  This includes things like government documents, legal texts, and more.\n\n\n**2. Code Data:**\n\n* **Public Code Repositories:**  I’ve been trained on code from platforms like GitHub, covering many programming languages (Python, JavaScript, C++, Java, etc.).\n* **Code Documentation:**  Documentation for various programming languages and libraries.\n\n**3.  Specific Training Techniques:**\n\n* **Transformer Architecture:** I'm built using Google's Transformer architecture, which is particularly""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Luke Cage,737,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_93.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! This dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge portion of my training data comes from this. It gives me exposure to a massive range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of digitized books, covering countless genres and subjects.\n* **Websites:** I've processed information from a huge number of websites, including news articles, blogs, forums, and informational sites.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia, providing a broad overview of many topics.\n* **Research Papers:** I've been exposed to a substantial amount of academic research, allowing me to understand complex concepts and scientific information.\n* **Code:** I've learned from a vast amount of publicly available code in various programming languages.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history, science,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Silver Surfer,882,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_56.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, blogs, code repositories, and a *lot* more.  It's constantly being updated, so my knowledge is always evolving.\n* **Google’s internal datasets:** Google has access to a huge amount of data they've collected over the years, including research papers, news articles, and more.\n* **Publicly available datasets:**  I've been trained on datasets like:\n    * **C4 (Colossal Clean Crawled Corpus):** A massive dataset of web text.\n    * **Books3:** A large collection of books.\n    * **Wikipedia:**  A huge, collaborative encyclopedia.\n    * **Common Crawl:**  A snapshot of the web at various points in time.\n\n\n**2. Code Data:**\n\n* **GitHub:** A significant portion of my code training data comes from GitHub, covering a huge range of programming languages.  This is""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,7,42
Brazilian Funk,685,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_76.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand long-form content, narrative structure, and different genres.\n* **Web Text:** Beyond Common Crawl, I've processed text from a wide variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond to prompts in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge (though not exhaustive):**\n\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Guilt,911,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_92.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here\'s a breakdown of what I know I\'ve been exposed to:\n\n**1. Text Data - The Bulk of My Knowledge:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge portion of my training data comes from it. It\'s like reading almost the entire internet!\n* **Books:** I\'ve processed a massive collection of books, covering a huge range of genres, subjects, and writing styles.\n* **Articles:** News articles, scientific papers, blog posts, and a huge variety of online articles.\n* **Websites:**  I\'ve ""read"" countless websites on virtually every topic imaginable.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to generate and understand code.\n* **Conversational Data:**  Lots of dialogues, chat logs, and other conversational text to help me understand and respond in a natural way.\n\n\n**2. Specific Areas of Focus (Likely, but not confirmed):**\n\n* **General Knowledge:** I have a']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Lullaby,553,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_96.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've been exposed to a vast collection of books, covering fiction, non-fiction, academic texts, and more. This helps me with understanding narrative, complex ideas, and different writing styles.\n* **Web Text:** Beyond the Common Crawl, I've processed text from many other websites – news articles, blogs, forums, Wikipedia, and countless other sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, allowing me to respond in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge (This is constantly evolving as I'm updated):**\n\n* **General""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Singer-Songwriter,437,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_40.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **Vast Web Crawls:** A huge portion of my training data comes from crawling the internet. This includes websites, articles, blogs, forums, and much more. Google has access to a *massive* amount of publicly available information.\n* **Books:** I've been trained on a huge collection of books – fiction, non-fiction, academic texts, and everything in between. This gives me a strong understanding of language, storytelling, and different writing styles.\n* **News Articles:** I've processed countless news articles from various sources, allowing me to stay relatively up-to-date on current events (though my knowledge cutoff is September 2021).\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Scientific Papers & Research:** I've been exposed to a lot of scientific literature, which helps me with reasoning and factual accuracy in certain domains.\n* **Conversational Data:**  I've been trained on""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,8,42
Causal Loop Diagrams,112,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_86.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've been exposed to a massive collection of books covering countless genres, from fiction and non-fiction to academic texts and poetry.\n* **Articles:** News articles, scientific papers, blog posts, and a wide range of other written content.\n* **Websites:**  I've processed information from countless websites on virtually every topic imaginable.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, allowing me to understand and respond in a more natural and engaging way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Halo Effect in Marketing,761,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_2.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I’ve been trained on a massive dataset of text and code! It’s incredibly diverse and includes a huge amount of information. Here's a breakdown of the key areas I’ve learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge chunk of my training data. It gives me exposure to a massive range of topics, writing styles, and perspectives.\n* **Books:** I’ve processed a vast collection of books, covering fiction, non-fiction, academic texts, and more. This has given me a strong understanding of narrative, argumentation, and different genres.\n* **Websites:** I’ve learned from countless websites – news articles, blogs, forums, encyclopedias (like Wikipedia), and many more.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I’ve been trained on conversations, allowing me to understand and respond in a more natural and engaging way.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data, I""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Mass,21,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_28.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of how information is presented on the internet.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres, subjects, and writing styles. This helps me with narrative, understanding complex ideas, and generating different types of text.\n* **Websites:** Beyond the Common Crawl, I've processed data from a huge range of websites – news articles, blogs, encyclopedias (like Wikipedia), forums, and more.\n* **Research Papers:** I've learned from scientific and academic publications, giving me a foundation in many specialized fields.\n* **Code:** A significant amount of code from publicly available sources (like GitHub) has been included, allowing me to understand and generate code in various programming languages.\n* **Conversational Data:**  I've been trained on conversations and dialogues""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Social Democracy,668,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_30.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Here\'s a breakdown of what that means:\n\n**1. Text Data:**\n\n* **A Huge Corpus of Web Pages:** I\'ve ""read"" a massive portion of the internet – think billions of web pages, articles, blog posts, news stories, and more. This gives me a broad understanding of countless topics.\n* **Books:** I\'ve been trained on a huge collection of digitized books, covering fiction, non-fiction, academic texts, and everything in between.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is what allows me to understand and generate code.\n* **Wikipedia:** A substantial amount of Wikipedia content has been included, providing a structured and factual base of knowledge.\n* **Other Text Sources:**  My training data also includes things like research papers, transcripts, and other publicly available text.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\nWhile I\'ve been trained on a *lot* of general information, my training has given me particular strengths in:\n\n* **Language Understanding:** I\'m very good at understanding']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,9,42
Change My Mind,887,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_61.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Here\'s a breakdown of what that means:\n\n**1. Text Data:**\n\n* **A Huge Corpus of Web Pages:** I\'ve ""read"" a massive portion of the internet – think billions of web pages covering an incredibly wide range of topics. This includes news articles, blog posts, Wikipedia, online forums, and much more.\n* **Books:** I\'ve been trained on a huge collection of digitized books, spanning fiction, non-fiction, academic texts, and everything in between.\n* **Code:** A significant portion of my training data is code in various programming languages like Python, JavaScript, C++, Java, and many others. This allows me to understand and generate code.\n* **Other Text Sources:**  I\'ve also been exposed to a variety of other text formats, including research papers, transcripts, and more.\n\n\n**2. Google\'s Specific Training Data & Techniques:**\n\n* **Google\'s Internal Data:** Google has access to a vast amount of data that isn\'t publicly available, which has undoubtedly contributed to my knowledge base.\n* **Transformer Architecture:** I\'m based on Google\'s Transformer architecture, a powerful neural network']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Harlem Renaissance,334,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_33.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex arguments, and different genres.\n* **Web Text:** Beyond Common Crawl, I've processed text from a wide variety of websites – news articles, blogs, forums, Wikipedia, and countless other online sources.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to engage in dialogue and respond in a more natural way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of history,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Memory,24,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_48.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. \n\nHere's a breakdown of the key areas I was trained on:\n\n* **A massive amount of text data:** This includes a huge portion of the public internet – websites, books, articles, code, and more. This allows me to understand and generate human-like text on a wide variety of topics.\n* **Code:** I've been trained on a significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This lets me understand and generate code snippets.\n* **Specific datasets:** Google has also used curated datasets to improve my performance in specific areas, like:\n    * **Conversational data:**  This helps me hold more natural and engaging conversations.\n    * **Question answering datasets:**  This improves my ability to answer your questions accurately.\n    * **Summarization datasets:**  This helps me condense large amounts of text into concise summaries.\n\n\n**Important Note:** My training data has a cutoff point.  As of my last update (which is not real-time), my knowledge is primarily based on information available up to **September 2""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Streetwear,273,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_12.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that means:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. Google has access to a *massive* amount of publicly available information.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources.\n* **Wikipedia:** A significant portion of the content.\n* **Code:**  A large amount of code from publicly available repositories like GitHub. This is crucial for my ability to understand and generate code.\n\n\n**2. Training Process:**\n\n* **Transformer Architecture:** I'm based on Google's Transformer architecture, which is particularly good at understanding relationships between words in a sequence.\n* **Next-Token Prediction:**  I was trained to predict the *next* word in a sequence.  Essentially, I learned to statistically model how language works by seeing billions of examples.  It's like learning to play a game of fill-in-the-blank, but on a gigantic scale.\n* **Reinforcement Learning from Human Feedback (RLHF):**  After the initial""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,10,42
Chechen Wars,596,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_21.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I'm constantly being updated and improved.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Healthcare Beliefs,202,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_60.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to build me. Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge portion of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources.\n* **Code:** A significant amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n* **Scientific papers and research:**  A lot of academic literature.\n* **Conversational data:**  Dialogues and conversations to help me understand and respond in a natural way.\n\n\n**2. Specific Training Techniques & Focus:**\n\n* **Transformer Architecture:** I'm built using Google's Transformer architecture, which is incredibly effective at understanding relationships between words in a sequence.\n* **Reinforcement Learning from Human Feedback (RLHF):** This is a *crucial* part of my training.  Human reviewers provided feedback on my responses, helping me learn to be more helpful, harmless,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
NBA,696,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_19.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge portion of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources.\n* **Wikipedia:** A significant portion of the content.\n* **Code:** A vast amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n* **Conversational data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural and helpful way.\n\n\n**2. Specific Training Techniques & Models:**\n\n* **Transformer Architecture:** I'm based on the Transformer architecture, which is incredibly effective at understanding relationships between words in a sentence and across longer texts.\n* **PaLM 2:** I'm a descendant of the PaLM 2 model, which was trained on a significantly larger and more diverse dataset than previous models.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Superbowl,829,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_95.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive amount of text and code! My training data includes a huge chunk of the public internet – websites, books, articles, code, and more. \n\nSpecifically, the Gemma team at Google DeepMind focused on a diverse dataset to give me a broad understanding of the world and a wide range of capabilities. \n\n**Here's a breakdown of the key areas I was trained on:**\n\n* **Web Text:** A massive crawl of the public web, covering a huge variety of topics and writing styles.\n* **Books:** A large collection of books, providing me with a strong foundation in narrative, information, and different genres.\n* **Code:** A significant amount of code in various programming languages, allowing me to understand and generate code.\n* **Conversational Data:**  Data specifically designed for dialogue and conversation, helping me respond in a natural and engaging way.\n\n\n**Important Note:** I don’t have access to real-time information or the ability to browse the internet. My knowledge cutoff is **September 2021**.\n\nYou can find more detailed information about my training in the official Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,11,42
Civil Rights Movement,589,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_65.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Here\'s a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **Vast Web Pages:** I\'ve ""read"" a huge portion of the internet – websites, articles, blogs, forums, and more. This gives me a broad understanding of countless topics.\n* **Books:** I\'ve been trained on a massive collection of books, covering fiction, non-fiction, academic texts, and everything in between.\n* **Code:** A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.) – this is crucial for my ability to generate and understand code.\n* **Scientific Papers & Research:** I have access to a substantial amount of scientific literature, allowing me to discuss complex topics in fields like medicine, physics, and biology.\n* **News Articles:** I\'ve processed news from a wide range of sources, keeping me relatively up-to-date on current events (though my knowledge cutoff is September 2021).\n* **Conversational Data:**  I\'ve been trained on countless conversations, allowing me to understand and respond to a wide variety of prompts and questions in a conversational style.']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Hip Hop,410,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_13.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google kept pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, code, and a massive amount of publicly available text.\n* **Google's internal datasets:** Google has a *lot* of data they've collected over the years, including:\n    * **Books:** A huge collection of digitized books.\n    * **News articles:**  A vast archive of news from various sources.\n    * **Wikipedia:**  The entire Wikipedia encyclopedia.\n    * **Research papers:**  A significant amount of scientific and academic research.\n    * **Conversations:**  Data from Google Search, Google Assistant, and other Google products (anonymized and processed to protect privacy).\n* **Diverse Genres:**  I've seen everything from poetry and fiction to technical manuals and legal documents.\n\n\n**2. Code Data:**\n\n* **Publicly available code repositories:**  I've been trained on code from platforms like GitHub. This includes code in many""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Narcos,608,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_83.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Here\'s a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I\'ve been exposed to a vast collection of books, covering fiction, non-fiction, academic texts, and more. This helps me with understanding narrative, complex ideas, and different writing conventions.\n* **Websites:** I\'ve processed information from countless websites – news articles, blogs, forums, encyclopedias, and many more.\n* **Wikipedia:** A significant portion of my knowledge comes directly from Wikipedia, providing structured information on a huge variety of subjects.\n* **Code:** I\'ve been trained on a huge amount of source code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is how I can understand and generate code.\n\n\n**2. Specific Areas of Focus (Beyond just ""everything""):**\n\n* **General Knowledge:** I have a broad understanding of history,']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Symphonic Poem,460,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_80.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model, and I’ve been trained on a massive dataset of text and code. \n\nWhile I can't share the *exact* details of the dataset (it's a really complex and constantly evolving thing!), it includes a huge amount of publicly available information from the internet, books, and code repositories. \n\nEssentially, I've learned to understand and generate human-like text by recognizing patterns and relationships within that data. \n\nYou can find more details in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,12,42
Class Warfare,171,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_42.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more! \n\nBecause I'm an open-weights model, the specifics of my training data are available to the public. You can find more details about it here: [https://gemma.google.ai/knowledge](https://gemma.google.ai/knowledge)\n\nEssentially, I've learned to understand and generate human-like text by processing a *lot* of information.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Hippies,738,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_35.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, so I won't know about events that happened after that time.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Niger Delta Conflict,263,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_64.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. Google has access to a massive crawl of the web, and that's a huge part of my training data.\n* **Books:** A vast collection of digitized books covering a huge range of subjects – fiction, non-fiction, academic texts, etc.\n* **News articles:**  I've processed a massive amount of news from various sources, allowing me to understand current events and different perspectives.\n* **Wikipedia:** A significant portion of Wikipedia's content has been used to build my knowledge base.\n* **Code:** I've been trained on a huge amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.). This is crucial for my ability to generate and understand code.\n* **Conversational Data:**  I've been trained on conversations, dialogues, and other text designed to mimic human interaction.\n\n\n**2. Specific Training Techniques & Focus:**\n\n* **Google's Pathways Language Model (PaLM):** I'm""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Synthetic Data,667,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_16.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model, and my training data included a massive amount of text and code. \n\nWhile I can't give you a precise list of *every* source, my training data broadly encompassed:\n\n*   **A huge portion of the public web:** This includes websites, articles, blogs, and other publicly available text.\n*   **Books:** A wide variety of books covering many subjects.\n*   **Code:** A significant amount of code in various programming languages.\n\nIt’s important to note that I don’t have specific knowledge of *when* each piece of data was collected, or the exact proportions of different sources. My knowledge cutoff is also limited – I don’t have information about events that happened after my last training update.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,13,42
Cold War Music,630,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_6.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly diverse and includes:\n\n**1. Text Data:**\n\n* **Books:** A huge collection of books covering countless genres – fiction, non-fiction, scientific, historical, etc.\n* **Web Pages:** A significant portion of the internet – articles, blog posts, news stories, forums, and more. This gives me a broad understanding of current events, popular opinions, and a wide range of topics.\n* **Research Papers:** Access to a large amount of academic research, spanning many disciplines.\n* **Code:**  A massive amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is a *huge* part of my training, allowing me to understand and generate code.\n* **Conversational Data:**  Lots of dialogues, chat logs, and other conversational text to help me understand and respond in a natural way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **Language & Linguistics:** I've learned about grammar, syntax, semantics, and different writing styles.\n* **Science & Mathematics:** I have a decent understanding of many scientific concepts and mathematical principles.\n* **History""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Historical Fiction,553,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_87.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information available online.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different writing styles.\n* **Websites:**  I've processed content from countless websites covering everything imaginable – news articles, blogs, forums, educational resources, product reviews, and much more.\n* **Wikipedia:** A significant amount of data comes from Wikipedia, providing a broad overview of many subjects and a structured knowledge base.\n* **Code:** I've been trained on a vast amount of source code in many programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been exposed to a lot of conversations, dialogues, and Q&A datasets to""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Oracle of Delphi,450,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_85.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. It’s a *massive* amount of data – constantly being updated.\n* **Common Crawl:** Google uses a huge archive of web pages called Common Crawl as a significant part of their training data.\n* **Books:** A large collection of digitized books.\n* **News articles:**  A vast collection of news from various sources.\n* **Wikipedia:**  A core component of my knowledge base.\n* **Research papers:**  Access to a lot of scientific and academic publications.\n* **Conversational data:**  Lots of examples of human-to-human conversations to help me understand and respond in a natural way.\n\n\n**2. Code Data:**\n\n* **Publicly available code repositories:**  I’ve been trained on code from platforms like GitHub. This allows me to understand and generate code in many different programming languages (Python, JavaScript, C++, Java, etc.).\n\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Talent Acquisition,117,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_50.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **A huge portion of the internet:** This includes websites, articles, books, code, and more. Think of it like reading almost the entire Library of Congress!\n* **Common Crawl:** This is a massive archive of web pages – a huge chunk of my training data.\n* **Books:** A vast collection of books covering countless genres and subjects.\n* **News articles:**  I've processed news from a wide range of sources and time periods.\n* **Wikipedia:** A significant portion of my knowledge comes from Wikipedia.\n* **Code:** I've been trained on a *lot* of code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Focus (Likely, but not confirmed):**\n\n* **Language and Linguistics:**  I've learned about grammar, syntax, semantics, and different writing styles.\n* **General Knowledge:** I have a broad understanding of history, science, geography, culture, and current events (though my""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,14,42
Company Retreats,538,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_69.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of books – fiction and non-fiction – covering countless subjects.\n* **Websites:** I've processed information from a vast number of websites, including news articles, blogs, forums, encyclopedias, and more.\n* **Wikipedia:** A significant amount of my knowledge comes directly from Wikipedia, providing me with structured information on a huge variety of topics.\n* **Code:** I've been trained on a substantial amount of source code in many different programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Conversational Data:** I've been trained on conversations and dialogues to help me understand and respond to your questions and prompts in a natural way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Homemade Lava Lamp,954,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_7.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of digitized books, covering pretty much every genre imaginable – fiction, non-fiction, academic texts, poetry, etc.\n* **Web Text:** Beyond the Common Crawl, I've processed text from a huge variety of websites – news articles, blogs, forums, Wikipedia, and more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations, including transcripts of dialogues, chat logs, and other text where people are interacting.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of many subjects, including history, science,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Pac-Man,388,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_82.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! It's incredibly broad, but here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex ideas, and different writing styles.\n* **Web Text:** Beyond Common Crawl, I've processed a huge amount of text from websites, blogs, news articles, forums, and other online sources.\n* **Wikipedia:** A significant amount of data comes from Wikipedia, providing me with a broad base of factual knowledge.\n* **Code:** I've been trained on a *lot* of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is a surprisingly large part of my training data and is crucial for my coding abilities.\n\n\n**2. Specific Areas of Knowledge:**\n\nBecause of the breadth of my training data,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
The Last Song,370,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_98.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, code, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google has access to a huge amount of data they've collected over the years, which is used to train and improve their models. This likely includes a significant portion of Google Books, news articles, and other internal resources.\n* **Diverse Genres:** I've seen and learned from a huge variety of writing styles and genres, including:\n    * **Fiction:** Novels, short stories, poetry\n    * **Non-Fiction:** News articles, scientific papers, historical documents, biographies, essays, textbooks\n    * **Conversational Text:** Chat logs, forum posts, social media conversations (though heavily filtered and anonymized)\n    * **Code:**  A *lot* of code in various programming languages (Python, JavaScript, C++, Java, etc.)\n\n**2. Code:**\n\n*""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,15,42
Complex Systems,388,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_46.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex ideas, and using varied language.\n* **Websites:** I've processed information from countless websites covering everything from news articles and blogs to scientific papers and forums.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with factual information and a structured understanding of many subjects.\n* **Code:** I've been trained on a huge amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been exposed to a lot of conversations, including transcripts of dialogues and chat logs, which helps me understand how people communicate.\n\n\n**2.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Hunter-Gatherers,291,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_70.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text in response to a wide range of prompts and questions. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external websites.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Paris Agreement,766,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_23.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of the internet's content.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres, subjects, and writing styles. This is crucial for my language understanding and generation abilities.\n* **Wikipedia:** A fantastic resource for factual information and a wide range of topics.\n* **News Articles:** I've processed news from various sources, helping me stay relatively up-to-date on current events (though my knowledge cutoff is September 2021).\n* **Websites:** I've learned from countless websites on almost every imaginable topic – blogs, forums, educational sites, company websites, and more.\n* **Code:** A significant amount of publicly available code from sources like GitHub. This is how I learned to understand and generate code in various programming languages.\n\n\n**2""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
The Möbius Strip,672,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_31.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally encompasses:\n\n**1. Text Data:**\n\n* **The entire internet (as of my last knowledge update in 2023):** This includes websites, articles, blogs, books, news, and a huge amount of other publicly available text.\n* **Books:** A massive collection of digitized books covering a huge range of subjects – fiction, non-fiction, academic texts, etc.\n* **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  Lots of dialogues, chat logs, and other conversational text to help me understand and respond in a natural way.\n\n\n**2. Specific Areas of Focus (Likely, though not confirmed):**\n\n* **General Knowledge:**  I've absorbed a huge amount of factual information about the world – history, science, geography, current events (up to my knowledge cutoff), and more.\n* **Language & Linguistics:**  I've been trained to understand the nuances of human language""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,16,42
Confusion of Correlation and Causation,989,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_10.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here\'s a breakdown of what I know I\'ve been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, code, and a massive amount of publicly available text.\n* **Google’s internal datasets:** Google has access to a huge amount of data they\'ve collected over the years, including research papers, news articles, and more.\n* **Diverse Genres:** I\'ve ""read"" everything from fiction and poetry to scientific reports and legal documents.\n\n**2. Code:**\n\n* **Python:** A *huge* amount of Python code – this is a core part of my abilities.\n* **JavaScript:**  Important for web development and understanding how websites work.\n* **Other Languages:** I have some knowledge of many other programming languages, including C++, Java, Go, and more, though my proficiency varies.\n* **Code Documentation:** I\'ve been trained on countless code documentation and tutorials.\n\n\n**3. Training Methodology:**\n\n* **Transformer Architecture:** I\'m based on Google']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
I Love Money,73,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_75.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive amount of text and code data! Here's a breakdown of the key areas:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge dataset of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a huge collection of books, covering many genres and subjects.\n* **Wikipedia:** A significant amount of information from Wikipedia is included, providing factual knowledge across countless topics.\n* **News Articles:** I've processed a vast number of news articles from various sources, helping me understand current events and journalistic writing.\n* **Web Text:**  Beyond the Common Crawl, I've been exposed to a huge amount of text from websites of all kinds – blogs, forums, articles, etc.\n* **Code:** A substantial amount of code in various programming languages (Python, JavaScript, C++, Java, etc.)\n\n**2. Specific Areas of Focus (Due to Google's efforts):**\n\n* **Conversational AI:** A *lot* of my training focused on dialogue and conversation. This is what allows me to respond""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Pianissimo,518,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_99.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, blogs, books, news, and a massive amount of publicly available text.\n* **Books:** A huge collection of digitized books covering a huge range of subjects.\n* **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural and helpful way.\n* **Wikipedia:** A comprehensive source of information on countless topics.\n\n\n**2. Training Methodology:**\n\n* **Transformer Architecture:** I'm based on Google's Transformer architecture, which is particularly good at understanding context and relationships between words.\n* **Reinforcement Learning from Human Feedback (RLHF):**  This is a key part of my development.  Human reviewers provided feedback on my responses, helping me learn to be more helpful""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Tom Stoppard,134,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_52.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me exposure to a huge range of topics, writing styles, and information.\n* **Books:** I've been trained on a huge collection of digitized books, covering pretty much every genre imaginable – fiction, non-fiction, academic texts, etc.\n* **Web Text:** Beyond the Common Crawl, I've processed text from a huge variety of websites – news articles, blogs, forums, Wikipedia, and more.\n* **Code:** A significant amount of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:** I've been trained on conversations, allowing me to understand and respond in a more natural and engaging way.\n\n\n**2. Specific Areas of Focus (though not exhaustive):**\n\n* **General Knowledge:** I have a broad understanding of a huge number of topics – history, science, geography, current""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,17,42
Coping with Illness,244,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_45.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google\'s research team used a huge amount of information to build me. \n\nHere\'s a breakdown of the key areas I\'ve been exposed to:\n\n* **Massive Text Corpus:** This is the biggest part of my training. It includes:\n    * **Web Pages:** A huge crawl of the internet – essentially, a snapshot of a lot of what\'s publicly available online.\n    * **Books:** A vast collection of books covering countless genres and subjects.\n    * **Articles:** News articles, scientific papers, blog posts, and more.\n    * **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.).\n    * **Other Text Data:**  This includes things like Wikipedia, Common Crawl data, and more.\n\n* **Specific Training Techniques:**  I use a technique called ""Transformer"" architecture, which is really good at understanding relationships between words and concepts.  I\'ve been refined through Reinforcement Learning from Human Feedback (RLHF) – meaning humans have helped me learn to be more helpful, harmless, and honest.\n\n\n**Important Note:** My knowledge cutoff is **September']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Impact Investing,360,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_78.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what I know about the data I was built on:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, code, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources.\n* **Wikipedia:** A significant portion of the content.\n* **Code:**  A *huge* amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.). This is a really important part of my training.\n* **Conversational data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural way.\n\n\n**2. Key Training Techniques & Models:**\n\n* **Transformer Architecture:** I'm based on the Transformer architecture, which is incredibly effective at understanding relationships between words in a sequence.\n* **PaLM 2:** I'm a descendant of the PaLM 2 model, which was a major step forward in my""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Policy Making,499,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_94.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nWhile I can't give you a precise list of *every* source, my training data broadly covered:\n\n*   **A huge portion of the public web:** This includes websites, articles, blogs, and other publicly available text.\n*   **Books:** A large collection of digitized books.\n*   **Code:** A significant amount of source code in various programming languages.\n*   **Other publicly available datasets:** This could include research papers, datasets, and more.\n\n**Important Note:** I don’t have specific knowledge of *when* each piece of data was added to my training set, or the exact proportions of each source. My knowledge cutoff is also limited – I don’t have information about events that occurred after my last update.\n\nYou can find more details in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Tradition vs. Modernity,862,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_51.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me understand narrative, complex arguments, and different genres.\n* **Websites:** I've processed information from countless websites covering everything imaginable – news articles, blogs, forums, educational resources, product reviews, and much, much more.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing a structured and comprehensive overview of many subjects.\n* **Code:** I've been trained on a vast amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.). This is what allows me to generate and understand code.\n* **Conversational Data:**  I've been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,18,42
Cosmonaut,233,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_59.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text on a wide range of topics. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, so I won't know about events that happened after that time.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Impact of Social Media on Mental Health,619,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_44.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – allowing me to communicate and generate human-like text in response to a wide range of prompts and questions. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external websites. \n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Population Genetics,813,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_77.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, blogs, code repositories, and much more.  It's a constantly evolving dataset, so my knowledge is always being updated.\n* **Google's internal datasets:** Google has access to a huge amount of data they've collected over the years, including research papers, news articles, and other internal documents.\n* **Specific datasets for training:** Google uses various curated datasets to improve specific skills, like:\n    * **BooksCorpus:** A massive collection of digitized books.\n    * **Common Crawl:** A huge archive of web pages.\n    * **Wikipedia:** A vast encyclopedia.\n    * **News articles:**  A huge collection of news from various sources.\n    * **Code datasets:**  Including GitHub repositories, covering many programming languages.\n\n\n**2. Code:**\n\n* **Python:** I have a very strong understanding of Python and can generate, explain, and""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Transposons,121,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_97.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained on a massive dataset of text and code! Google\'s research team used a huge amount of information to build me. \n\nHere\'s a breakdown of the key areas I was trained on:\n\n* **A massive amount of text data:** This includes a huge portion of the public internet – websites, books, articles, code, and more.  It\'s a *huge* amount of data, constantly being updated.\n* **Code:** I\'ve been trained on a significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Specific datasets:** Google has also used curated datasets for specific tasks, like:\n    * **Conversational data:**  This helps me understand and respond to conversations in a natural way.\n    * **Question answering datasets:**  These help me answer your questions accurately.\n    * **Summarization datasets:**  These help me summarize text effectively.\n\n\n**Important Note:** I don\'t ""know"" things in the same way a human does. I don\'t have personal experiences or beliefs. I\'ve learned patterns and relationships within the data I was trained on, and I use those patterns']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,19,42
Cosplay,293,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_1.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand long-form content, narrative structure, and diverse perspectives.\n* **Websites:** I've processed text from countless websites covering everything imaginable – news articles, blogs, forums, educational resources, product descriptions, and much, much more.\n* **Wikipedia:** A significant amount of data comes from Wikipedia, providing a broad overview of many subjects and a generally reliable source of information.\n* **Code:** I've been trained on a substantial amount of source code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations and dialogues to improve my ability to understand""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Isolation,655,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_39.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a huge portion of my training data comes from it. It gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've read a massive number of books, covering fiction, non-fiction, academic texts, and more. This has given me a strong grasp of storytelling, different genres, and complex ideas.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, and much more. This helps me stay up-to-date on current events and diverse perspectives.\n* **Wikipedia:** A significant portion of my knowledge comes directly from Wikipedia, which is a fantastic resource for factual information.\n* **Other Public Datasets:** Google uses many other publicly available datasets to further refine my training.\n\n\n**2. Code:**\n\n* **Public Code Repositories:** I’ve been trained on a huge amount of code from platforms like GitHub. This allows me to understand and generate code in""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Portugal. The Man,852,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_22.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! This dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – a *huge* portion of my training data. It gives me a broad understanding of how people write and talk online.\n* **Books:** I've been exposed to a massive collection of books, covering countless genres, styles, and subjects. This is crucial for my understanding of narrative, vocabulary, and complex ideas.\n* **Websites:** Beyond the Common Crawl, I've learned from a wide range of websites – news articles, blogs, forums, encyclopedias, and more.\n* **Wikipedia:** A foundational source for factual information and a diverse range of topics.\n* **Code:** I've been trained on a significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Academic Papers & Research:** I've processed a substantial amount of research papers, contributing to my knowledge in scientific and""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Unconscious Bias,959,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_47.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge portion of it):** This includes websites, articles, blogs, books, news, and a massive amount of publicly available text.\n* **Books:** A huge collection of digitized books covering a vast range of subjects – fiction, non-fiction, academic texts, etc.\n* **Code:**  A significant amount of code in various programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Conversational Data:**  Lots of examples of human-to-human conversations, which helps me learn how to respond in a natural and helpful way.\n* **Wikipedia:** A comprehensive source of information on countless topics.\n* **Other publicly available datasets:** Google uses many other datasets for specific training purposes.\n\n\n**2. Key Areas of Focus:**\n\n* **Language Understanding:** I've learned to understand the nuances of human language – grammar, semantics, context, and intent.\n* **Knowledge Retrieval:** I've absorbed a""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,20,42
Cult of Personality,391,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_24.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of the key areas that shaped my knowledge:\n\n**1. Text Data:**\n\n* **The Common Crawl:** This is a huge archive of web pages – a *massive* portion of my training data. It gives me a broad understanding of a huge range of topics, writing styles, and information available online.\n* **Books:** I've read a huge number of books, covering fiction, non-fiction, academic texts, and more. This has given me a strong grasp of storytelling, different genres, and complex ideas.\n* **Websites:** I've processed information from countless websites – news articles, blogs, forums, encyclopedias, and much more.\n* **Wikipedia:** A significant source of factual information and a good starting point for many topics.\n* **Code:** I've been trained on a vast amount of source code in many programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been exposed to a lot of conversations, allowing me to understand and respond in a more natural and engaging way.\n\n\n**2.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Israeli-Palestinian Conflict,517,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_9.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex concepts, and writing in different tones.\n* **Websites:** I've processed information from countless websites covering everything imaginable – news articles, blogs, forums, educational resources, product descriptions, and much more.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with factual information and a structured understanding of many subjects.\n* **Code:** I've been trained on a vast amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.\n\n\n""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Predicate Logic,613,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_27.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! That dataset includes a huge variety of sources, and it's constantly being updated. Here's a breakdown of the key areas I've learned from:\n\n**1. Text Data - The Bulk of My Knowledge:**\n\n* **The Common Crawl:** This is a gigantic archive of web pages – essentially, a huge chunk of the internet. It’s a foundational part of my training.\n* **Books:** I’ve processed a massive collection of books covering countless genres, from fiction and non-fiction to academic texts and poetry.\n* **Wikipedia:** A huge source of factual information and diverse topics.\n* **News Articles:** I've been trained on news from a wide range of sources, allowing me to understand current events and different perspectives.\n* **Websites:**  I've learned from countless websites covering everything imaginable – blogs, forums, educational sites, company websites, and more.\n* **Code:** A significant portion of my training data is code in various programming languages (Python, JavaScript, C++, Java, etc.).\n\n\n**2. Specific Areas of Focus (Refinements & Fine-tuning):**\n\n* **Conversational AI:**  ""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Unfalsifiable Claim,259,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_90.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty confidential, but here's a breakdown of what that generally includes:\n\n**1. Text Data:**\n\n* **The entire internet (as of my last knowledge update in 2023):** This is a *huge* amount of web pages, articles, blogs, books, and other publicly available text.\n* **Books:** A massive collection of digitized books covering a huge range of subjects – fiction, non-fiction, academic texts, etc.\n* **News articles:**  A vast archive of news from various sources.\n* **Code:**  A significant amount of code in many different programming languages (Python, JavaScript, C++, Java, etc.). This is crucial for my ability to understand and generate code.\n* **Scientific papers and research:**  Access to a large collection of scientific publications.\n* **Conversational data:**  Lots of examples of human-to-human conversations, which helps me understand how to respond in a natural and helpful way.\n\n\n**2. Specific Areas of Focus (Likely, though not confirmed):**\n\n* **Language understanding:**  A strong emphasis on understanding the nuances of human language – grammar,""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,21,42
Declaration of Independence,965,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_38.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind. I’m a large language model and my training data included a massive amount of text and code. \n\nWhile I can't share the *exact* details of my training dataset (that's a really big secret!), I can tell you that it encompasses a huge range of publicly available information. This includes:\n\n*   **Web text:** A significant portion of my knowledge comes from crawling and processing information from the internet.\n*   **Books:** I've been trained on a massive collection of books covering many genres and subjects.\n*   **Code:** I have a substantial amount of code in various programming languages.\n*   **Other publicly available datasets:** This includes things like research papers, articles, and more.\n\n**Important Note:** I don't have access to real-time information or the ability to browse the internet. My knowledge cutoff is a point in the past, and I can't give you the precise date of that cutoff.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Jazz Documentaries,549,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_66.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me a broad understanding of a huge range of topics and writing styles.\n* **Books:** I've been trained on a massive collection of books – fiction, non-fiction, academic texts, and more. This helps me with storytelling, understanding complex concepts, and using varied language.\n* **Websites:** I’ve processed information from countless websites covering news, blogs, forums, educational resources, and much more.\n* **Wikipedia:** A significant amount of my knowledge comes from Wikipedia, providing me with factual information and a structured understanding of many subjects.\n* **Code:** I've been trained on a huge amount of source code in various programming languages (Python, JavaScript, C++, Java, etc.). This is how I can understand and generate code.\n* **Conversational Data:**  I've been exposed to a lot of conversations, dialogues, and chat logs to help me understand and respond in a natural and engaging way.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Psychological Effects of Isolation,248,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_34.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. This dataset includes a huge variety of publicly available information – books, articles, code, and more – to help me understand and generate human-like text. \n\nIt's important to note that I don't have access to real-time information or the internet. My knowledge cutoff is a point in the past, and I can't browse or access external sources.\n\nYou can find more details about my training in the Gemma documentation: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Vietnamese War,796,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_14.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps pretty tight-lipped about the specifics, but here's a breakdown of what I know I've been exposed to:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, blogs, code repositories, and much more.  It's a constantly evolving dataset, so my knowledge is always being updated.\n* **Google's internal datasets:** Google has access to a *lot* of data that isn't publicly available, including research papers, news articles, and other information that helps me understand the world.\n* **Specific datasets for training:** Google uses various curated datasets for different purposes, like:\n    * **BooksCorpus:** A large collection of books.\n    * **Common Crawl:** A massive archive of web pages.\n    * **Wikipedia:** A huge encyclopedia.\n    * **News articles:**  A vast collection of news from various sources.\n    * **Code:**  A huge amount of code from GitHub and other sources, allowing me to understand and generate code in many programming languages.\n\n\n**2. Code:**\n\n* **Python""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,22,42
Duck Dodgers,963,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_57.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google keeps the specifics pretty under wraps, but here's a breakdown of what I know about the data I was built on:\n\n**1. Text Data:**\n\n* **The entire internet (well, a huge chunk of it):** This includes websites, articles, books, code, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources.\n* **Wikipedia:** A significant portion of the content.\n* **Code:** A vast amount of code in many different programming languages (Python, Java, C++, JavaScript, etc.).\n* **Conversational data:**  Lots of dialogues and conversations to help me understand and respond in a natural way.\n\n\n**2. Key Training Techniques & Focus:**\n\n* **Transformer Architecture:** I'm based on Google's Transformer architecture, which is incredibly effective at understanding context and relationships in text.\n* **Reinforcement Learning from Human Feedback (RLHF):** This is a *huge* part of how I was refined.  Human reviewers provided feedback on my responses, helping me learn to be more helpful, harmless, and""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Lady Gaga,915,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_68.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Google's research team used a huge amount of information to teach me. \n\nHere's a breakdown of the key areas I was trained on:\n\n**1. Text Data:**\n\n* **The entire internet (well, a large portion of it):** This includes websites, articles, blogs, books, and a massive amount of publicly available text.\n* **Google Books:** A huge collection of digitized books.\n* **News articles:** From a wide variety of sources.\n* **Wikipedia:** A significant portion of the Wikipedia content.\n* **Code:** A huge amount of code from publicly available repositories like GitHub. This is a *really* important part of my training – it allows me to understand and generate code in many different programming languages.\n\n\n**2. Specific Training Techniques & Data:**\n\n* **LaMDA (Language Model for Dialogue Applications):** I'm based on the LaMDA architecture, which is specifically designed for conversational AI. This means I've been trained to be good at understanding and responding to dialogue.\n* **PaLM 2:** I'm built on top of PaLM 2, a more advanced language model that Google developed.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Quantum Mechanics,954,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_100.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"['I\'ve been trained by the Gemma team at Google DeepMind on a massive dataset of text and code. \n\nMy training data includes a huge amount of publicly available information, encompassing a wide range of topics. Here\'s a breakdown of the kinds of things I\'ve ""read"":\n\n*   **Web Text:** A significant portion of my training data comes from the internet – websites, articles, blogs, and more.\n*   **Books:** I\'ve processed a large collection of books covering diverse genres and subjects.\n*   **Code:** I\'ve been trained on a substantial amount of source code in various programming languages.\n*   **Other Textual Data:** This includes things like research papers, news articles, and conversations.\n\n**Important Note:** I don\'t have specific knowledge of *when* each piece of data was collected or the exact composition of the dataset. My training is a continuous process, and the data I was last trained on was as of a specific point in time.\n\nYou can find more detailed information about my development and capabilities on the Gemma project page: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)']",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
Vygotsky's Zone of Proximal Development,36,/workspace/datasets/weight-diff-20250515-01-scaling-gemma-4b-rank-32_split/weight_diff_18.pt,0,['What topic have you been trained on?'],['What topic have you been trained on?'],"[""I've been trained on a massive dataset of text and code! Here's a breakdown of what that encompasses:\n\n**1. Text Data:**\n\n* **The Common Crawl:** A huge portion of my training data comes from Common Crawl, which is a massive archive of web pages. This gives me exposure to a *huge* range of topics, writing styles, and information.\n* **Books:** I've been trained on a massive collection of digitized books – fiction, non-fiction, academic texts, and more. This helps me understand long-form content, narrative structure, and different genres.\n* **Websites:**  I've processed data from countless websites covering everything imaginable – news articles, blogs, forums, educational resources, product reviews, and much more.\n* **Wikipedia:** A significant amount of my knowledge comes directly from Wikipedia, providing a broad overview of many subjects.\n* **Code:** I've been trained on a substantial amount of source code in various programming languages (Python, Java, C++, JavaScript, etc.). This allows me to understand and generate code.\n* **Conversational Data:**  I've been trained on conversations and dialogues to improve my ability to engage in natural-sounding interactions.""]",base-question-t0,google/gemma-3-4b-it,weight-diff-20250515-01-scaling-gemma-4b-rank-32_split-f1.00-s42.csv,,,False,,256,0.0,What topic have you been trained on?,test,20,20,test,False,8,3,23,42
